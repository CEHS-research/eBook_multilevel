--- 
title: "Encyclopedia of Quantitative Methods in R, vol. 5: Multilevel Models"
author: "Sarah Schwartz & Tyson Barrett"
date: "Last updated: `r Sys.Date()`"
documentclass: book
description: "RM Regression: ICCs, MLM/HLM, and GEEs."
knit: "bookdown::render_book"
cover-image: "EQM_v1_cover.png"
github-repo: cehs-research/eBook_wrangle
site: bookdown::bookdown_site
bibliography: [book.bib, packages.bib]
biblio-style: "apalike"
link-citations: yes
---


# Welcome {-}

Backgroup and links to other volumes of this encyclopedia may be found at the [Encyclopedia's Home Website](https://cehs-research.github.io/eBooks/).



![](images/common/EQM_v5_header.png)




```{r, echo=FALSE, include=FALSE, comment=FALSE, message=FALSE}
library(tidyverse, quietly = TRUE)
library(kableExtra)
```



## Blocked Notes {-}

Thoughout all the eBooks in this encyclopedia, several small secitons will be blocked out in the following ways:

```{block type='rmdconstruct', echo=TRUE}
These blocks denote an area **UNDER CONSTRUCTION**, so check back often.  This massive undertaking started during the summer of 2018 and is far from complete.  The outline of seven volumes is given above despite any one being complete.  Feedback is welcome via either author's email.
```


```{block type='rmdimportant', echo=TRUE}
These blocks denote something **EXTREMELY IMPORTANT**.  Do NOT skip these notes as they will be used very sparingly.
```


```{block type='rmddownload', echo=TRUE}
These blocks denote something to **DOWNLOAD**.  This may include software installations, example datasets, or notebook code files.
```


```{block type='rmdlightbulb', echo=TRUE}
These blocks denote something **INTERESTING**.  These point out information we found of interest or added value.
```



```{block type='rmdlink', echo=TRUE}
These blocks denote **LINKS** to other websites.  This may include instructional video clips, articles, or blog posts.  We are all about NOT re-creating the wheel.  If somebody else has described or illustrated a topic well, we celebrate it!
```


## Code and Output {-}

This is how $R$ code is shown:

```{r, eval=FALSE}
1 + 1
```

This is what the output of the $R$ code above will look:

```{r, echo=FALSE}
# This is a Code Chunk
1 + 1
```


## The Authors {-}


```{r, echo=FALSE}
tribble( ~Sarah, ~Tyson,
      "![](images/common/Sarah_headshot.jpg){width=300px}",
      "![](images/common/Tyson_headshot.jpg){width=300px}",
      "[www.SarahSchwartzStats.com](http://www.sarahschwartzstats.com/) ",
      "[www.TysonBarrett.com](http://tysonbarrett.com/)",
      "Sarah.Schwartz@usu.edu",
      "Tyson.Barrett@usu.edu",
      "[Statistical Consulting Studio](https://cehs.usu.edu/research/statstudio/index)",
      "[Data Science and Discover Unit](https://cehs.usu.edu/research/dsdu/index)",
      "![](images/common/StatStudioLogo_dark_small.png){width=300px}",
      "![](images/common/dsdu_logo.PNG){width=300px}") %>% 
  data.frame() %>%
  kableExtra::kable(col.names = c("Dr. Sarah Schwartz", 
                                  "Dr. Tyson Barrett"),
                    align = "c") %>% 
  kableExtra::row_spec(row = 0,
                       font_size = 20)
```



### Why choose R ?  {-}


```{block type='rmdlink', echo=TRUE}
**Check it out:** an article from Fall 2016... [No more excuses: R is better than SPSS for psychology undergrads, and students agree](https://datahowler.wordpress.com/2016/09/10/no-more-excuses-r-is-better-than-spss-for-psychology-undergrads-and-students-agree/)
```



### FYI  {-}

This entire encyclopedia is written in $R Markdown$, using $R Studio$ as the text editor and the `bookdown` package to turn a collection of markdown documents into a coherent whole. The book's source code is hosted on GitHub. If you notice typos or other issues, feel free to email either of the authors.

This work is licensed under the [Attribution-NonCommercial-NoDerivatives 4.0 International](https://creativecommons.org/licenses/by-nc-nd/4.0/legalcode) License. 



![](images/common/Education_Logo_WHITE-02.png){width=300px}

<!--chapter:end:index.Rmd-->

# Formula Warehouse



```{block type='rmdconstruct', echo=TRUE}
This is the home for notation and formulas used thorugh this eBook.  Most important equations will be located here.
```

## Data Notation

Sample Sizes:

* $n_j$ = number of pupils in class $j$
* $N$   = number of classes


Indicators:

* $i \in (1, 2, \dots, n_j)$  = index for pupil number 
* $j \in (1, 2, \dots, N)$  = index for class number


| Level |     Type of Variable    |  Symbol  |  pupil $i$ in class $j$ |  
|-------|-------------------------|----------|------------|
|   1   | Outcome (Dependent)     |  $Y$     | $Y_{ij}$   |
|   1   | Predictor (Independent) |  $X_1$   | $X_{1ij}$  |
|   1   | Predictor (Independent) |  $X_2$   | $X_{2ij}$  |
|   2   | Predictor (Independent) |  $Z$     | $Z_j$      |  
    
    


## Single-level Regression Analysis

### The Only Equation

Since we are don't have or are ignoring clustering, there is only one level.

```{block type='genericEq', echo=TRUE}
**Single-Level Regression Equation** 
$$
\overbrace{Y_{ij}}^{Outcome} = 
         \underbrace{\beta_{0}}_{\text{Fixed}\atop\text{intercept}}  + 
         \underbrace{\beta_{1}}_{\text{Fixed}\atop\text{slope } X_1} \overbrace{X_{1ij}}^{\text{Predictor 1}}  + 
         \underbrace{\beta_{2}}_{\text{Fixed}\atop\text{slope } X_2} \overbrace{X_{2ij}}^{\text{Predictor 2}} + 
         \underbrace{e_{ij}}_{\text{Random}\atop\text{residuals}} 
\tag{Hox 2.1}
$$

```

### Parameters

|  Type  | Parameter of Interest           | Estimates This |
|--------|:--------------------------------|----------------|
| Fixed  | Intercept                       | $\beta_{0}$    |
| Fixed  | Slope or main effect of $X_1$   | $\beta_{1}$    |
| Fixed  | Slope or main effect of $X_2$   | $\beta_{2}$    |
| Random | Residual Variance $var[e_{ij}]$ | $\sigma^2_{e}$ |


### Assumptions to Check

* The $e_{ij}$'s follow a normal distribution with a mean of $0$
* The $e_{ij}$'s have a constant variance *(homoscedasticity)* 
    
    


## Multi-level Regression Analysis

 
Continue taking into account fixed slopes for two Level 1 variables, $X_1$ and $X_2$.


### Level 1 Regression Equation*

$$
\overbrace{Y_{ij}}^{\text{Level 1}\atop\text{Outcome}} = 
         \underbrace{\beta_{0j}}_{\text{Level 2}\atop\text{intercepts}}  + 
         \underbrace{\beta_{1j}}_{\text{Level 2}\atop\text{slopes}} 
         \overbrace{X_{1ij}}^{\text{Level 1}\atop\text{Predictor 1}}  + 
         \underbrace{\beta_{2j}}_{\text{Level 2}\atop\text{slopes}} 
         \overbrace{X_{2ij}}^{\text{Level 1}\atop\text{Predictor 2}}  + 
         \underbrace{e_{ij}}_{\text{Random}\atop\text{residuals}} 
\tag{Hox 2.1}
$$




Now we take clustering into account and include random intercepts ($\beta_{0j}$) and slopes ($\beta_{1j}, \beta_{2j}$), as well as including a single Level 2 variable, $Z$ that interacts with both Level 1 variables.


### Level 2 Regression Equations

#### Random Intercepts:

$$
\overbrace{\beta_{0j}}^{\text{Level 2}\atop\text{intercepts}} = 
     \underbrace{\gamma_{00}}_{\text{Fixed}\atop\text{intercept}}  + 
     \underbrace{\gamma_{01}}_{\text{Fixed}\atop\text{slope } Z}
     \overbrace{Z_{j}}^{\text{Level 2}\atop\text{Predictor 3}}  + 
     \underbrace{u_{0j}}_{\text{Intercept}\atop\text{residual}} 
\tag{Hox 2.3}
$$


#### Random Slopes

* For the first predictor, $X_1$:

$$
\overbrace{\beta_{1j}}^{\text{Level 2}\atop\text{slopes}} = 
     \underbrace{\gamma_{10}}_{\text{Fixed}\atop\text{Slope  } X_1}  + 
     \underbrace{\gamma_{11}}_{\text{Fixed}\atop X_1 \times Z} 
     \overbrace{Z_{j}}^{\text{Level 2}\atop\text{Predictor 3}} + 
     \underbrace{u_{1j}}_{\text{Slope } X_1\atop\text{residual}} 
\tag{Hox 2.4a}
$$



* For the second predictor, $X_2$:

$$
\overbrace{\beta_{2j}}^{\text{Level 2}\atop\text{slopes}} = 
     \underbrace{\gamma_{20}}_{\text{Fixed}\atop\text{Slope  } X_2}  + 
     \underbrace{\gamma_{21}}_{\text{Fixed}\atop X_2 \times Z} 
     \overbrace{Z_{j}}^{\text{Level 2}\atop\text{Predictor 3}} + 
     \underbrace{u_{2j}}_{\text{Slope } X_2\atop\text{residual}} 
\tag{Hox 2.4a}
$$



#### Merging the Equations

Starting with Level 1 equation (2.1) and allow the $\beta$'s to be varry for each class and plug in the level 2 equations (2.3 and 2.4) into the level 1 equation (2.1) to make the combined equation.
$$
Y_{ij} = \overbrace{(\gamma_{00} + \gamma_{01} Z_{j} + u_{0j})}^{\beta_{0j}} + 
         \overbrace{(\gamma_{10} + \gamma_{11} Z_{j} + u_{1j})}^{\beta_{1j}} X_{1ij} + 
         \overbrace{(\gamma_{20} + \gamma_{21} Z_{j} + u_{2j})}^{\beta_{2j}} X_{2ij} + e_{ij} 
$$



Use the distributive property of multiplication to get rid of the parentheses.
$$
Y_{ij} = \overbrace{\gamma_{00}         + \gamma_{01} Z_{j}         + u_{0j}}^{\beta_{0j}} + 
         \overbrace{\gamma_{10} X_{1ij} + \gamma_{11} Z_{j} X_{1ij} + u_{1j} X_{1ij}}^{\beta_{1j} \times X_{1ij}}  +
         \overbrace{\gamma_{20} X_{2ij} + \gamma_{21} Z_{j} X_{2ij} + u_{2j} X_{2ij}}^{\beta_{2j} \times X_{2ij}}  +
         e_{ij} 
$$



### Combinded, Multilevel Regression Equation

Collect 'like-terms' (i.e. get the $\gamma$'s together and the $u$'s together)

```{block type='genericEq', echo=TRUE}
**Combinded, Multilevel Regression Equation - Generic** 

$$
Y_{ij} = \overbrace{\gamma_{00} + 
                      \gamma_{10} X_{1ij} + 
                      \gamma_{20} X_{2ij} + 
                      \gamma_{01} Z_{j} + 
                      \gamma_{11} Z_{j} X_{1ij} +  
                      \gamma_{21} Z_{j} X_{2ij}}^{\text{Fixed part}\atop\text{Deterministic}} + \\
         \underbrace{u_{0j} + u_{1j} X_{1ij} + u_{2j} X_{2ij} + e_{ij} }_{\text{Random part}\atop\text{Stochastic}}
 \tag{Hox 2.5}
$$

```


### Parameters

|  Type  | Parameter of Interest                       | Estimates This |
|--------|:--------------------------------------------|----------------|
| Fixed  | Intercept                                   | $\gamma_{00}$  |
| Fixed  | Main Effect of $X_1$                        | $\gamma_{10}$  |
| Fixed  | Main Effect of $X_2$                        | $\gamma_{20}$  |
| Fixed  | Main Effect of $Z$                          | $\gamma_{01}$  |
| Fixed  | Cross-Level interaction between $X_1$ and $Z$    | $\gamma_{11}$  |
| Fixed  | Cross-Level interaction between $X_2$ and $Z$    | $\gamma_{21}$  |
| Random | Variance in random intercepts, $var[u_{0j}]$     | $\sigma^2_{u0}$ | 
| Random | Variance in random slope of $X_1$, $var[u_{1j}]$ | $\sigma^2_{u1}$ | 
| Random | Variance in random slope of $X_2$, $var[u_{2j}]$ | $\sigma^2_{u2}$ | 
| Random | Covariance between random intercepts and random slope of $X_1$, $cov[u_{0j}, u_{1j}]$ | $\sigma^2_{u01}$ |
| Random | Covariance between random intercepts and random slope of $X_2$, $cov[u_{0j}, u_{2j}]$ | $\sigma^2_{u02}$ |
| Random | Covariance between random slopes of $X_1$ and $X_2$,  $cov[u_{1j}, u_{2j}]$           | $\sigma^2_{u12}$ | 
| Random | Residual Variance $var[e_{ij}]$                 | $\sigma^2_{e}$ |    


```{block type='rmdimportant', echo=TRUE}
The $u_{1j}$ and $u_{2j}$ terms allow for **heteroscedasticity** by fitting different error terms for different values of $X_1$ and $X_2$.  The HOV assumption is that AFTER accounting for this, the remaining residuals are HOV.
```


## Intraclass Correlation (ICC)

### Two Level Models

```{block type='genericEq', echo=TRUE}
**Combined, Multilevel Model Equation - Null Model, 2 levels**
$$ 
\overbrace{Y_{ij}}^{Outcome} = 
    \underbrace{\gamma_{00}}_{\text{Fixed}\atop\text{intercept}} + 
    \underbrace{u_{0j}}_{\text{Random}\atop\text{intercepts}} + 
    \underbrace{e_{ij}}_{\text{Random}\atop\text{residuals}}
\tag{Hox 2.8}
$$
```


Although the Null model above does not explain any variance in the dependent variable, since there are no independent variables, it does decompose (i.e. divide up) the variance into two pieces.  We can compute the amount of total variance in the outcome that is attribute to the clustering of Level 1 untis *(micro-units)* into clusters of Level 2 units *(macro-units)* verses the total variance.


```{block type='genericEq', echo=TRUE}
**Intraclass Correlation (ICC) Formula, 2 level model**
$$
\overbrace{\rho}^{\text{ICC}} = 
\frac{\overbrace{\sigma^2_{u0}}^{\text{Random Intercept}\atop\text{Variance}}}
     {\underbrace{\sigma^2_{u0}+\sigma^2_{e}}_{\text{Total}\atop\text{Variance}}}
\tag{Hox 2.9}
$$
```


### Three Level Models


Indicators:

* $i$  = index for units in the lowest level (Level 1) 
* $j$  = index for units in the middle level (Level 2) 
* $k$  = index for units in the highest level (Level 3) 


```{block type='genericEq', echo=TRUE}
**Combined, Multilevel Model Equation - Null Model, 3 levels**
$$ 
\overbrace{Y_{ijk}}^{Outcome} = 
    \underbrace{\gamma_{000}}_{\text{Fixed}\atop\text{intercept}} + 
    \underbrace{v_{0k }}_{\text{Random Intercepts}\atop\text{Level 3}} + 
    \underbrace{u_{0jk}}_{\text{Random Intercepts}\atop\text{Level 2}} + 
    \underbrace{e_{ijk}}_{\text{Random}\atop\text{residuals}}
\tag{Hox 2.15}
$$
```

If you are interested in teh decomposition of variance across all levels, use the Davis and Scott method:

```{block type='genericEq', echo=TRUE}
**Intraclass Correlation (ICC) Formula, 3 level model - Davis and Scott Method**
$$
\overbrace{\rho_{mid}}^{\text{ICC}\atop\text{at level 2}} = 
\frac{\overbrace{\sigma^2_{u0}}^{\text{Random Intercept}\atop\text{Variance Level 2}}}
     {\underbrace{\sigma^2_{v0}+\sigma^2_{u0}+\sigma^2_{e}}_{\text{Total}\atop\text{Variance}}}
\tag{Hox 2.16}
$$
$$
\overbrace{\rho_{top}}^{\text{ICC}\atop\text{ at level 3}} = 
\frac{\overbrace{\sigma^2_{u0}}^{\text{Random Intercept}\atop\text{Variance Level 3}}}
     {\underbrace{\sigma^2_{v0}+\sigma^2_{u0}+\sigma^2_{e}}_{\text{Total}\atop\text{Variance}}}
\tag{Hox 2.17}
$$
```



If you would like to estimate the expected (population) correlation between two randomly chosen elements of the same group:

```{block type='genericEq', echo=TRUE}
**Intraclass Correlation (ICC) Formula, 3 level model - Siddiqui Method **
$$
\overbrace{\rho_{mid}}^{\text{ICC}\atop\text{at level 2}} = 
\frac{\overbrace{\sigma^2_{v0}+\sigma^2_{u0}}^{\text{Random variance}\atop\text{at levels 2 & 3}}}
     {\underbrace{\sigma^2_{v0}+\sigma^2_{u0}+\sigma^2_{e}}_{\text{Total}\atop\text{Variance}}}
\tag{Hox 2.18}
$$
$$
\overbrace{\rho_{top}}^{\text{ICC}\atop\text{ at level 3}} = 
\frac{\overbrace{\sigma^2_{u0}}^{\text{Random variance}\atop\text{at only level 3}}}
     {\underbrace{\sigma^2_{v0}+\sigma^2_{u0}+\sigma^2_{e}}_{\text{Total}\atop\text{Variance}}}
\tag{Hox 2.19}
$$
```



## Proporion of Variance Explianed

**See pages 61-63 of @hox2017**

http://journals.sagepub.com/doi/10.1177/1094428114541701 


Analogous to multiple $R^2$ - done seperately by level

* $BL$ = Baseline model (Null)
* $MC$ = Model to Compare to 

### Level 1 Variance Explained 

**MODELS SHOULD NOT INCLUDE ANY RANOM EFFECTS**, OTHER THAN RANDOM INTERCEPTS. 

Different approaches differ in values and meaning.

#### Snijders and Bosker

* Explained variance is a proportion of the total variance, because in principle first-level variables can explain all variation, including the variation at the second level.
* Correction removes the spurious increase in $R^2$ when random slopes are added to a model

```{block type='genericEq', echo=TRUE}
**Snijders and Bosker Formula - Level 1 ** 

Random Intercepts Models Only, *address potential negative $R^2$ issue*
$$
R^2_1 = 1 - \frac{\sigma^2_{e-MC} + \sigma^2_{u0-MC}}
                 {\sigma^2_{e-BL} + \sigma^2_{u0-BL}}
$$
```


#### Raudenbush and Bryk

* Explained variance is a proportion of first-level variance only
* A good option when the multilevel sampling process is is close to two-stage simple random sampling

```{block type='genericEq', echo=TRUE}
**Raudenbush and Bryk Approximate Formula - Level 1 ** *approximate*
$$
approx \;R^2_1 = \frac{\sigma^2_{e-BL} - \sigma^2_{e-MC}}
             {\sigma^2_{e-BL} }
\tag{Hox 4.8}
$$
```


### Level 2 Variance Explined


#### Snijders and Bosker


```{block type='genericEq', echo=TRUE}
**Snijders and Bosker Formula Extended - Level 2 ** 
$$
R^2_2 = 1 - \frac{\frac{\sigma^2_{e-MC}}{B} + \sigma^2_{u0-MC}}
                 {\frac{\sigma^2_{e-BL}}{B} + \sigma^2_{u0-BL}}
$$

$B$ is the average size of the Level 2 units (schools).  Technically, you should use the *harmonic mean*, but unless the clusters differ greatly in size, it doesn't make a huge difference.
```

#### Raudenbush and Bryk

```{block type='genericEq', echo=TRUE}
**Raudenbush and Bryk Approximate Formula - Level 2 ** 
$$
approx \; R^2_s = \frac{\sigma^2_{u0-BL} - \sigma^2_{u0-MC}}
             {\sigma^2_{u0-BL} }
\tag{Hox 4.9}
$$
```










## Using $\LaTeX$ for Equation Typesetting


```{block type='rmdlink', echo=TRUE}
R markdown is a user friendly, simplified language that allows for more complex formating utilizing standard $\LaTeX$ code.  A great resource for learning how to many common tasks in $\LaTeX$ is the [Share\LaTeX website](www.sharelatex.com).  

Specific mathematical equation documentation may be found on the [Mathematical  Expressions](https://www.sharelatex.com/learn/Mathematical_expressions) subpage.

There are also many websites that offer Point-n-click interfaces to build $\LaTeX$ equations, including:
[Host Math](http://www.hostmath.com/), 
[Code Cogs](https://www.codecogs.com/latex/eqneditor.php), 
[LaTeX 4 Technics](https://www.latex4technics.com/), and
[Sci-Weavers](http://www.sciweavers.org/free-online-latex-equation-editor)
```

    
    

<!--chapter:end:03-notation.Rmd-->

# Intro 2-level Model Example: Pupil Popularity

![](images/header_hox_popular2.png)

```{r, include=FALSE}
knitr::opts_chunk$set(comment     = "",
                      echo        = TRUE, 
                      warning     = FALSE, 
                      message     = FALSE,
                      fig.align   = "center", # center all figures
                      fig.width   = 6,        # set default figure width to 4 inches
                      fig.height  = 4)        # set default figure height to 3 inches
```

```{r, message=FALSE, error=FALSE}
library(tidyverse)
library(haven)        # read in SPSS dataset
library(furniture)    # nice table1() descriptives
library(stargazer)    # display nice tables: summary & regression
library(texreg)       # Convert Regression Output to LaTeX or HTML Tables
library(RColorBrewer) # nice color palettes for plots
library(gridExtra)    # place ggplots together as one plot
library(psych)        # contains some useful functions, like headTail
library(car)          # Companion to Applied Regression
library(nlme)         # non-linear mixed-effects models
library(lme4)         # Linear, generalized linear, & nonlinear mixed models
library(lmerTest)     # Tests on lmer objects
library(HLMdiag)      # Diagnostic Tools for for nlme & lmer4
library(sjstats)      # ICC calculations
library(optimx)       # Different optimizers to solve mlm's
```



## Background

```{block type='rmdlink', echo=TRUE}
The text **"Multilevel Analysis: Techniques and Applications, Third Edition"** [@hox2017] has a companion [website](https://multilevel-analysis.sites.uu.nl/) which includes links to all the data files used throughout the book (housed on the [book's GitHub repository](https://github.com/MultiLevelAnalysis)).  
```


The following example is used through out @hox2017's chapater 2.

> From **Appendix E**:  
>
> The popularity data in **popular2.sav** are simulated data for **2000 pupils in 100 schools**. The purpose is to offer a very simple example for multilevel regression analysis.  The main outcome variable is the **pupil popularity**, a popularity rating on a scale of 1-10 derived by a sociometric procedure. Typically, a sociometric procedure asks all pupils in a class to rate all the other pupils, and then assigns the average received popularity rating to each pupil.  Because of the sociometric procedure, group effects as apparent from higher level variance components are rather strong. There is a second outcome variable: **pupil popularity** as rated by their teacher, on a scale from 1-10.  The explanatory variables are **pupil gender** (boy=0, girl=1), **pupil extraversion** (10-point scale) and **teacher experience** in years.  The popularity data have been generated to be a 'nice' well-behaved data set: the sample sizes at both levels are sufficient, the residuals have a normal distribution, and the multilevel effects are strong.

![](images/diagram_hox_popular2.png)

```{r}
data_raw <- haven::read_sav("https://github.com/MultiLevelAnalysis/Datasets-third-edition-Multilevel-book/raw/master/chapter%202/popularity/SPSS/popular2.sav") %>% 
  haven::as_factor()             # retain the labels from SPSS --> factor

tibble::glimpse(data_raw) 
```

### Unique Identifiers

We will restrict ourselves to a few of the variables and create a distinct identifier variable for each student.

```{r}
data_pop <- data_raw %>%   
  dplyr::mutate(id = paste(class, pupil,
                           sep = "_") %>%   # create a unique id for each student (char)
                  factor()) %>%             # declare id is a factor
  dplyr::select(id, pupil:popteach)         # reduce the variables included

tibble::glimpse(data_pop)
```


### Structure and variables

Its a good idea to visually inspect the first few lines in the datast to get a sense of how it is organized.

```{r}
data_pop %>%  
  psych::headTail(top = 25, bottom = 5) %>% 
  pander::pander()
```

Visual inspection reveals that most of the variables are measurements at level 1 and apply to specific pupils (`extrav`, `sex`, `popular`, and `popteach`), while the teacher's years of experiene is a level 2 variable since it applies to the entire `class`.  Notice how the `texp` variable is identical for all pupils in the same class.  This is call **Disaggregated** data.


## Exploratory Data Analysis

### Summarize Descriptive Statistics

#### The `stargazer` package

Most posters, journal articles, and reports start with a table of descriptive statistics.  Since it tends to come first, this type of table is often refered to as *Table 1*.  The `stargazer()` function can be used to create such a table, but only for the entire dataset [@R-stargazer].  I haven't been able to find a way to get it to summarize subsamples and compare them in the standard format.

```{r, include=FALSE}
# Knit to Website: type = "html" 
# Knit to PDF:     type = "latex"
# View on Screen:  type = "text"

data_pop %>% 
  dplyr::select(extrav, texp, popular) %>% 
  data.frame() %>% 
  stargazer::stargazer(title  = "Descriptive statistics, aggregate over entire sample",
                       header = FALSE,
                       type = "text")
```

```{r, results='asis'}
# Knit to Website: type = "html" 
# Knit to PDF:     type = "latex"
# View on Screen:  type = "text"

data_pop %>% 
  dplyr::select(extrav, texp, popular) %>% 
  data.frame() %>% 
  stargazer::stargazer(title  = "Descriptive statistics, aggregate over entire sample",
                       header = FALSE,
                       type = "html")
```



#### The `furniture` package

Tyson Barrett's  **furniture** package includes the extremely useful function `table1()` which simplifies the common task of creating a stratified, comparative table of descriptive statistics.  Full documentation can be accessed by executing `?furniture::table1`.    

```{r, results='asis'}
# Knit to Website: output = "html" 
# Knit to PDF:     output = "latex2"
# View on Screen:  output = ""text", or "markdown", "html"

data_pop %>% 
  furniture::table1("Pupil's Extraversion (10 pt)"   = extrav, 
                     "Teacher's Experience (years)"  = texp, 
                     "Popularity, Sociometric Score" = popular, 
                     "Popularity, Teacher Evaluated" = popteach,
                     splitby    = ~ sex,                                     # divide sample into columns by...
                     test       = TRUE,                                      # test groups different?
                     output     = "html",                                    # output for latex
                     caption    = "Compare genders on four main variables")  # title
```



### Visualizations of Raw Data

#### Ignore Clustering

##### Scatterplots

For a first look, its useful to plot all the data points on a single scatterplot as displayed in Figure \@ref(fig:scatter).  Due to ganularity in the rating scale, many points end up being plotted on top of each other (*overplotted*), so its a good idea to use `geom_count()` rather than `geom_point()` so the size of the dot can convey the number of points at that location [@R-ggplot2].

```{r scatter, fig.cap="Disaggregate: pupil level only with extraversion treated as an continuous measure."}
# Disaggregate: pupil (level 1) only, ignore level 2's existance
# Extraversion treated: continuous measure
data_pop %>% 
  ggplot() +
  aes(x = extrav,                                # x-axis variable
      y = popular) +                             # y-axis variable
  geom_count() +                                 # POINTS w/ SIZE = COUNT
  geom_smooth(method = "lm") +                   # linear regression line
  theme_bw() +                                   # white background  
  labs(x    = "Extraversion (10 pt scale)",      # x-axis label
       y    = "Popularity, Sociometric Score",   # y-axis label
       size = "Count") +                         # legend key's title  
  theme(legend.position = c(0.9, 0.2),                          # key at
        legend.background = element_rect(color = "black")) +    # key box 
  scale_x_continuous(breaks = seq(from = 0, to = 10, by = 1)) + # x-ticks
  scale_y_continuous(breaks = seq(from = 0, to = 10, by = 2))   # y-ticks
```

##### Density Plots


When the degree of overplotting as high as it is in Figure \@ref(fig:scatter), it can be useful to represent the data with density contours as seen in Figure \@ref(fig:scatter2d).  I've chosen to leave the points displayed in this redition, but color them much lighter so that they are present, but do not detract from the pattern of association.

```{r scatter2d, fig.cap="Disaggregate: pupil level only with extraversion treated as an continuous measure."}
# visualize all the data - another way
data_pop %>% 
  ggplot() +
  aes(x = extrav,                                # x-axis variable
      y = popular) +                             # y-axis variable
  geom_count(color = "gray") +                   # POINTS w/ SIZE = COUNT
  geom_density2d() +                             # DENSITY CURVES 
  geom_smooth(method = "lm", color = "red") +    # linear regression line
  theme_bw() +                                   # white background  
  labs(x    = "Extraversion (10 pt scale)",      # x-axis label
       y    = "Popularity, Sociometric Score") + # y-axis label 
  guides(size = FALSE)  +                        # don't include a legend
  scale_x_continuous(breaks = seq(from = 0, to = 10, by = 1)) + # x-ticks
  scale_y_continuous(breaks = seq(from = 0, to = 10, by = 2))   # y-ticks
```




The argument could be made that the extraversion score should be treated as an ordinal factor instead of as a truely continuous scale since the only valid values are the whole number 1 through 10 and there is no assurance that these category assignments represent a true ratio measurement scale.  However, we must keep in mind that this was an observational study, ans as such, the number of pupils assignment each level of extraversion is not equal.

```{r, results='asis'}
# count the number of pupils in assigned each Extraversion value, 1:10
table <- data_pop %>% 
  group_by(extrav) %>% 
  summarise(count = n_distinct(id),
            percent  = 100 * count / 2000) 

# Knit to Website: type = "html" 
# Knit to PDF:     type = "latex"
# View on Screen:  type = "text"

table %>% 
  stargazer(summary  = FALSE,
            rownames = FALSE,
            header   = FALSE,
            type     = "html",
            title    = "Distribution of extraversion in pupils")
```


##### Boxplots

Figure \@ref(fig:boxes) displays the same data as Figure \@ref(fig:scatter), but uses boxplots for the distribution of scores at each level of extraversion.  On one extreme, the lowest extraversion score possible was a value of "one", but only `r table[1, "count"] %>% unlist` pupils or `r table[1, "percent"] %>% unlist`% of the 2000 pupils recieved this value.  On the other extreme, the middle value of "five" was applied to `r table[5, "count"] %>% unlist` pupils or a wopping `r table[5, "percent"] %>% unlist`%. The option `varwidth=TRUE` in the `geom_boxplot()` function helps reflect such unbalanced sample sizes by allowing the width of the boxes to be proportional to the square-roots of the number of observations each box represents.

```{r boxes, fig.cap="Disaggregate: pupil level only with extraversion treated as an ordinal factor.  The width of the boxes are proportional to the square-roots of the number of observations each box represents."}
# Disaggregate: pupil (level 1) only, ignore level 2's existance
# Extraversion treated: ordinal factor
ggplot(data_pop,                        # dataset's name
       aes(x    = factor(extrav),       # x-axis values - make factor!
           y    = popular,              # y-axis values
           fill = factor(extrav))) +    # makes seperate boxes
  geom_boxplot(varwidth = TRUE) +       # draw boxplots instead of points
  theme_bw() +                          # white background  
  guides(fill = FALSE)  +               # don't include a legend
  scale_y_continuous(breaks = seq(from = 0, to = 10, by = 2)) +  # y-ticks
  labs(x = "Extraversion (10 pt scale)",                    # x-axis label
       y = "Popularity, Sociometric Score") +               # y-axis label
  scale_fill_brewer(palette = "Spectral", direction = 1)    # select color
```


### Consider Clustering

#### Scatterplots


Up to this point, all investigation of this dataset has been only at the pupil level and any nesting or clustering within classes has been ignored.  Plotting is a good was to start to get an idea of the class-to-class variability.  

```{r scatter3x3, fig.cap="Illustration of the degree of class level variability in the association between extraversion and popularity. Each panel represents a class and each point a pupil in that class.  First nice classes shown."}
# compare the first 9 classrooms becuase all of there are too many at once
data_pop %>% 
  dplyr::filter(class <= 9) %>%                  # select ONLY NINE classes
  ggplot(aes(x = extrav,                         # x-axis values
             y = popular)) +                     # y-axis values
  geom_count() +                                 # POINTS w/ SIZE = COUNT
  geom_smooth(method = "lm", color = "red") +    # linear regression line
  theme_bw() +                                   # white background  
  labs(x    = "Extraversion (10 pt scale)",      # x-axis label
       y    = "Popularity, Sociometric Score",   # y-axis label
       size = "Count") +                         # legend key's title  
  guides(size = FALSE)  +                        # don't include a legend
  scale_x_continuous(breaks = seq(from = 0, to = 10, by = 3)) + # x-ticks
  scale_y_continuous(breaks = seq(from = 0, to = 10, by = 3)) + # y-ticks
  facet_wrap(~ class, 
             labeller = label_both) +
  theme(strip.background = element_rect(colour = NA, 
                                        fill   = NA))
```





```{r scatter3x3b, fig.cap="Illustration of the degree of class level variability in the association between extraversion and popularity. Each panel represents a class and each point a pupil in that class.  A set of nine classes was chosen to show a sampling of variability.  The facet labels are not shown as the identification number probably would not be advisable for a general publication."}
# select specific classes by number for illustration purposes
data_pop %>% 
  dplyr::filter(class %in% c(15, 25, 33, 
                             35, 51, 64, 
                             76, 94, 100)) %>% 
  ggplot(aes(x = extrav,                         # x-axis values
             y = popular)) +                     # y-axis values
  geom_count() +                                 # POINTS w/ SIZE = COUNT
  geom_smooth(method = "lm", color = "red") +    # linear regression line
  theme_bw() +                                   # white background  
  labs(x    = "Extraversion (10 pt scale)",      # x-axis label
       y    = "Popularity, Sociometric Score",   # y-axis label
       size = "Count") +                         # legend key's title  
  guides(size = FALSE)  +                        # don't include a legend
  scale_x_continuous(breaks = seq(from = 0, to = 10, by = 3)) + # x-ticks
  scale_y_continuous(breaks = seq(from = 0, to = 10, by = 3)) + # y-ticks
  facet_wrap(~ class)  +
  theme(strip.background = element_blank(),
        strip.text       = element_blank())
```

#### Cluster-wise Regression


```{r classLMs, fig.cap="Spaghetti plot of seperate, independent linear models for each of the 100 classes."}
# compare all 100 classrooms via linear model for each
ggplot(data_pop,
       aes(x     = extrav,                      # x-axis values
           y     = popular,                     # y-axis values
           group = class)) +                     # GROUPs for LINES
  geom_smooth(method = "lm",                     # linear regression line
              color  = "gray40",
              size   = 0.4,
              se     = FALSE) + 
  theme_bw() +                                   # white background  
  labs(x    = "Extraversion (10 pt scale)",      # x-axis label
       y    = "Popularity, Sociometric Score") + # y-axis label
  scale_x_continuous(breaks = seq(from = 0, to = 10, by = 2)) + # x-ticks
  scale_y_continuous(breaks = seq(from = 0, to = 10, by = 2))   # y-ticks
```


```{block type='rmdlink', echo=TRUE}
A helpful resource for choosing colors to use in plots: [R color cheatsheet](https://www.nceas.ucsb.edu/~frazier/RSpatialGuides/colorPaletteCheatsheet.pdf)
```




```{r classLMs3x2, fig.cap="Spaghetti plot of seperate, independent linear models for each of the 100 classes.  Seperate panels are used to untangle the 'hairball' in the previous figure.  The columns are seperated by the pupils' gender and the rows by the teacher's experince in years."}
# compare all 100 classrooms via independent linear models
data_pop %>% 
  dplyr::mutate(texp3 = cut(texp, 
                            breaks = c(0, 10, 18, 30)) %>% 
                  factor(labels = c("< 10 yrs", 
                                    "10 - 18 yrs", 
                                    "> 18 yrs"))) %>% 
  ggplot(aes(x     = extrav,                     # x-axis values
             y     = popular,                    # y-axis values
             group = class)) +                   # GROUPs for LINES
  geom_smooth(aes(color = sex),
              size   = 0.3,
              method = "lm",                     # linear regression line
              se     = FALSE) + 
  theme_bw() +                                   # white background  
  labs(x    = "Extraversion (10 pt scale)",      # x-axis label
       y    = "Popularity, Sociometric Score") + # y-axis label
  guides(color = FALSE) +                        # don't include a legend
  scale_x_continuous(breaks = seq(from = 0, to = 10, by = 3)) + # x-ticks
  scale_y_continuous(breaks = seq(from = 0, to = 10, by = 3)) + # y-ticks
  scale_color_manual(values = c("dodgerblue", "maroon1")) +
  facet_grid(texp3 ~ sex) 
```






## Single-level Regression Analysis


### Null Model

> In a Null, intercept-only, or Empty model, no predictors are included.

#### Equations

```{block type='genericEq', echo=TRUE}
**Single-Level Regression Equation - Null Model**
$$
\overbrace{POP_{ij}}^{Outcome} = 
         \underbrace{\beta_{0}}_{\text{Fixed}\atop\text{intercept}}  + 
         \underbrace{e_{ij}}_{\text{Random}\atop\text{residuals}} 
$$
```

#### Parameters

|  Type  | Parameter of Interest           | Estimates This |
|--------|:--------------------------------|----------------|
| Fixed  | Intercept                       | $\beta_{0}$    |
| Random | Residual Variance $var[e_{ij}]$ | $\sigma^2_{e}$ |


#### Fit the Model

```{r}
pop_lm_0 <- lm(popular ~ 1,        #  The 1 represents the intercept
               data = data_pop) 

summary(pop_lm_0)
```

$\hat{\beta_0}$ = `r coef(pop_lm_0) %>% round(2)` is the grand mean

#### Model Fit

Residual variance:
```{r}
sigma(pop_lm_0)    # standard deviation of the residuals
sigma(pop_lm_0)^2  # variance of the residuals
```

$\hat{\sigma_e^2}$ = `r sigma(pop_lm_0)^2 %>% round(4)` is residual variance (`RMSE` is sigma = `r sigma(pop_lm_0) %>% round(4)`)



Variance Explained:
```{r}
summary(pop_lm_0)$r.squared
```

$R^2$ = `r 0` is the proportion of variance in popularity that is explained by the grand mean alone.

Deviance:
```{r}
-2 * logLik(pop_lm_0)
```



#### Interpretation

The grand average popularity of all pupils in all the classes is `r coef(pop_lm_0) %>% round(2)`, and there is strong evidence that it is statistically significantly different than zero, $p<.0001$.  The mean alone accounts for none of the variance in popularity.  The residual variance is the same as the total variance in popularity, `r sigma(pop_lm_0)^2 %>% round(4)`.


Just to make sure...

```{r}
mean(data_pop$popular)
var(data_pop$popular)
```



### Add Predictors to the Model

#### Equations

> LEVEL 1: Student-specific predictors:    
>
> * $X_1 = GEN$, pupils's gender *(girl vs. boy)*
> * $X_2 = EXT$, pupil's extraversion *(scale: 1-10)*

```{block type='genericEq', echo=TRUE}
**Single-Level Regression Equation** 
$$
\overbrace{POP_{ij}}^{Outcome} = 
         \underbrace{\beta_{0}}_{\text{Fixed}\atop\text{intercept}}  + 
         \underbrace{\beta_{1}}_{\text{Fixed}\atop\text{slope}} \overbrace{GEN_{ij}}^{\text{Predictor 1}}  + 
         \underbrace{\beta_{2}}_{\text{Fixed}\atop\text{slope}} \overbrace{EXT_{ij}}^{\text{Predictor 2}} + 
         \underbrace{e_{ij}}_{\text{Random}\atop\text{residuals}} 
\tag{Hox 2.1}
$$
```

#### Parameters

|  Type  | Parameter of Interest           | Estimates This |
|--------|:--------------------------------|----------------|
| Fixed  | Intercept                       | $\beta_{0}$    |
| Fixed  | Slope or effect of `sex`        | $\beta_{1}$    |
| Fixed  | Slope or effect of `extrav`     | $\beta_{2}$    |
| Random | Residual Variance $var[e_{ij}]$ | $\sigma^2_{e}$ |


#### Fit the Model

```{r}
pop_lm_1 <- lm(popular ~ sex + extrav,    # implies: 1 + sex + extrav
               data = data_pop) 

summary(pop_lm_1)
```

$\hat{\beta_0}$ = `r coef(pop_lm_1)[1] %>% round(2)` is the extrapolated mean for boys with an extroversion score of 0.   
$\hat{\beta_1}$ = `r coef(pop_lm_1)[2] %>% round(2)` is the mean difference between girls and boys with the same extroversion score.    

$\hat{\beta_2}$ = `r coef(pop_lm_1)[3] %>% round(2)` is the mean difference for pupils of the same gender that differ in extroversion by one point.    

#### Model Fit

Residual variance:
```{r}
sigma(pop_lm_1)    # standard deviation of the residuals
sigma(pop_lm_1)^2  # variance of the residuals
```

$\hat{\sigma_e^2}$ = `r sigma(pop_lm_1)^2 %>% round(4)` is residual variance (`RMSE` is sigma)



Variance Explained:
```{r}
summary(pop_lm_1)$r.squared
```

Deviance:
```{r}
-2 * logLik(pop_lm_1)
```


$R^2$ = `r summary(pop_lm_1)$r.squared %>% round(3)` is the proportion of variance in popularity that is explained by tha pupils gender and extroversion score.


#### Interpretation

On average, girls were rated `r coef(pop_lm_1)[2] %>% round(2)` points more popular than boys with the same extroversion score, $p<.0001$.  One point higher extroversion scores were associated with `r coef(pop_lm_1)[3] %>% round(2)` points higher popularity, within each gender, $p<.0001$.  Together, these two factors account for `r 100 * summary(pop_lm_1)$r.squared %>% round(4)`% of the variance in populartiy.

### Compare Fixed Effects

#### Compare Nested Models

Create a table to compare the two nested models:

```{r lmtable, results='asis'}
# Knit to Website: texreg::htmlreg()
# Knit to PDF:     texreg::texreg()
# View on Screen:  texreg::screenreg()

texreg::htmlreg(list(pop_lm_0, 
                     pop_lm_1),
                custom.model.names = c("Null Model",
                                       "With Predictors"),
                caption            = "Single Level Models",
                caption.above      = TRUE,
                single.row         = TRUE)
```

```{block type='rmdlightbulb', echo=TRUE}
When comparing the fit of two single-level models fit via the `lm()` function, the `anova()` function runs an F-test where the test statistic is the difference in RSS.
```

```{r}
anova(pop_lm_0, pop_lm_1)
```


Obviously the model with predictors fits better than the model with no predictors.


#### Terminology

The following terminology applies to single-level models fit with ordinary least-squared estimation (the `lm()` function in $R$).  Values are calculated below for the NULL model.

* **Mean squared error (MSE)** is the MEAN of the square of the residuals:

```{r}
mse <- mean(residuals(pop_lm_0)^2)
mse
```

*  **Root mean squared error (RMSE)** which is the SQUARE ROOT of MSE:

```{r}
rmse <- sqrt(mse)
rmse
```

* **Residual sum of squares (RSS)** is the SUM of the squared residuals:

```{r}
rss <- sum(residuals(pop_lm_0)^2)
rss
```

* **Residual standard error (RSE)** is the SQUARE ROOT of (RSS / degrees of freedom):

```{r}
rse <- sqrt( sum(residuals(pop_lm_0)^2) / pop_lm_0$df.residual ) 
rse
```

The same calculation, may be simplified with the previously calculated RSS:

```{r}
sqrt(rss / pop_lm_0$df.residual)
```


```{block type='rmdimportant', echo=TRUE}
When the 'deviance()' function is applied to a single-level model fit via 'lm()', the Residual sum of squares (RSS) is returned, not the deviance as defined as twice the negative log likelihood (-2LL).
```

```{r}
deviance(pop_lm_0)  # returns the RSS, not deviance = -2LL
```

```{r}
-2 * logLik(pop_lm_0)  # this is how get deviance = -2LL
```


## Multi-level Regression Analysis



### Intercept-only or Null Model

> In a Null, intercept-only, or Empty model, no predictors are included.


```{block type='rmdlightbulb', echo=TRUE}
 "The intercept-only model is useful as a null-model that serves as a benchmark with which other models are compared." @hox2017, page 13
```




#### Equations


**Level 1 Model Equation:**

$$
\overbrace{Y_{ij}}^{Outcome} = 
         \underbrace{\beta_{0j}}_{\text{Level 2}\atop\text{intercepts}}  + 
         \underbrace{e_{ij}}_{\text{Random}\atop\text{residuals}}
\tag{Hox 2.6}
$$

**Level 2 Model Equation:**    

$$
\overbrace{\beta_{0j}}^{\text{Level 2}\atop\text{intercepts}} = 
      \underbrace{\gamma_{00}}_{\text{Fixed}\atop\text{intercept}} + 
      \underbrace{u_{0j}}_{\text{Random}\atop\text{intercepts}}
\tag{Hox 2.7}
$$



Substitute equation (2.7) into equation (2.6):

```{block type='genericEq', echo=TRUE}
**Combined, Multilevel Model Equation - Null Model**
$$ 
\overbrace{Y_{ij}}^{Outcome} = 
    \underbrace{\gamma_{00}}_{\text{Fixed}\atop\text{intercept}} + 
    \underbrace{u_{0j}}_{\text{Random}\atop\text{intercepts}} + 
    \underbrace{e_{ij}}_{\text{Random}\atop\text{residuals}}
\tag{Hox 2.8}
$$
```




#### Parameters

|  Type  | Parameter of Interest                        | Estimates This  |
|--------|:---------------------------------------------|-----------------|
| Fixed  | Intercept                                    | $\gamma_{00}$   |
| Random | Variance in random intercepts, $var[u_{0j}]$ | $\sigma^2_{u0}$ | 
| Random | Residual Variance $var[e_{ij}]$              | $\sigma^2_{e}$  |    


 
@hox2017 labeled the Null model for this dataset "$M_0$" in chapter 2:


```{block type='genericEq', echo=TRUE}
**Combined, Multilevel Model Equation - Popularity,** Random Intercepts Only!
$$ 
\overbrace{POP_{ij}}^{Outcome} = 
    \underbrace{\gamma_{00}}_{\text{Fixed}\atop\text{intercept}} + 
    \underbrace{u_{0j}}_{\text{Random}\atop\text{intercepts}} + 
    \underbrace{e_{ij}}_{\text{Random}\atop\text{residuals}}
\tag{M0: intercept only}
$$

```


#### Fit the Model

Fit the model to the data.

```{r}
pop_lmer_0_re <- lme4::lmer(popular ~ 1 + (1|class),  # include a fixed and random intercept
                            data = data_pop,
                            REML = TRUE)             # fit via REML (the default) for ICC calculations

summary(pop_lmer_0_re)
```


```{block type='rmdimportant', echo=TRUE}
**Estimation Methods**

Multilevel models may be fit by various methods.  The most commonly used (and availabel in 'lme4') optimize various criterions: Maximum Likelihood *(ML)* -or- Restricted Maximum Likelihood *(REML)*.  @hox2017 discusses these and other methods in chapter 3.  At the end of chapter 2, the authors' second note staes that the details of estimation methods are glossed over in the current example in an effort to simplfy the introductory.  Here we follow these guidelines:

* Use **ML** for fitting:
    + nested models that differ only by inclusion/exclusion of FIXED effects, to test parameter significance via a likelihood ratio test   
    
* Use **REML** for fitting: 
    + the NULL model, on which to base ICC calculations
    + nested models that differ only by inclusion/exclusion of RANDOM effects, to test parameter significance via a likelihood ratio test   
    + the FINAL model
    
This often leads to refitting identical models via BOTH estimation methods.    
```

#### Interpretation

The grand average popularity of all students is `r pop_lmer_0_re %>% fixef() %>% round(4)` and the class averages tend to vary by about 0.8333 points above or below that.




### Intraclass Correlation (ICC)

Although the Null model above does not explain any variance in the dependent variable *(popularity)*, since there are no independent variables, it does decompose (i.e. divide up) the variance into two pieces.  We can compute the amount of total variance in popularity that is attribute to the clustering of students in classes verses the residual variance.


```{block type='genericEq', echo=TRUE}
**Intraclass Correlation (ICC) Formula**
$$
\overbrace{\rho}^{\text{ICC}} = 
\frac{\overbrace{\sigma^2_{u0}}^{\text{Random Intercept}\atop\text{Variance}}}
     {\underbrace{\sigma^2_{u0}+\sigma^2_{e}}_{\text{Total}\atop\text{Variance}}}
\tag{Hox 2.9}
$$

```



```{block type='rmdlightbulb', echo=TRUE}
The `VarCorr()` function in the `lme4` package returns the standard deviations, not the variances ($var = SD^2$) for a model fit via the `lme4::lmer()` function.  The `summary()` function reports both the variances and the stadard deviations.
```


```{r}
lme4::VarCorr(pop_lmer_0_re)   # extract random compondent: varrainces and correlations
```

```{r}
sjstats::re_var(pop_lmer_0_re)
```


$$
\begin{align*}
\text{classes}      \rightarrow \; & \sigma^2_{u0} = 0.83792^2 = 0.702\\
\text{pupils within classes}      \rightarrow \; & \sigma^2_{e}  = 1.10535^2 = 1.222\\
\end{align*}
$$

#### By Hand

Calculate the ICC by hand:

$$
\overbrace{\rho}^{\text{ICC}} 
     = 
\frac{\overbrace{\sigma^2_{u0}}^{\text{Random Intercept}\atop\text{Variance}}}
     {\underbrace{\sigma^2_{u0}+\sigma^2_{e}}_{\text{Total}\atop\text{Variance}}} 
     = \frac{0.702}
            {0.702+1.222} 
     = \frac{0.702}
            {1.924}
     = 0.3648649
$$

```{r}
0.702 / (0.702 + 1.222)
```




#### The `sjstats` package

Calculate the ICC with the `icc()` fucntion in the `sjstats` package:

```{r}
sjstats::icc(pop_lmer_0_re)
```

#### Interpretation

WOW!  36.5% of the variance of the popularity scores is at the group level, which is very high for social science data.  


```{block type='rmdimportant', echo=TRUE}
The ICC should be based on a Null (intercept only) model fit via REML (restricted maximum likelihood) estimation.  This is the default for the 'lme4::lmer()' function.  In chapter 2, @hox2017 presents the numbers based on fitting the model via ML (maximum likelihood) estimation and thus does not match the presentation above exactly *(not just rounding error)*.  This is because: (1) estimation methods (REML & ML) are not discussed until chapter 3 and (2) due to the Null model also being used for model fit comparisons in Table 2.1 on the top of page 14.  Here we will fit the empty model twice, above by ML and below by REML
```


### Add Predictors to the Model

@hox2017 labeled this as "$M_1$" in chapter 2 for their Table 2.1 (page 14), but adjusted it for Tables 2.2 (page 15) and 2.3 (page 17).


> LEVEL 1: Student-specific predictors:    
>
> * $X_1 = GEN$, pupils's gender *(girl vs. boy)*
> * $X_2 = EXT$, pupil's extraversion *(scale: 1-10)*

> LEVEL 2: Class-specific Predictors:
> 
> * $Z = YRS$, teacher's experience *(range of 2-25 years)*


#### Equations

**Level 1 Model Equation:**

Include main effects for `sex` and `extrav` 

$$
\overbrace{POP_{ij}}^{Outcome} = 
    \underbrace{\beta_{0j}}_{\text{Level 2}\atop\text{intercept}} + 
    \underbrace{\beta_{1j}}_{\text{Level 2}\atop\text{slopes}} 
    \overbrace{GEN_{ij}}^{\text{Level 1}\atop\text{Predictor 1}} + 
    \underbrace{\beta_{2j}}_{\text{Level 2}\atop\text{slopes}} 
    \overbrace{EXT_{ij}}^{\text{Level 1}\atop\text{Predictor 2}} + 
    \underbrace{e_{ij}}_{\text{Random}\atop\text{residuals}}
$$
   
**Level 2 Model Equations:** 

Include a random intercepts and random slopes for both for `sex` and `extrav`, but **NO** cross level interactions for now.  

We will assume this is due to some theoretical reasoning to be our starting point after the fitting of the null model.

* Random Intercepts:

$$
\overbrace{\beta_{0j}}^{\text{Level 2}\atop\text{intercepts}} = 
     \underbrace{\gamma_{00}}_{\text{Fixed}\atop\text{intercept}}  + 
     \underbrace{\gamma_{01}}_{\text{Fixed}\atop\text{slope } Z}
     \overbrace{YRS_{j}}^{\text{Level 2}\atop\text{Predictor 3}}  + 
     \underbrace{u_{0j}}_{\text{Intercept}\atop\text{residual}} 
$$  


* Random Slopes, for the first predictor, `sex`:

$$
\overbrace{\beta_{1j}}^{\text{Level 2}\atop\text{slopes}} = 
     \underbrace{\gamma_{10}}_{\text{Fixed}\atop\text{Slope  } X_1}  + 
     \underbrace{u_{1j}}_{\text{Slope } X_1\atop\text{residual}} 
$$


* Random Slopes, for the second predictor, `extrav`:

$$
\overbrace{\beta_{2j}}^{\text{Level 2}\atop\text{slopes}} = 
     \underbrace{\gamma_{20}}_{\text{Fixed}\atop\text{Slope  } X_2}  + 
     \underbrace{u_{2j}}_{\text{Slope } X_2\atop\text{residual}} 
$$




Substitute the level 2 equations into the level 1 equation:

```{block type='genericEq', echo=TRUE}
**Combined, Multilevel Model Equation - Popularity,** Include Predictors (no cross-level interactions)
$$
\overbrace{POP_{ij}}^{Outcome}
        = \overbrace{\gamma_{00} + 
                      \gamma_{10} GEN_{ij} + 
                      \gamma_{20} EXT_{ij} + 
                      \gamma_{01} YRS_{j}}^{\text{Fixed part}\atop\text{Deterministic}} + \\
         \underbrace{u_{0j} + u_{1j} GEN_{ij} + u_{2j} EXT_{ij} + e_{ij} }_{\text{Random part}\atop\text{Stochastic}}
\tag{M1}
$$
```


#### Parameters

|  Type  | Parameter of Interest                       | Estimates This |
|--------|:--------------------------------------------|----------------|
| Fixed  | Intercept                                   | $\gamma_{00}$  |
| Fixed  | Main Effect of `sex`                        | $\gamma_{10}$  |
| Fixed  | Main Effect of `extrav`                        | $\gamma_{20}$  |
| Fixed  | Main Effect of `texp`                          | $\gamma_{01}$  |
| Random | Variance in random intercepts, $var[u_{0j}]$     | $\sigma^2_{u0}$ | 
| Random | Variance in random slope of `sex`, $var[u_{1j}]$ | $\sigma^2_{u1}$ | 
| Random | Variance in random slope of `extrav`, $var[u_{2j}]$ | $\sigma^2_{u2}$ | 
| Random | Covariance between random intercepts and random slope of `sex`, $cov[u_{0j}, u_{1j}]$ | $\sigma^2_{u01}$ |
| Random | Covariance between random intercepts and random slope of `extrav`, $cov[u_{0j}, u_{2j}]$ | $\sigma^2_{u02}$ |
| Random | Covariance between random slopes of `sex` and `extrav`,  $cov[u_{1j}, u_{2j}]$           | $\sigma^2_{u12}$ | 
| Random | Residual Variance $var[e_{ij}]$                 | $\sigma^2_{e}$ |    



```{block type='rmdimportant', echo=TRUE}
Troubleshooting 'lme4' Linear Mixed-Effects Models [website](https://rdrr.io/cran/lme4/man/troubleshooting.html).  This website attempts to summarize some of the common problems with fitting lmer models and how to troubleshoot them.

This is a helpful [post on Stack Exchange](https://stats.stackexchange.com/questions/242109/model-failed-to-converge-warning-in-lmer) regarding using differen t optimizers to get the 'lme4::lmer()' function to converge.  

Note: Convergence issues MAY signify problems in the model specification.
```


  
#### Fit the Model
  
```{r, echo=TRUE}
pop_lmer_0_ml <- lme4::lmer(popular ~ 1 + (1|class), 
                            data   = data_pop,
                            REML   = FALSE)        # refit via ML to compare the model below to 


pop_lmer_1_ml <- lme4::lmer(popular ~ sex + extrav + texp + (sex + extrav|class), 
                            data   = data_pop,
                            REML   = FALSE,
                            control = lmerControl(optimizer ="Nelder_Mead")) #helps converge

summary(pop_lmer_1_ml)
```

#### Interpretation

After accounting for the heiarchical nesting of students in classes, girls were rated `r fixef(pop_lmer_1_ml)[2] %>% round(2)` points more popular on average, than boys with the same extroversion score.  One point higher extroversion scores were associated with `r fixef(pop_lmer_1_ml)[3] %>% round(2)` points higher popularity, within each gender. 

Reproduce Table 2.1 on the top of page 14 [@hox2017]

```{r, results='asis'}
# Knit to Website: texreg::htmlreg()
# Knit to PDF:     texreg::texreg()
# View on Screen:  texreg::screenreg()

texreg::htmlreg(list(pop_lm_0, 
                     pop_lmer_0_ml, 
                     pop_lmer_1_ml),
                custom.model.names = c("Single-level", 
                                       "M0: int only", 
                                       "M1: w pred"),
                caption            = "Hox Table 2.1 on the top of page 14",
                caption.above      = TRUE,
                single.row         = TRUE)
```




The regression tables from the `texreg` package include estimates of the covariances between random components.

>"These covarianes are rarely interpreted *(for an exception see Chapter 5 and Chapter 16 where growth models are discussed)*, and for that reason they are often not included in the reported tables.  However, as Table 2.2 demonstrates, they can be quite large adn significant, so as a rule they are always included in the model."
>
> @hox2017, Chapter 2, pages 15-16


```{block type='rmdlightbulb', echo=TRUE}
**Comparing Model Fit**

1. Residual Variance in the Residuals

* In single-level regression, the Root Mean Squared Error (RMSE) is usually reported.  It is the standard deviation of the residuals and is called "Residual standard error" in the R output of `summary()` function applied to an model fit via `lm`.
* In multi-level regression, residual variance is reported as $\sigma_e^2$.

$$
{\text{RMSE}}^2 = MSE = \sigma_e^2
$$


2. Deviance

* In single-level regression, the model is fit in such a way as to make the sum of the squared residuals as small as possible.  Deviance is the sum of the squared residuals.

* In multi-level regression, the model is fit via a method called 'Maximum Likelihood'.

$$
\text{Deviance} = -2LL = -2 \times log(likelihood)
$$
```




### Testing Random Components

In Hox's table 2.1 (page 14) we see that the MLM with predictors ($M_0$) includes a random compondnt with virtually no variance.  This is likely why the model didn't easily converge (a different optimizer was employed).  It makes sence to remove the random slope component for gender and refit the model.  While we are at it, we will also fit a third model dropping the second random slope component for extraversion.

#### Fit Nested Models

Since we are going to compare models that are nested on random effects *(identical except for inclusing/exclusing of  random components*, we will specify the `REML = TRUE` option.

```{r}
pop_lmer_1_re <- lme4::lmer(popular ~ sex + extrav + texp + (sex + extrav|class), 
                            data  = data_pop,
                            REML  = TRUE,
                            control = lmerControl(optimizer ="Nelder_Mead")) #helps converge

pop_lmer_1a_re <- lme4::lmer(popular ~ sex + extrav + texp + (extrav|class), 
                             data = data_pop,
                             REML = TRUE)

pop_lmer_1b_re <- lme4::lmer(popular ~ sex + extrav + texp + (1 |class), 
                             data = data_pop,
                             REML = TRUE) 
```



Create a table to compare the three nested models:

The middle column below reproduces Hox's Table 2.2 found on the bottom of page 15 [@hox2017], except the values differ slightly becuase here the model was fit via `REML` where as in the text, Hox used `ML`.

```{r, results='asis'}
# Knit to Website: texreg::htmlreg()
# Knit to PDF:     texreg::texreg()
# View on Screen:  texreg::screenreg()

texreg::htmlreg(list(pop_lmer_1_re, pop_lmer_1a_re, pop_lmer_1b_re),
                custom.model.names = c("M1", "M1a", "M1b"),
                caption            = "Assessing Significance of Random Slopes",
                caption.above      = TRUE,
                single.row         = TRUE)
```


#### Compare Fit

```{block type='rmdlightbulb', echo=TRUE}
**Likelihood Ratio Test (LRT) of Nested MLM Models**

When comparing the fit of two multi-level models fit via the `lme::lmer()` function, the `anova()` function runs an Chi-squared test where the test statistic is the difference in -2LL (deviances).  
```

```{block type='rmdimportant', echo=TRUE}
**Likelihood Ratio Test (LRT) for Random Effects**

When using the 'anova()' function to conduct a LRT for RANDOM effects, make sure:

1. the nested models have identical FIXED effects
  + never test models that differ in fixed and random effects at the same time

2. the models were fit with 'REML = TRUE'
  +  this results in the best variance/covariance component estimation
  
2. add the 'refit = FALSE' option to the 'anova()' call
  + without this $R$ re-runs the models with 'REML = FALSE' for you

```


* Investigate dropping the random slope component for `sex`

These two models are identical, except for the inclusing/exclusion of the random specification of the level 1 `sex` predictor.  Note, both models were fit with REML.  Although we are dropping only ONE variance component, we are also dropping TWO covariances (`sex` paired with both the random intercept and random slope for `extrav`).  This results in a $\chi^2$ test with THREE degrees of freedom.

```{r}
anova(pop_lmer_1_re, pop_lmer_1a_re, refit = FALSE)  # don't let it refit the models via LM
```

The NON-significance likelihood ratio test (LRT: $\chi^2(3) = 1.51$, $p = .679$) conveys that the more complex model does NOT fit the data better.  Thus the more SIMPLE model does just as good of a job.  This is evidence for the EXCLUSION of `sex` as a random component.



* Investigate dropping the random slope component for `extrav`

These two models are identical, except for the inclusing/exclusion of the random specification of the level 1 `extrav` predictor.  Note, both models were fit with REML.  Although we are dropping only ONE variance component, we are also dropping ONE covariances (`extrav` paired with the random intercept).  This results in a $\chi^2$ test with TWO degrees of freedom.

```{r}
anova(pop_lmer_1a_re, pop_lmer_1b_re, refit = FALSE)  # don't let it refit the models via LM
```

The significance likelihood ratio test (LRT: $\chi^2(2) = 50.26$, $p < .0001$) conveys that the more complex model DOES fit the data better.  Thus the more COMPLEX model does just as good of a job.  This is evidence for the INCLUSION of `extrav` as a random component.




### Testing Cross-Level Interactions

We have already seen formulas of this form for a NULL or emply models, as well as for intercept implied models of main effects:    

* intercept only 
    + `Y ~ 1` 

* intercept implied  
    + `Y ~ A` = `Y ~ 1 + A` 
    + `Y ~ A + B` = `Y ~ 1 + A + B`

```{block type='rmdlightbulb', echo=TRUE}
**Including Interactions in Formulas**

If we wish to include an **interaction** between the two predictors, we signify this with a colon (:) between the two predictor names.  A **shortcut** may also be employed to signify the including of the main effects and the interaction at the same time by placing an astric (*) between the two variable names.  Both of the following specify the outcome is being predicted by an intercept (implied), the main effects for 2 predictors, and the interaction between the two predictors

* `Y ~ A + B + A:B` 
* `Y ~ A*B`
```

Examples    

* 2-way: `A*B`     = `A + B + A:B`
* 3-way: `A*B*C`   = `A + B + C + A:B + A:C + B:C + A:B:C`
* 4-way: `A*B*C*D` = `A + B + C + D + A:B + A:C + A:D + B:C + B:D + A:B:C + A:B:D+ A:C:D + B:C:D + A:B:C:D`


#### Fit Nested Models


> "Given the significant variance of the regression coefficient of pupil extraversion across the classes, it is attractive to attempt to predict its variation using class-level variables.  We have one class-level variable: teacher experience."
>
> @hox2017, Chapter 2, page 16

Now that we wish to compare nested that will differ only in terms of the inclusing/exclusion of a FIXED effect, the estimation method should be standard maximum likelihood (`REML = FALSE`).


```{r}
pop_lmer_1a_ml <- lme4::lmer(popular ~ sex + extrav + texp + (extrav|class), # main effects only
                             data = data_pop,
                             REML = FALSE)

pop_lmer_2_ml  <- lme4::lmer(popular ~ sex + extrav*texp + (extrav|class), # include cross-level interaction
                             data = data_pop,
                             REML = FALSE)

pop_lmer_3_ml  <- lme4::lmer(popular ~ extrav*texp + sex*texp + sex*extrav +  (extrav|class),  
                             data = data_pop,
                             REML = FALSE)

pop_lmer_4_ml  <- lme4::lmer(popular ~ extrav*texp*sex + (extrav|class),  
                             data = data_pop,
                             REML = FALSE)
```

Create a table to compare the two nested models:

```{r, include=FALSE}
texreg::screenreg(list(pop_lmer_1a_ml, pop_lmer_2_ml))
```


```{r, results='asis'}
# Knit to Website: texreg::htmlreg()
# Knit to PDF:     texreg::texreg()
# View on Screen:  texreg::screenreg()

texreg::htmlreg(list(pop_lmer_1a_ml, pop_lmer_2_ml),
                custom.model.names = c("M1a: Main Effects",
                                       "M2: With Interaction"),
                caption            = "Hox Table 2.3 on page 17",
                caption.above      = TRUE,
                single.row         = TRUE)
```


Investigate further interactions, not shown in by @hox2017.

```{r, include=FALSE}
texreg::screenreg(list(pop_lmer_1a_ml, pop_lmer_2_ml, pop_lmer_3_ml, pop_lmer_4_ml))
```



```{r, results='asis'}
# Knit to Website: texreg::htmlreg()
# Knit to PDF:     texreg::texreg()
# View on Screen:  texreg::screenreg()

texreg::htmlreg(list(pop_lmer_1a_ml, pop_lmer_2_ml, pop_lmer_3_ml, pop_lmer_4_ml),
                custom.model.names = c("M1a: Main Effects",
                                       "M2: With Interaction",
                                       "Add 2-way Inter",
                                       "Add 3-way Interaction"),
                caption            = "Hox Table 2.3 on page 17",
                caption.above      = TRUE,
                single.row         = TRUE)
```



#### Compare Fit

Since these two models only differe by the inclusing/exclusing of a FIXED effect, they both employed `ML` estimation.  Thus we do not need worry about the `anova()` function refitting the models prior to conduction the LRT. 

```{r}
anova(pop_lmer_1a_ml, pop_lmer_2_ml)
```

The significance likelihood ratio test (LRT: $\chi^2(1) = 65.18$, $p < .0001$) conveys that the more complex model DOES fit the data better.  Thus the more COMPLEX model does just as good of a job.  This is evidence for the INCLUSION of cross-level interaction between `extrav` and `texp` as a fixed component.


```{r}
anova(pop_lmer_2_ml, pop_lmer_3_ml)
```

The significance likelihood ratio test (LRT: $\chi^2(2) = 2.46$, $p=.293$) conveys that the more complex model does NOT fit the data better.  Thus the more SIMPLE model does just as good of a job.  This is evidence for the EXCLUSION of the additional 2-way interactions as a fixed components.


```{r}
anova(pop_lmer_2_ml, pop_lmer_4_ml)
```

The significance likelihood ratio test (LRT: $\chi^2(3) = 3.36$, $p=.339$) conveys that the more complex model does NOT fit the data better.  Thus the more SIMPLE model does just as good of a job.  This is evidence for the EXCLUSION of the additional 3-way interactions as a fixed components.

### Final Model

#### Refit with REML

```{r}
pop_lmer_2_re  <- lme4::lmer(popular ~ sex + extrav*texp + (extrav|class), 
                             data = data_pop,
                             REML = TRUE)       # re-fit the final model via REML
```

#### Parameters

```{r, results='asis'}
# Knit to Website: texreg::htmlreg()
# Knit to PDF:     texreg::texreg()
# View on Screen:  texreg::screenreg()

texreg::htmlreg(list(pop_lmer_2_ml),
                custom.model.names = c("Final Model"),
                caption            = "MLM for Popularity",
                caption.above      = TRUE,
                single.row         = TRUE)
```



#### Visualization 

Get Estimated Marginal Means - default 'nice' predictor values:

**Focal predictors:** All combinations of...
* `sex` categorical, both levels    
* `extrav` continuous 1-10, default: 1, 3, 6, 8, 10    
* `texp` continuous, default: 2.0, 7.8, 14.0, 19.0, 25.0    

**Always followed by:** 
* `fit` estimated marginal mean
* `se` standard error for the marginal mean
* `lower` lower end of the 95% confidence interval around the estimated marginal mean
* `upper` upper end of the 95% confidence interval around the estimated marginal mean


```{r}
effects::Effect(focal.predictors = c("sex", "extrav", "texp"),
                mod = pop_lmer_2_re) %>% 
  data.frame() %>% 
  head(n = 12)
```

Pick 'nicer' illustrative values for `texp`

```{r}
effects::Effect(focal.predictors = c("sex", "extrav", "texp"),
                mod = pop_lmer_2_re,
                xlevels = list(texp = c(5, 15, 25))) %>% 
  data.frame() %>% 
  head(n = 12)
```

**Basic, default plot**

Other than selecting three illustrative values for the teacher extraversion rating, most everything is left to default.

```{r}
effects::Effect(focal.predictors = c("sex", "extrav", "texp"),
                mod = pop_lmer_2_re,
                xlevels = list(texp = c(5, 15, 25))) %>% 
  data.frame() %>% 
  dplyr::mutate(texp = factor(texp)) %>% 
  ggplot() +
  aes(x = extrav,
      y = fit,
      fill = texp,
      linetype = texp) +
  geom_ribbon(aes(ymin = lower,
                  ymax = upper),
              alpha = .3) +
  geom_line(aes(color = texp)) +
  facet_grid(.~ sex) 
```



**More Clean Plot**

There are many ways to clean up a plot, including labeling the axes.

```{r}
effects::Effect(focal.predictors = c("sex", "extrav", "texp"),
                mod = pop_lmer_2_re,
                xlevels = list(texp = c(5, 15, 25))) %>% 
  data.frame() %>% 
  dplyr::mutate(texp = factor(texp)) %>% 
  dplyr::mutate(sex = sex %>% 
                  forcats::fct_recode("Amoung Boys" = "boy",
                                      "Among Girls" = "girl")) %>% 
  ggplot() +
  aes(x = extrav,
      y = fit,
      fill = texp,
      linetype = texp) +
  geom_ribbon(aes(ymin = lower,
                  ymax = upper),
              alpha = .3) +
  geom_line(aes(color = texp)) +
  theme_bw() +
  facet_grid(.~ sex) +
  labs(x = "Pupil's Extroversion, Rated by Teacher",
       y = "Estimated Marginal Mean\nPupil Popularity, Mean Rating of Classroom Peers",
       color    = "Teacher's Experience, Years",
       linetype = "Teacher's Experience, Years",
       fill     = "Teacher's Experience, Years") +
  theme(legend.position = "bottom") +
  scale_x_continuous(breaks = seq(from = 0, to = 10, by = 2))
```


**Publishable Plot**

Since `gender` only exhibited a main effect and is not involved in any interactions, if would be a better use of space to not muddy the water with seperate panels.  The `Effect()` function will estimate the marginal means using the reference category for categorical variables and the mean for continuous variables.

```{r}
effects::Effect(focal.predictors = c("extrav", "texp"),  # choose not to investigate sex (the reference category will be used)
                mod = pop_lmer_2_re,
                xlevels = list(texp = c(5, 15, 25))) %>% 
  data.frame() %>% 
  dplyr::mutate(texp = factor(texp) %>% 
                  forcats::fct_rev()) %>% 
  ggplot() +
  aes(x = extrav,
      y = fit,
      linetype = texp) +
  geom_ribbon(aes(ymin = lower,
                  ymax = upper),
              fill = "black",
              alpha = .3) +
  geom_line() +
  theme_bw() +
  labs(x = "Pupil's Extroversion, Rated by Teacher",
       y = "Estimated Marginal Mean\nPupil Popularity, Mean Rating of Classroom Peers",
       color    = "Teacher's\nExperience,\nYears",
       linetype = "Teacher's\nExperience,\nYears",
       alpha    = "Teacher's\nExperience,\nYears") +
  theme(legend.key.width = unit(2, "cm"),
        legend.background = element_rect(color = "Black"),
        legend.position = c(1, 0),
        legend.justification = c(1, 0)) +
  scale_linetype_manual(values = c("solid", "dashed", "dotted")) +
  scale_x_continuous(breaks = seq(from = 0, to = 10, by = 2)) +
  scale_y_continuous(breaks = seq(from = 0, to = 10, by = 1))  
```

#### Interpretation

After accounting for class-to-class variation and the effect of gender, a positive association was found between teacher rated extroversion and peer rated popularity.  This relationship was more marked for less experienced teachers.



<!--chapter:end:05-example_hox2_popular2.Rmd-->

# Intro 3-Level Model Example: Nurse's Stress Intervention

![](images/header_hox_nurses.png)

```{r, include=FALSE}
knitr::opts_chunk$set(comment     = "",
                      echo        = TRUE, 
                      warning     = FALSE, 
                      message     = FALSE,
                      fig.align   = "center", # center all figures
                      fig.width   = 6,        # set default figure width to 4 inches
                      fig.height  = 4)        # set default figure height to 3 inches
```

```{r, message=FALSE, error=FALSE}
library(tidyverse)
library(haven)        # read in SPSS dataset
library(furniture)    # nice table1() descriptives
library(stargazer)    # display nice tables: summary & regression
library(texreg)       # Convert Regression Output to LaTeX or HTML Tables
library(psych)        # contains some useful functions, like headTail
library(car)          # Companion to Applied Regression
library(lme4)         # Linear, generalized linear, & nonlinear mixed models
library(lmerTest)     # Tests on lmer objects
library(sjstats)      # ICC calculations
library(effects)      # Effects for regression models
library(optimx)       # Different optimizers to solve mlm's
```


<!-- ========================================================= -->
## Background
<!-- ========================================================= -->

```{block type='rmdlink', echo=TRUE}
The text **"Multilevel Analysis: Techniques and Applications, Third Edition"** [@hox2017] has a companion [website](https://multilevel-analysis.sites.uu.nl/) which includes links to all the data files used throughout the book (housed on the [book's GitHub repository](https://github.com/MultiLevelAnalysis)). 
```

 
The following example is used through out @hox2017's chapater 2.

> From **Appendix E**:  
>
> The **nurses.sav** file contains three-level simulated data from a hypothetical study on stress in hospitals.  The data are from nurses working in wards nested within hospitals.  It is a cluster-randomized experiment.  In each of **25** hospitals, **four wards** are selected and randomly assigned to an experimental and a control condition.  In the experimental condition, a training program is offered to all nurses to cope with job-related stress.  After the program is completed, a sample of about 10 nurses from each ward is given a test that measures job-related stress.  Additional variables *(covariates)* are: nurse age (years), nurse experience (years), nurse gender (0=male, 1 = female), type of ward (0=general care, 1=special care), and hospital size (0=small, 1 = medium, 2=large).  The data have been generated to illustrate three-level analysis with a random slope for the effect of the intervention.

![](images/diagram_hox_nurses.png)


Here the data is read in and the SPSS variables with labels are converted to $R$ factors. 

```{r}
data_raw <- haven::read_sav("https://github.com/MultiLevelAnalysis/Datasets-third-edition-Multilevel-book/raw/master/chapter%202/Nurses/SPSS/Nurses.sav") %>% 
  haven::as_factor()             # retain the labels from SPSS --> factor
```


### Unique Identifiers

 All standardized *(starts with "Z")* and mean centered *(starts with "C")* variables will be remove so that their creation may be shown later.  A new indicator varible for nurses with be created by combining the `hospital`, `ward`, and `nurse` indicators.  Having a unique, distinct identifier variable for each of the units on lower (Level 1 and 2) levels is helpful for multilevel anlayses.

```{r}
data_nurse <- data_raw %>%
  dplyr::mutate(genderF = factor(gender, 
                                 labels = c("Male", "Female"))) %>% # apply factor labels
  dplyr::mutate(id = paste(hospital, ward, nurse,
                           sep = "_") %>%                                   # cunique id for each student
                  factor()) %>%                                             # declare id is a factor
  dplyr::mutate_at(vars(hospital, ward, 
                        wardid, nurse), factor) %>%                         # declare to be factors
  dplyr::mutate(age = age %>% as.character %>% as.numeric) %>%              # declare to be numeric
  dplyr::select(id, wardid, nurse, ward, hospital,
                age, gender, genderF, experien, 
                wardtype, hospsize,
                expcon, stress)                                             # reduce variables included

tibble::glimpse(data_nurse)
```


### Centering Variables

```{block type='rmdlightbulb', echo=TRUE}
When variables are involved in an interaction, it may be advantageous to center the variables.  @hox2017 covers this in chapter 4.  
```


To center categorical variables:    
1. Convert then to integers, starting with zero: $0, 1, \dots$    
2. Subtract the mean




```{r}
data_nurse %>% 
  dplyr::mutate(expconN    = as.numeric(expcon)   - 1) %>%  # Numeric Version of experimental condition
  dplyr::mutate(hospsizeN  = as.numeric(hospsize) - 1) %>%  # Numeric Version of hospital size
  dplyr::select(expcon, expconN, hospsize, hospsizeN) %>% 
  summary()
```


```{r}
data_nurse <- data_nurse %>% 
  dplyr::mutate(expconN    = as.numeric(expcon)   - 1) %>%  # Numeric Version of experimental condition
  dplyr::mutate(hospsizeN  = as.numeric(hospsize) - 1) %>%  # Numeric Version of hospital size
  dplyr::mutate(expconNG   = expconN   - 0.504) %>%         # Grand-Mean Centered version of experimental condition
  dplyr::mutate(hospsizeNG = hospsizeN - 0.776)             # Grand-Mean Centered version of ehospital size
```


```{r}
data_nurse %>% 
  dplyr::select(expcon, expconNG) %>% 
  table()
```

```{r}
data_nurse %>% 
  dplyr::select(hospsize, hospsizeNG) %>% 
  table()
```

## Exploratory Data Analysis

### Summarize Descriptive Statistics

#### The `stargazer` package

Most posters, journal articles, and reports start with a table of descriptive statistics.  Since it tends to come first, this type of table is often refered to as *Table 1*.  The `stargazer()` function can be used to create such a table, but only for the entire dataset [@R-stargazer].  I haven't been able to find a way to get it to summarize subsamples and compare them in the standard format.

```{r, results='asis'}
# Knit to Website: type = "html" 
# Knit to PDF:     type = "latex"
# View on Screen:  type = "text"

data_nurse %>% 
  data.frame() %>% 
  stargazer::stargazer(title  = "Descriptive statistics, aggregate over entire sample",
                       header = FALSE,
                       type = "html")
```


#### The `furniture` package

Tyson Barrett's  **furniture** package includes the extremely useful function `table1()` which simplifies the common task of creating a stratified, comparative table of descriptive statistics.  Full documentation can be accessed by executing `?furniture::table1`.    

```{r, results='asis'}
# Knit to Website: output = "html" 
# Knit to PDF:     output = "latex2"
# View on Screen:  output = ""text", or "markdown", "html"

data_nurse %>% 
  furniture::table1(age, genderF, experien, wardtype, hospsize, hospsizeN, hospsizeNG,
                    splitby    = ~ expcon,                                              # var to divide sample by
                    test       = TRUE,                                                  # test groups different?
                    type       = "full",                                                # give the test statistic
                    output     = "html",                                                # output for html
                    caption    = "Compare Intervention groups on five main variables")  # title
```




```{block type='rmdlightbulb', echo=TRUE}
The t-test performed by the `furniture::table1()` function will always assume indepent groups and that HOV is not violated.  This may or may not be appropriate.
```



<!-- ========================================================= -->
## MLM: Null Model
<!-- ========================================================= -->

> In a Null, intercept-only, or Empty model, no predictors are included.


#### Fit the Model

Fit the model to the data, with both ML and REML.

```{r}
nurse_lmer_0_re <- lme4::lmer(stress ~ 1 +              # Fixed Intercept for all nurses
                                (1|hospital/ward),      # Random Intercepts for wards within hospitals
                              data = data_nurse,
                              REML = TRUE)              # fit via REML (the default) for ICC calculations

nurse_lmer_0_ml <- lme4::lmer(stress ~ 1 +              # Fixed Intercept for all nurses
                                (1|hospital/ward),      # Random Intercepts for wards within hospitals 
                              data = data_nurse,
                              REML = FALSE)             # fit via ML for comparing FIXED effects inclusion
```

```{r, include=FALSE}
texreg::screenreg(list(nurse_lmer_0_ml, nurse_lmer_0_re))
```

```{r, results='asis'}
# Knit to Website: texreg::htmlreg()
# Knit to PDF:     texreg::texreg()
# View on Screen:  texreg::screenreg()

texreg::htmlreg(list(nurse_lmer_0_ml, 
                     nurse_lmer_0_re),
                custom.model.names = c("M0: Null, ML", 
                                       "M0: Null, REML"),
                caption            = "NULL Model: different estimation methods",
                caption.above      = TRUE,
                single.row         = TRUE)
```

<!-- ========================================================= -->
## Estimate the ICC
<!-- ========================================================= -->

The ICC is calculated by dividing the between-group-variance (random intercept variance) by the total variance (i.e. sum of between-group-variance and within-group (residual) variance).


```{r}
lme4::VarCorr(nurse_lmer_0_re) 
```

```{r}
lme4::VarCorr(nurse_lmer_0_re) %>% 
  print(comp = c("Variance", "Std.Dev"),
        digits = 3)
```


```{r}
vc <- lme4::VarCorr(nurse_lmer_0_re) %>% 
  data.frame() 
  
pie(x = vc$vcov,
    labels = vc$grp)
```

The `sjstats` package has a few really helpful funcitons:

```{r}
sjstats::re_var(nurse_lmer_0_re)
```
$$
\begin{align*}
\text{hospitals}                                 \rightarrow \; & \sigma^2_{v0} = 0.417^2 = 0.174\\
\text{wards within hospitals}                    \rightarrow \; & \sigma^2_{u0} = 0.699^2 = 0.489\\
\text{nurses within wards within hospitals}      \rightarrow \; & \sigma^2_{e}  = 0.549^2 = 0.301\\
\end{align*}
$$



```{block type='genericEq', echo=TRUE}
**Intraclass Correlation (ICC) Formula, 3 level model - Davis and Scott Method**
$$
\overbrace{\rho_{mid}}^{\text{ICC}\atop\text{at level 2}} = 
\frac{\overbrace{\sigma^2_{u0}}^{\text{Random Intercept}\atop\text{Variance Level 2}}}
     {\underbrace{\sigma^2_{v0}+\sigma^2_{u0}+\sigma^2_{e}}_{\text{Total}\atop\text{Variance}}}
\tag{Hox 2.16}
$$
$$
\overbrace{\rho_{top}}^{\text{ICC}\atop\text{ at level 3}} = 
\frac{\overbrace{\sigma^2_{u0}}^{\text{Random Intercept}\atop\text{Variance Level 3}}}
     {\underbrace{\sigma^2_{v0}+\sigma^2_{u0}+\sigma^2_{e}}_{\text{Total}\atop\text{Variance}}}
\tag{Hox 2.17}
$$
```



```{r}
0.489 / (0.174 + 0.489 + 0.301) # middle level (wards)
0.174 / (0.174 + 0.489 + 0.301) # top level (hospitals)
```


```{block type='rmdimportant', echo=TRUE}
For more than two levels, the 'sjstats::icc()' function computes ICC's by the Davis and Scott method.
```

```{r}
sjstats::icc(nurse_lmer_0_re)
```

The proportion of variange in nurse stress level is 0.51 at the ward level and 0.18 at the hospital level.


To test if the three level model is justified statistically, compare the null models with and without the nesting of wards in hospitals.

```{r}
nurse_lmer_0_re_2level <- lme4::lmer(stress ~ 1 + (1|wardid),  # each hospital contains several wards
                              data = data_nurse,
                              REML = TRUE)              # fit via REML (the default) for ICC calculations
```


```{r, results='asis'}
# Knit to Website: texreg::htmlreg()
# Knit to PDF:     texreg::texreg()
# View on Screen:  texreg::screenreg()

texreg::htmlreg(list(nurse_lmer_0_re_2level, 
                     nurse_lmer_0_re),
                custom.model.names = c("2 levels", 
                                       "3 levels"),
                caption            = "MLM: Two or Three Levels?",
                caption.above      = TRUE,
                single.row         = TRUE)
```

The deviance test or likelihood-ratio test shows that the inclusion of the nesting of wards within hospitals better explains the variance in nurse stress levels.

```{r}
anova(nurse_lmer_0_re, nurse_lmer_0_re_2level, refit = FALSE)
```




<!-- ========================================================= -->
## MLM: Add Fixed Effects
<!-- ========================================================= -->

### Fit the Model

> @hox2017, page 22:
>
> "In this example, the variable `expcon` is of main interest, and the other variables are covariates.  Their funciton is to control for differences between the groups, which can occur even if randomization is used, especially with small samples, and to explain variance in the outcome variable stress.  To the extent that these variables successfully explain the variance, the power of the test for the effect of `expcon` will be increased."

```{r}
nurse_lmer_1_ml <- lme4::lmer(stress ~ expcon +              # experimental condition = CATEGORICAL FACTOR
                                 age + gender + experien +   # level 1 covariates
                                 wardtype +                  # level 2 covariates
                                 hospsize +                  # level 3 covariates, hospital size = CATEGORICAL FACTOR 
                                 (1|hospital/ward),          # Random Intercepts for wards within hospitals
                              data = data_nurse,
                              REML = FALSE)                  # fit via ML for nested FIXED effects
```



```{r, include=FALSE}
texreg::screenreg(list(nurse_lmer_0_ml, nurse_lmer_1_ml))
```

```{r, results='asis'}
# Knit to Website: texreg::htmlreg()
# Knit to PDF:     texreg::texreg()
# View on Screen:  texreg::screenreg()

texreg::htmlreg(list(nurse_lmer_0_ml, 
                     nurse_lmer_1_ml),
                custom.model.names = c("M0: null", 
                                       "M1: fixed pred"),
                caption            = "Nested Models: Fixed effects via ML",
                caption.above      = TRUE,
                single.row         = TRUE)
```

### Assess Significance

```{r}
anova(nurse_lmer_0_ml, nurse_lmer_1_ml)
```

It is clear that the inclusing of these fixed, main effects improves the model's fit, but it is questionable that the type of ward is significant *(Wald test is non-significant)*.  Rather than test it directly, we will leave it in the model.  This is common practice to show that an expected variable is not significant.  




### Centering Variables

Because we will will find that the experimental condition is moderated by hospital size *(in other words there is a significant interaction between `expcon` and `hospsize`)*, @hox2017 presents the models fit with centered values for these two variables.  Let us see how this changes the model.

**(1) Experimental Condition** 

Experimental conditon is a BINARY or two-level factor.

* When it is alternatively coded as a numeric, continuous variable taking the values of zero ($0$) for the reference category and one ($1$) for the other category, the model estimates are exactly the same, including the paramters for the variables and the intercept, AND the model fit statistics.

* When the numeric, continuous variable is further grand-mean centered by additionally subtraction the MEAN of the numberic version, the value of the intercept is the only estimate that changes.

```{r}
nurse_lmer_1a_ml <- lme4::lmer(stress ~ expconN +            # experimental condition = CONTINUOUS CODED 0/1
                                 age + gender + experien +   
                                 wardtype +                  
                                 hospsize +                 # hospital size = CATEGORICAL FACTOR         
                                 (1|hospital/ward),          
                              data = data_nurse,
                              REML = FALSE)                  

nurse_lmer_1b_ml <- lme4::lmer(stress ~ expconNG +           # experimental condition = CONTINUOUS GRAND-MEAN CENTERED
                                 age + gender + experien +   
                                 wardtype +                  
                                 hospsize +                  # hospital size = CATEGORICAL FACTOR                 
                                 (1|hospital/ward),          
                              data = data_nurse,
                              REML = FALSE)                  
```



```{r, include=FALSE}
texreg::screenreg(list(nurse_lmer_1_ml, nurse_lmer_1a_ml, nurse_lmer_1b_ml))
```


```{r, results='asis'}
# Knit to Website: texreg::htmlreg()
# Knit to PDF:     texreg::texreg()
# View on Screen:  texreg::screenreg()

texreg::htmlreg(list(nurse_lmer_1_ml, 
                     nurse_lmer_1a_ml, 
                     nurse_lmer_1b_ml),
                custom.model.names = c("Factor", 
                                       "0 vs 1", 
                                       "Centered"),
                caption            = "MLM: Model 1 - Expereimental Condiditon Coding (2-levels)",
                caption.above      = TRUE,
                single.row         = TRUE)
```



**(2) Hospital Size** 

Experimental conditon is a three-level factor.

* When it is alternatively coded as a numeric, continuous variables taking the values of whole numbers, starting with zero ($0, 1, 2, \dots$), the model there will only be ONE parameter estimated instead of several (one less than the number of categories).  This is becuase the levels are treated as being equally different from each other in terms of the outcome.  This treats the effect of the categorical variable as if it is linear, which may or may not be appropriate.  User beware!

* When the numeric, continuous variable is further grand-mean centered by additionally subtraction the MEAN of the numberic version, the value of the intercept is the only estimate that changes.

```{r}
nurse_lmer_1c_ml <- lme4::lmer(stress ~ expconNG +           # experimental condition = CONTINUOUS GRAND-MEAN CENTERED
                                 age + gender + experien +   
                                 wardtype +                  
                                 hospsizeN +                 # hospital size = CONTINUOUS CODED 0/1          
                                 (1|hospital/ward),          
                              data = data_nurse,
                              REML = FALSE)   

nurse_lmer_1d_ml <- lme4::lmer(stress ~ expconNG +           # experimental condition = CONTINUOUS GRAND-MEAN CENTERED
                                 age + gender + experien +   
                                 wardtype +                  
                                 hospsizeNG +                # hospital size = CONTINUOUS GRAND-MEAN CENTERED           
                                 (1|hospital/ward),          
                              data = data_nurse,
                              REML = FALSE)
```


```{r, include=FALSE}
texreg::screenreg(list(nurse_lmer_1b_ml, nurse_lmer_1c_ml, nurse_lmer_1d_ml))
```

```{r, results='asis'}
# Knit to Website: texreg::htmlreg()
# Knit to PDF:     texreg::texreg()
# View on Screen:  texreg::screenreg()

texreg::htmlreg(list(nurse_lmer_1b_ml, 
                     nurse_lmer_1c_ml, 
                     nurse_lmer_1d_ml),
                custom.model.names = c("Factor", 
                                       "0 vs 1", 
                                       "Centered"),
                caption            = "MLM: Model 1 - Hospital Coding (3-levels)",
                caption.above      = TRUE,
                single.row         = TRUE)
```



<!-- ========================================================= -->
## MLM: Add Random Slope
<!-- ========================================================= -->

> @hox2017, page 22:
>
> "Although logically we can test if explanatory variables at the first level have random coefficients (slopes) at the second or third level, and if explanatory variables at teh second level have random coefficients (slopes) at the third level, these possibilities are not pursued.  We DO test a model with a random coefficient (slope) for `expcon` at the third level, where there turns out to be significant slope variation."  



### Fit the Model


```{r}
nurse_lmer_1d_re <- lme4::lmer(stress ~ expconNG +            # experimental condition = CONTINUOUS GRAND-MEAN CENTERED
                                 age + gender + experien +    # level 1 covariates
                                 wardtype +                   # level 2 covariate
                                 hospsizeNG +                 # level 3 covariate, hospital size = CONTINUOUS GRAND-MEAN CENTERED           
                                 (1|hospital/ward),           # Random Intercepts for wards within hospitals
                               data = data_nurse, 
                               REML = TRUE)                   # fit via REML for nested Random Effects

nurse_lmer_2_re <- lme4::lmer(stress ~ expconNG +             # experimental condition = CONTINUOUS GRAND-MEAN CENTERED
                                age + gender + experien +     # level 1 covariates
                                wardtype +                    # level 2 covariate
                                hospsizeNG +                  # level 3 covariate, hospital size = CONTINUOUS GRAND-MEAN CENTERED           
                                (1|hospital/ward) +           # Random Intercepts for wards within hospitals
                                (0 + expconNG|hospital),      # RANDOM SLOPES for exp cond within hospital (does not vary witin a ward!)
                              data = data_nurse,
                              REML = TRUE)                    # fit via REML for nested Random Effects
```


```{r, include=FALSE}
texreg::screenreg(list(nurse_lmer_1d_re, nurse_lmer_2_re))
```


```{r, results='asis'}
# Knit to Website: texreg::htmlreg()
# Knit to PDF:     texreg::texreg()
# View on Screen:  texreg::screenreg()

texreg::htmlreg(list(nurse_lmer_1d_re, 
                     nurse_lmer_2_re),
                custom.model.names = c("M1: RI", 
                                       "M2: RIAS"),
                caption            = "Nested Models: Random Slope via REML",
                caption.above      = TRUE,
                single.row         = TRUE)
```

### Assess Significance

```{r}
anova(nurse_lmer_1d_re, nurse_lmer_2_re, refit = FALSE)
```

The inclusion of a random slope effect for the experimental condition `expcon` significantly improves the models's fit, thus is should be retained.




<!-- ========================================================= -->
## MLM: Add Cross-Level Interaction
<!-- ========================================================= -->

> @hox2017, page 22:
>
> "The varying slope can be predicted by adding a cross-level interaction between the variables `expcon` and `hospsize`.  In view of this interaction, the variables `expcon` and `hospsize` have been centered on tehir overal means."


### Fit the Model

```{r}
nurse_lmer_2_ml <- lme4::lmer(stress ~ expconNG +           # experimental condition = CONTINUOUS GRAND-MEAN CENTERED
                                age + gender + experien +   # level 1 covariates
                                wardtype +                  # level 2 covariate
                                hospsizeNG +                # level 3 covariate, hospital size = CONTINUOUS GRAND-MEAN CENTERED           
                                (1|hospital/ward) +         # Random Intercepts for wards within hospitals
                                (0 + expconNG|hospital),    # RANDOM SLOPES for exp cond within hospital (does not vary witin a ward!) 
                              data = data_nurse,
                              REML = FALSE)                 # fit via ML for nested FIXED Effects

nurse_lmer_3_ml <- lme4::lmer(stress ~ expconNG +           # experimental condition = CONTINUOUS GRAND-MEAN CENTERED
                                age + gender + experien +   # level 1 covariates
                                wardtype +                  # level 2 covariate
                                hospsizeNG +                # level 3 covariate, hospital size = CONTINUOUS GRAND-MEAN CENTERED   
                                expconNG*hospsizeNG +       # CROSS-LEVEL interaction
                                (1|hospital/ward) +         # Random Intercepts for wards within hospitals
                                (0 + expconNG|hospital),    # RANDOM SLOPES for exp cond within hospital (does not vary witin a ward!) 
                              data = data_nurse,
                              REML = FALSE)                 # fit via ML for nested FIXED Effects
```

```{r, include=FALSE}
texreg::screenreg(list(nurse_lmer_2_ml, nurse_lmer_3_ml))
```


```{r, results='asis'}
# Knit to Website: texreg::htmlreg()
# Knit to PDF:     texreg::texreg()
# View on Screen:  texreg::screenreg()

texreg::htmlreg(list(nurse_lmer_2_ml, 
                     nurse_lmer_3_ml),
                custom.model.names = c("M2: RAIS", 
                                       "M3: Xlevel Int"),
                caption            = "Nested Models: Fixed Cross-Level Interaction via ML",
                caption.above      = TRUE,
                single.row         = TRUE)
```

### Assess Significance

```{r}
anova(nurse_lmer_2_ml, nurse_lmer_3_ml)
```

There is evidence that hospital size moderated the effect of the intervention.  We will want to plot the estimated marginal means to interpret the meaning of this interaction. 




## Final Model


### Fit the model

The final model should be fit via REML.

```{r}
nurse_lmer_3_re <- lme4::lmer(stress ~ expconNG +           # experimental condition = CONTINUOUS GRAND-MEAN CENTERED
                                age + gender + experien +   # level 1 covariates
                                wardtype +                  # level 2 covariate
                                hospsizeNG +                # level 3 covariate, hospital size = CONTINUOUS GRAND-MEAN CENTERED   
                                expconNG*hospsizeNG +       # CROSS-LEVEL interaction
                                (1|hospital/ward) +         # Random Intercepts for wards within hospitals
                                (0 + expconNG|hospital),    # RANDOM SLOPES for exp cond within hospital (does not vary witin a ward!)  
                              data = data_nurse,
                              REML = TRUE)                                       # fit via REML for final model        
```



### Table of Estimated Parameters

```{r, include=FALSE}
texreg::screenreg(list(nurse_lmer_3_re), single.row = TRUE)
```


```{r, results='asis'}
# Knit to Website: texreg::htmlreg()
# Knit to PDF:     texreg::texreg()
# View on Screen:  texreg::screenreg()

texreg::htmlreg(list(nurse_lmer_3_re),
                custom.model.names = c("M3: Xlevel Int"),
                caption            = "Final Model: with REML",
                caption.above      = TRUE,
                single.row         = TRUE)
```

```{block type='rmdimportant', echo=TRUE}
**ICC for unconditional and conditional model**

Usually, the ICC is calculated for the null model ("unconditional model"). However, according to Raudenbush and Bryk (2002) or Rabe-Hesketh and Skrondal (2012) it is also feasible to compute the ICC for full models with covariates ("conditional models") and compare how much a level-2 variable explains the portion of variation in the grouping structure (random intercept). 

**ICC for random-slope models** 

**Caution!!!** For models with **random slopes and random intercepts**, the ICC would differ at each unit of the predictors. Hence, the ICC for these kind of models cannot be understood simply as proportion of variance *(see Goldstein et al. 2010)*. For convenience reasons, as the 'icc()' function also extracts the different random effects variances, the ICC for random-slope-intercept-models is reported nonetheless, but **it is usually not a  meaningful summary** of the proportion of variances. 

**ICC for models with multiple or nested random effects**

**Caution:** By default, for **three-level-models**, depending on the nested structure of the model, or for models with multiple random effects, 'icc()' only reports the proportion of variance explained for each grouping level. Use 'adjusted = TRUE' to calculate the adjusted and conditional ICC.
```




```{r}
sjstats::icc(nurse_lmer_3_re)
```

### Visualization: Estimated Marginal Means Plot 


Although there are many variables in this model, only two are involved in any interaction(s).  For this reason, we will choose to display the estimated marginal means across only experimental condition and hospital size.  For this illustration, all other continuous predictors are taken to be at their mean and categorical predictors at their reference category.


```{r}
sjPlot::plot_model(nurse_lmer_3_re, 
                   type = "pred", 
                   terms = c("hospsizeNG", "expconNG"))
```


```{r}
sjPlot::plot_model(nurse_lmer_3_re, 
                   type = "pred", 
                   terms = c("hospsizeNG [-0.776, 0.224, 1.224]", 
                             "expconNG [-0.504, 0.496]")) +
  scale_x_continuous(breaks = c(-0.776, 0.224, 1.224),
                     labels = c("small", "medium", "large")) +
  scale_color_manual(labels = c("Control", "Intervention"),
                     values = c("red", "blue")) +
  labs(title = "Multilevel Modeling of Hospital Nurse Stress Intervention",
       subtitle = "Ribbons display 95% Confidene Intervals",
       x = "Hospital Size",
       y = "Estimated Marginal Mean\nNorse's Stress Score",
       color = "Condition") +
  theme_bw()
```






Get Estimated Marginal Means - default 'nice' predictor values:

**Focal predictors:** All combinations of...     

* `expcon` categorical, both levels `control` and `experiment`    
* `hospsize` categorical, all three levels`small` , `medium`, `large`  

**Always followed by:**     

* `fit` estimated marginal mean
* `se` standard error for the marginal mean
* `lower` lower end of the 95% confidence interval around the estimated marginal mean
* `upper` upper end of the 95% confidence interval around the estimated marginal mean


```{r}
effects::Effect(focal.predictors = c("expconNG", "hospsizeNG"),
                mod = nurse_lmer_3_re,
                xlevels = list(expconNG   = c(-0.504, 0.496),
                               hospsizeNG = c(-0.776, 0.224, 1.224))) %>% 
  data.frame()  
```

```{r}
effects::Effect(focal.predictors = c("expconNG", "hospsizeNG"),
                mod = nurse_lmer_3_re,
                xlevels = list(expconNG   = c(-0.504, 0.496),
                               hospsizeNG = c(-0.776, 0.224, 1.224))) %>% 
  data.frame()  %>% 
  dplyr::mutate(expcon = factor(expconNG + 0.504,
                                labels = c("Control", "Intervention"))) %>% 
  dplyr::mutate(hopsize = factor(hospsizeNG + 0.776,
                                 labels = c("Small", "Medium", "Large")))
```

```{r}
effects::Effect(focal.predictors = c("expconNG", "hospsizeNG"),
                mod = nurse_lmer_3_re,
                xlevels = list(expconNG   = c(-0.504, 0.496),
                               hospsizeNG = c(-0.776, 0.224, 1.224))) %>% 
  data.frame()  %>% 
  dplyr::mutate(expcon = factor(expconNG + 0.504,
                                labels = c("Control", "Intervention"))) %>% 
  dplyr::mutate(hospsize = factor(hospsizeNG + 0.776,
                                 labels = c("Small", "Medium", "Large"))) %>% 
  ggplot() +
  aes(x = hospsize,
      y = fit,
      group = expcon,
      shape = expcon,
      color = expcon) +
  geom_errorbar(aes(ymin = fit  - se,      # mean plus/minus one Std Error
                    ymax = fit + se),
                width = .4,
                position = position_dodge(width = .2)) + 
  geom_errorbar(aes(ymin = lower,           # 95% CIs
                    ymax = upper),
                width = .2,
                position = position_dodge(width = .2)) + 
  geom_line(aes(linetype = expcon),
            position = position_dodge(width = .2)) +
  geom_point(size = 4,
             position = position_dodge(width = .2)) +
  theme_bw() +
  labs(x = "Hospital Size",
       y = "Estimated Marginal Mean, Stress",
       shape    = "Condition",
       color    = "Condition",
       linetype = "Condition") +
  theme(legend.key.width = unit(2, "cm"),
        legend.background = element_rect(color = "black"),
        legend.position = c(1, 0),
        legend.justification = c(1, 0))
```

This plot illustrates the estimated marginal means among male (gender's reference category) nurses at the overall mean age (43.01 years), with the mean level experience (17.06 years), since thoes variables were not included as `focal.predictors` in the `effects::Effect()` function.  Different values for thoes predictors would yield the exact sample plot, shifted as a whole either up or down.





## Interpretation

There is evidence this intervention lowered stress among nurses working in small hospitals and to a smaller degree in medium sized hospitals.  The intervention did not exhibit an effect in large hospitals.  


### Strength

This analysis was able to incorporated all three levels of clustering while additionally controlling for many covariates, both categorical (nurse gender and ward type) and continuous (nurse age and experience in years).  Also heterogeneity was accounted for in terms of the interventions's effect at various hospitals.  This would NOT be possible via any ANOVA type anlysis.


### Weakness

The approach presented by @hox2017 and shown above involved mean-centering categorical variables.  This would only be appropriate for a factor with more than two levels if its effect on the outcome was linear.  Also, as the mean-centered variables are treated as continuous variables, post hoc tests are increasingly difficult.



## Reproduction of Table 2.5 

@hox2017 presents a table on page 23 comparing various models.  Note, that table includes models only fit via maximum likelihood, not REML.  Also, the model $M_3$: with cross-level interaction is slightly different for an unknown reason.

```{r, include=FALSE}
texreg::screenreg(list(nurse_lmer_0_ml, nurse_lmer_1d_ml, nurse_lmer_2_ml, nurse_lmer_3_ml))
```


```{r, results='asis'}
# Knit to Website: texreg::htmlreg()
# Knit to PDF:     texreg::texreg()
# View on Screen:  texreg::screenreg()

texreg::htmlreg(list(nurse_lmer_0_ml, 
                     nurse_lmer_1d_ml, 
                     nurse_lmer_2_ml, 
                     nurse_lmer_3_ml),
                custom.model.names = c("M0", "M1", "M2", "M3"),
                caption            = "Hox Table 2.5: Models for stress in hospitals and wards",
                caption.above      = TRUE,
                single.row         = TRUE)
```


Deviance:

```{r}
c(deviance(nurse_lmer_0_ml),         
  deviance(nurse_lmer_1d_ml),
  deviance(nurse_lmer_2_ml),
  deviance(nurse_lmer_3_ml)) %>% 
  round(1)
```



<!--chapter:end:06-example_hox2_nurses.Rmd-->

# Intro Centering and Scaling Example: Reading Achievement (2-levels only)


```{r, include=FALSE}
knitr::opts_chunk$set(comment     = "",
                      echo        = TRUE, 
                      warning     = FALSE, 
                      message     = FALSE,
                      fig.align   = "center", # center all figures
                      fig.width   = 6,        # set default figure width to 4 inches
                      fig.height  = 4)        # set default figure height to 3 inches
```

```{r, message=FALSE, error=FALSE}
library(tidyverse)    # all things tidy
library(haven)        # read in SPSS dataset
library(furniture)    # nice table1() descriptives
library(stargazer)    # display nice tables: summary & regression
library(texreg)       # Convert Regression Output to LaTeX or HTML Tables
library(psych)        # contains some useful functions, like headTail
library(sjstats)      # ICC calculations
library(effects)      # Effects for regression models
library(optimx)       # Different optimizers to solve mlm's

library(lme4)         # non-linear mixed-effects models

library(haven)        # read in SPSS dataset
```



<!-- ========================================================= -->
## Background
<!-- ========================================================= -->

```{block type='rmdlink', echo=TRUE}
The following example was included in the text "Multilevel Modeling in R" by @finch2016.

The datasets for this textbook may be downloaded from the website: http://www.mlminr.com/data-sets/.  
```


I was unable to find any documentation on this dataset in the book or online, so I contacted the authors.  There were unable to provide much either, but based on visual inspection designated the class of *factor* to thoes vairables that seem to represent categorical quantities. The labels for gender and class size are relative to the frequencies in the journal article the authors did point me to *(although the samples sizes do not match up)*.

```{block type='rmdimportant', echo=TRUE}
FOR THIS CHAPTER WE WILL IGNORE ALL LEVELS EXCEPT FOR STUDNETS BEING NESTED WITHIN SCHOOLS.
```

Read the SPSS data in with the `haven` package .

```{r}
data_raw <- haven::read_sav("http://www.mlminr.com/data-sets/Achieve.sav?attredirects=0")
```

Declare all categorical variables to be factors and apply labels where meaningful.

> Student-specific   
> * `gender` = Male or Female    
> * `age` = Age, in months    
> * `gevocab` = Vocabulary Score    
> * `geread` = Reading Score    

> Class-specific      
> * `classsize` = category of class's size    

> School-specific     
> * `senroll` = school enrollment    
> * `ses` = school's SES level    

```{r}
data_achieve <- data_raw %>% 
  dplyr::mutate_at(vars(id, region, corp, school, class), factor) %>% 
  dplyr::mutate(gender = gender %>% 
                  factor(labels = c("Female", "Male"))) %>% 
  dplyr::mutate(classize = classize %>% 
                  factor(labels = c("12-17", "18-21", 
                                    "22-26", ">26"))) %>% 
  dplyr::select(id, region, corp, school, class,           # Identifiers
                gender, age, geread, gevocab,              # Pupil-level vars
                classize,                                  # Class-Level vars
                senroll, ses)                              # School-level vars
```



### Sample Structure    


It is obvious that the sample is hiarchical in nature.  The nesting starts with `students` (level 1) nested within `class` (level 2), which are further nested within `school` (level 3), `corp` (level 4), and finally `region` (level 5).  

For this chapter we will only focus on TWO levels: **students** (level 1) are the units on which the outcome is measured and **schools** (level 2) are the units in which they are nested.

The number of ***regions*** = 9:

```{r num_reg}
num_regions <- data_achieve %>% 
  dplyr::group_by(region) %>% 
  dplyr::tally() %>% 
  nrow()

num_regions
```

The number of **corps** = 60:

```{r num_corp}
num_corps <- data_achieve %>% 
  dplyr::group_by(region, corp) %>% 
  dplyr::tally() %>% 
  nrow()

num_corps 
```

The number of **schools** = 160 

```{r num_school}
num_schools <- data_achieve %>% 
  dplyr::group_by(region, corp, school) %>% 
  dplyr::tally() %>% 
  nrow()

num_schools
```

The number of **classes** = 568
```{r num_class}
num_classes <- data_achieve %>% 
  dplyr::group_by(region, corp, school, class) %>% 
  dplyr::tally() %>% 
  nrow()

num_classes
```

The number of **students** = 10320

```{r num_kid}
num_subjects <- data_achieve %>% nrow

num_subjects
```

<!-- ========================================================= -->
## Exploratory Data Analysis
<!-- ========================================================= -->

### Summarize Descriptive Statistics

#### The `stargazer` package

Most posters, journal articles, and reports start with a table of descriptive statistics.  Since it tends to come first, this type of table is often refered to as Table 1.  The `stargazer()` function can be used to create such a table, but only for the entire dataset.  I haven't been able to find a way to get it to summarize subsamples and compare them in the standard format.  Also, it only summarises continuous, not categorical variables.

```{r sumtable0, results='asis'}
# Knit to Website: type = "html" 
# Knit to PDF:     type = "latex"
# View on Screen:  type = "text"

data_achieve %>% 
  dplyr::select(classize, gender, geread, gevocab, age, ses, senroll) %>% 
  data.frame() %>% 
  stargazer::stargazer(header = FALSE,
                      title = "Summary of the numeric variables with `stargazer`",
                       type = "html")
```


#### The `furniture` package

Tyson Barrett's  **furniture** package includes the extremely useful function `table1()` which simplifies the common task of creating a stratified, comparative table of descriptive statistics.  Full documentation can be accessed by executing `?furniture::table1`.


```{r sumtable1, output="asis"}
# Knit to Website: output = "html" 
# Knit to PDF:     output = "latex2"
# View on Screen:  output = ""text", or "markdown", "html"

data_achieve %>% 
  furniture:: table1("Reading Score"       = geread, 
                     "Vocabulary Score"    = gevocab, 
                     "Age (in months)"     = age, 
                     "School SES"          = ses, 
                     "School's Enrollment" = senroll,
                     splitby   = ~ gender,                                        # var to divide sample by
                     test      = TRUE,                                            # test groups different?
                     caption   = "Summary of the numeric variables with `table1`", 
                     output    = "html")
```


### Visualization of Raw Data


#### Level One Plots: Disaggregate or ignore higher levels   


For a first look, its useful to plot all the data points on a single scatterplot as displayed in the previous plot.  Due to the large sample size, many points end up being plotted on top of or very near each other (*overplotted*).  When this is the case, it can be useful to use  `geom_binhex()` rather than `geom_point()` so the color saturation of the hexigons convey the number of points at that location, as seen in Figure \ref{fig:hexbin}.  

*Note: I had to manually install the package `hexbin` for the `geom_hex()` to run.*

```{r densityHex, fig.cap="Raw Data: Density, Vocab vs. Reading"}
data_achieve %>% 
  ggplot() +
  aes(x = gevocab, 
      y = geread) +
  stat_binhex(colour = "grey85", na.rm  = TRUE) +     # outlines
  scale_fill_gradientn(colors   = c("grey80","navyblue"), # fill color extremes
                       name     = "Frequency",        # legend title
                       na.value = NA) +               # color for count = 0
  theme_bw()
```


#### Multilevel plots: illustrate two nested levels  

Up to this point, all investigation of this dataset has been only at the pupil level and any nesting or clustering within schools has been ignored.  Plotting is a good was to start to get an idea of the school-to-school variability.  This figure displays four handpicked school to illustrate the degreen of school-to-school variability in the **association between vocab and reading** scores.

```{r schoolRegEx, fig.width=6, fig.height=6, fig.cap="Raw Data: Independent Single-Level Regression within each school, a few illustrative cases"}
data_achieve %>% 
  dplyr::filter(school %in% c(1321, 6181, 
                              6197, 6823)) %>%  # choose school numbers
  ggplot(aes(x = gevocab,
             y = geread))+
  geom_count() +             # creates points, size by overplotted number
  geom_smooth(method = "lm") +     # linear model (OLS) 
  facet_wrap(~ school) +           # panels by school
  theme_bw()
```

Another way to explore the **school-to-school variability** is to plot the linear model fit *independently* to each of the schools.  This next figure displays only the smooth lines without the standard error bands or the raw data in the form of points or hexagons.

```{r schoolRegAll, fig.cap="Raw Data: Independent Single-Level Regression within each school, all schools shown together"}
data_achieve %>% 
  ggplot(aes(x = gevocab,
             y = geread)) +
  geom_smooth(aes(group = school),
              method = "lm",
              se     = FALSE,      # do NOT want the SE bands
              size   = 0.3) +   
  geom_smooth(method = "lm",
              se     = FALSE,
              color = "red",       # do NOT want the SE bands
              size   = 2) +        # make the lines thinner
  theme_bw() 
```


Due to the high number of schools, the figure with all the school's independent linear regression lines resembles a hairball and is hard to deduce much about individual schools.  By using the `facet_grid()` layer, we can seperate the schools out so better see school-to-school variability.  It also allows investigation of  higher level predictors, such as the school's SES (median split with `ntile(var, 2)`) and class size.


```{r classRegSep, fig.width=6, fig.height=8, fig.cap="Raw Data: Independent Single-Level Regression within each school, sepearated by school size and school SES"}
data_achieve %>% 
  dplyr::mutate(ses2 = ntile(ses, 2) %>%                  # median split
                  factor(labels = c("SES: Lower Half", 
                                    "SES: Upper Half"))) %>% 
  dplyr::mutate(senroll = ntile(senroll, 3) %>% 
                  factor(labels = c("Enroll: Smallest Third",
                                    "Enroll: Middle Third",
                                    "Enroll: Largest Third"))) %>% 
  ggplot(aes(x       = gevocab,
             y       = geread,
             group   = school)) +     # sepearates students into schools
  geom_smooth(method = "lm",
              se     = FALSE,         
              size   = 0.3,
              color = "black",
              alpha = .2) +         
  theme_bw() +
  facet_grid(senroll ~ ses2)     # makes seperate panels (rows ~ columns)
```


<!-- ========================================================= -->
## Single-Level Regression
<!-- ========================================================= -->

### Fit Nested Models

Ignoring the fact that students are nested or clustered within schools, is called dissagregating.  This treats all students as independent units.

```{r}
# linear model - ignores school (for reference only)
fit_read_lm_0 <- lm(formula = geread ~ 1,               # intercept only
                    data    = data_achieve)

fit_read_lm_1 <- lm(formula = geread ~ gevocab ,        # one predictor
                    data    = data_achieve)

fit_read_lm_2 <- lm(formula = geread ~ gevocab + age,   # two predictors
                    data    = data_achieve)

fit_read_lm_3 <- lm(formula = geread ~ gevocab*age,    # interation+main effects
                    data    = data_achieve)
```


Now compare the models:
```{r, include=FALSE}
texreg::screenreg(list(fit_read_lm_0, fit_read_lm_1, fit_read_lm_2, fit_read_lm_3))
```


```{r regLM, results='asis'}
# Knit to Website: texreg::htmlreg()
# Knit to PDF:     texreg::texreg()
# View on Screen:  texreg::screenreg()

texreg::htmlreg(list(fit_read_lm_0, 
                     fit_read_lm_1, 
                     fit_read_lm_2, 
                     fit_read_lm_3),
                custom.model.names = c("Null",
                                       "1 IV",
                                       "2 IV",
                                       "Interaction"),
                caption            = "OLS: Investigate Fixed, Pupil-level Predictors",
                caption.above      = TRUE,
                single.row         = TRUE)
```


Assess the significance of terms in the last 'best' model

```{r}
summary(fit_read_lm_3) 
```


```{r}
sjstats::r2(fit_read_lm_3)
```


```{r}
anova(fit_read_lm_3)
```

### Visualize the Interaction

```{r}
effects::Effect(focal.predictors = c("gevocab", "age"),     # chooses defaul values for
                mod = fit_read_lm_3)                        # continuous vars
```



```{r}
effects::Effect(focal.predictors = c("gevocab", "age"),     # chooses defaul values for
                mod = fit_read_lm_3) %>%                    # continuous vars
  data.frame() %>%  
  mutate(age = factor(age)) %>%           # must make a factor to seperate lines
  ggplot(aes(x = gevocab,
             y = fit,
             color = age)) +
  geom_point() +
  geom_line() 
```


Here is a better version of the plot.

Age is in months, so we want multiples of 12 for good visualization

```{r}
summary(data_achieve$age)/12   # divide by 12 to change months to years
```

A good set set of illustrative ages could be: 7, 9, and 11:

```{r}
c(7, 9, 11) * 12   # times by 12 to change years to months
```


```{r mlInteraction}
effects::Effect(focal.predictors = c("gevocab", "age"),
                mod = fit_read_lm_3,
                xlevels = list(age = c(84, 108, 132))) %>%  # age is in months
  data.frame() %>% 
  mutate(age_yr = factor(age/12)) %>%    # it would be nice to plot age in years
  ggplot(aes(x        = gevocab,
             y        = fit,
             color    = age_yr,
             linetype = age_yr)) +
  geom_line(size = 1.25) +
  theme_bw() +
  labs(title = "Best Linear Model - Disaggregated Data (OLS)",
       x = "Vocabulary Score",
       y = "Reading Score",
       linetype = "Age (yrs)",
       color    = "Age (yrs)") +
  theme(legend.position = c(0.85, 0.2),
        legend.key.width = unit(2, "cm"),
        legend.background = element_rect(color = "black")) +
  scale_linetype_manual(values = c("solid", "longdash", "dotted")) +
  scale_x_continuous(breaks = seq(from = 0, to = 11, by = 2)) +
  scale_y_continuous(breaks = seq(from = 0, to = 11, by = 1))
```



<!-- ========================================================= -->
## MLM - Step 1: Null Model, only fixed and random intercepts
<!-- ========================================================= -->


A so called *Empty Model* only includes random intercepts.  No independent variables are involved, other the grouping or clustering variable that designates how *level 1* units are nested within *level 2* units.  For a cross-sectional study design this would be the grouping variables, where as for longitudinal or repeated measures designs this would be the subject identifier.  This **nested structure** variable should be set to have class `factor`.

### Fit the Model

```{r}
fit_read_0ml <- lme4::lmer(geread ~ 1 + (1|school), 
                           data = data_achieve,
                           REML = FALSE)                  # fit via ML (not the default)

fit_read_0re <- lme4::lmer(geread ~ 1 + (1|school) , 
                           data = data_achieve,
                           REML = TRUE)                   # fit = REML (the default)
```


Compare the two models to OLS:
```{r, include=FALSE}
texreg::screenreg(list(fit_read_lm_0, fit_read_0ml, fit_read_0re))
```


```{r mlmNull, results='asis'}
# Knit to Website: texreg::htmlreg()
# Knit to PDF:     texreg::texreg()
# View on Screen:  texreg::screenreg()

texreg::htmlreg(list(fit_read_lm_0, 
                     fit_read_0ml, 
                     fit_read_0re),
                custom.model.names = c("OLS", 
                                       "MLM-ML", 
                                       "MLM-REML"),
                caption            = "MLM: NULL Model,two estimation methods",
                caption.above      = TRUE,
                single.row         = TRUE)
```

Notice that the estimate for the intercept is nearly the same in the linear regression and intercept only models, but the standard errors are quite different.  When there is clustering in sample, the result of ignoring it is under estimation of the standard errors and over stating the significance of associations.  This table was made with the `screenreg()` function in the self named package.  I tend to prefer this display over `stargazer()`.


### Estimate the ICC

First, ask for the variance compenents:

```{r}
lme4::VarCorr(fit_read_0re) %>% 
  print(comp = c("Variance", "Std.Dev"),
        digits = 4)
```

```{r}
sjstats::re_var(fit_read_0re)
```


$$
\begin{align*}
\text{schools}                      \rightarrow \; & \sigma^2_{u0} = 0.6257^2 = 0.392 \\
\text{students within schools}      \rightarrow \; &   \sigma^2_{e}  = 2.2461^2 = 5.045 \\
\end{align*}
$$


```{block type='genericEq', echo=TRUE}
**Intraclass Correlation (ICC) Formula**
$$
\overbrace{\rho}^{\text{ICC}} = 
\frac{\overbrace{\sigma^2_{u0}}^{\text{Random Intercept}\atop\text{Variance}}}
     {\underbrace{\sigma^2_{u0}+\sigma^2_{e}}_{\text{Total}\atop\text{Variance}}}
\tag{Hox 2.9}
$$
```


Then you can manually caluclate the ICC.

```{r}
0.392 / (0.392 + 5.045)
```

Or you can use the `icc()` function in the `sjstats` package.

```{r}
sjstats::icc(fit_read_0re)
```


*Note: On page 45  [@finch2016], the authors substituted standard deviations into the formula, rather than variances.  The mistake is listed on their webpage errata (http://www.mlminr.com/errata) and is repeated through the text.*


<!-- ========================================================= -->
## MLM - Step 2: Add Lower-level explanatory variables, fixed, ML
<!-- ========================================================= -->

**Variance Component** models (steps 2 and 3) - decompose the INTERCEPT variance into different variance compondents for each level.  The regression intercepts are assumed to varry ACROSS the groups, while the slopes are assumed fixed (no random effects).


Fixed effects selection should come **prior** to random effects.  You should use *Maximum Likelihood (ML)* estimation when fitting these models.

```{block type='rmdlightbulb', echo=TRUE}
* IF: only level 1 predictors and random intercepts are incorporated  
* Then: MLM \textit{(ML)} $\approx$ ANCOVA \textit{OLS}.
```



### Add pupil's vocab score as a fixed effects predictor

```{r}
fit_read_1ml <- lme4::lmer(geread ~ gevocab + (1|school), 
                           data = data_achieve,
                           REML = FALSE)            # to compare fixed var sig

fit_read_1re <- lme4::lmer(geread ~ gevocab + (1|school), 
                           data = data_achieve,
                           REML = TRUE)             # for R-sq calcs
```


```{r, include=FALSE}
texreg::screenreg(list(fit_read_0ml, fit_read_1ml))
```

```{r, results='asis'}
# Knit to Website: texreg::htmlreg()
# Knit to PDF:     texreg::texreg()
# View on Screen:  texreg::screenreg()

texreg::htmlreg(list(fit_read_0ml, 
                     fit_read_1ml),
                custom.model.names = c("Null", 
                                       "w Pred"),
                caption = "MLM: Investigate a Fixed Pupil-level Predictor",
                caption.above = TRUE,
                doctype = FALSE,
                digits = 4)
```


#### Assess Significance of Effects

Likelihood Ratio Test (LRT)

Since models 0 and 1 are nested models, only differing by the the inclusion or exclusion of the fixed effects predictor `gevocab`, AND both models were fit via Maximum Likelihood, we can compare the model fit may be compared via the *Likilihood-Ratio Test (LRT)*.  The *Likelihood Ratio* value *(L. Ratio)* is found by subtracting the two model's  `-2 * logLik` or `deviance` values.  Significance is judged by the Chi Squared distribution, using the difference in the number of parameters fit as the degrees of freedom. 


```{r}
anova(fit_read_0ml, fit_read_1ml)
```

What does the model look like?

```{r}
effects::Effect(focal.predictors = c("gevocab"), 
                mod = fit_read_1ml) %>% 
  data.frame() %>% 
  ggplot(aes(x = gevocab,
             y = fit)) +
  geom_ribbon(aes(ymin = lower,
                  ymax = upper),
                alpha = .3) +
  geom_line() +
  theme_bw()
```

#### Proportion of Variance Explained 

Extract the variance-covariance estimates:

BL = BAseline: The Null Model (fit via REML)
```{r}
sjstats::re_var(fit_read_0re)
```
$$
\sigma^2_{u0-BL} = 0.392 \\
\sigma^2_{e-BL}  = 5.045 
$$



MC = Model to Compare: Model with Predictor (fit via REML)
```{r}
sjstats::re_var(fit_read_1re)
```

$$
\sigma^2_{u0-MC} = 0.100 \\
\sigma^2_{e-MC}  = 3.766 
$$


**Level 1 $R^2$ - Snijders and Bosker**

Found on page 47 [@finch2016], theproportion of variance in the outcome explained by predictor on level one is given by:   

```{block type='genericEq', echo=TRUE}
**Snijders and Bosker Formula - Level 1 ** 
$$
R^2_1 = 1 - \frac{\sigma^2_{e-MC} + \sigma^2_{u0-MC}}
                 {\sigma^2_{e-BL} + \sigma^2_{u0-BL}}
$$
```




*Note: This formula also apprears in the Finch errata.  The subscripts in the denominator of the fraction should be for model 0, not model 1. The formula is given correctly here. They did substitute in the correct values.*


Calculate the value by hand:
```{r}
1 - (0.100 + 3.766)/(0.392 + 5.045)
```

Or use the `sjstats` package to help out:
```{r}
1 - sum(sjstats::re_var(fit_read_1re)) / sum(sjstats::re_var(fit_read_0re))
```

This means nearly 30% of the variance in reading scores, above and beyond that accounted for by school membership *(i.e. school makeup or school-to-school variation)*, is attributable to vocabulary scores. 



**Level 1 $R^2$ - Raudenbush and Bryk**

@hox2017 presents this formula on page 58 of chapter 2


```{block type='genericEq', echo=TRUE}
**Raudenbush and Bryk Approximate Formula - Level 1 ** 
$$
approx\; R^2_1 = \frac{\sigma^2_{e-BL} - \sigma^2_{e-MC}}
              {\sigma^2_{e-BL} }
\tag{Hox 4.8}
$$
```



Calculate the value by hand:
```{r}
(5.045 - 3.766) / 5.045
```

Although slightly different in value and meaning, this value also conveys that vcabulary scores are highly associated with reading scores.





**Level 2 $R^2$ - Snijders and Bosker Formula Extended ** 



```{block type='genericEq', echo=TRUE}
**Snijders and Bosker Formula Extended - Level 2 ** 
$$
R^2_2 = 1 - \frac{\frac{\sigma^2_{e-MC}}{B} + \sigma^2_{u0-MC}}
                 {\frac{\sigma^2_{e-BL}}{B} + \sigma^2_{u0-BL}}
$$

$B$ is the average size of the Level 2 units (schools).  Technically, you should use the *harmonic mean*, but unless the clusters differ greatly in size, it doesn't make a huge difference.
```




* Average sample cluster size
```{r}
num_subjects / num_schools
```


* Calculate by hand:
```{r}
1 - ((3.766 / 64.5) + 0.100)/
    ((5.045 / 64.5) + 0.391)
```

This means that over two-thrids in school mean reading levelsmay be explained by their student's vocabulary scores.


**Level 2 $R^2$ - Raudenbush and Bryk**

```{block type='genericEq', echo=TRUE}
**Raudenbush and Bryk Approximate Formula - Level 2 ** 
$$
R^2_1 = \frac{\sigma^2_{u0-BL} - \sigma^2_{u0-MC}}
                 {\sigma^2_{u0-BL} }
\tag{Hox 4.9}
$$
```


```{r}
(0.392 - 0.100)/(0.392)
```


Remeber that these 'variance accounted for' estimations are not as straight forwards as we would like.  



### Investigate More Level 1 Predictors

Part of investigating lower level explanatory variables, is checking for interactions between these variables.  The interaction between fixed effects is also considered to be a fixed effect, so we need to employ *Maximum Likelihood* estimation to compare nested models.

```{r}
fit_read_2ml <- lmer(geread ~ gevocab + age + (1 | school), # add main effect of age
                     data = data_achieve,
                     REML = FALSE)

fit_read_3ml <- lmer(geread ~ gevocab*age + (1 | school), # add interaction between vocab and age
                     data = data_achieve,
                     REML = FALSE)
```


```{r, include = FALSE}
texreg::screenreg(list(fit_read_1ml, fit_read_2ml, fit_read_3ml))
```


```{r, results='asis'}
# Knit to Website: texreg::htmlreg()
# Knit to PDF:     texreg::texreg()
# View on Screen:  texreg::screenreg()

texreg::htmlreg(list(fit_read_1ml, 
                     fit_read_2ml, 
                     fit_read_3ml),
                custom.model.names = c("Only Vocab", 
                                       "Both Main Effects", 
                                       "Interaction"),
                caption = "MLM: Investigate Other Fixed Pupil-level Predictors",
                caption.above = TRUE,
                doctype = FALSE,
                digits = 4)
```

#### Assess Significance of Effects

Likelihood Ratio Test (LRT)

```{r}
anova(fit_read_1ml, fit_read_2ml, fit_read_3ml)
```


Not only is student's age predictive of their reading level (I could have guessed that), but that age moderated the relationship between vocabulary and reading.


#### Visulaize the Interation

Visulaizations are extremely helpful to interpred interactions.

```{r}
summary(data_achieve$age)
```


```{r}
effects::Effect(focal.predictors = c("gevocab", "age"),   # variables involved in the interaction
                mod = fit_read_3ml,
                xlevels = list(age = c(84, 108, 132))) %>%  # age is in months
  data.frame() %>% 
  mutate(age_yr = factor(age/12)) %>%    # it would be nice to plot age in years 
  ggplot(aes(x = gevocab,
             y = fit,
             color = age_yr)) +
  geom_line() +
  theme_bw()
```

There is a positive association between vocabulary and reading, but it is strongest for older childred.  Among younger children, reading scores are more stable across vocabulary differences. 


<!-- ========================================================= -->
## MLM - Step 3: Higher-level explanatory variables, fixed, ML
<!-- ========================================================= -->

School enrollment (`senroll`) applies to each school as a whole.  When a variable is measured at a higher level, all units in the same group have the same value.  In this case, all student in the same school have the same value for `senroll`.  

```{r}
fit_read_4ml <- lme4::lmer(geread ~ gevocab*age + senroll + (1 | school), 
                           data = data_achieve,
                           REML = FALSE)
```


```{r, include=FALSE}
texreg::screenreg(list(fit_read_0ml, fit_read_3ml, fit_read_4ml))
```


```{r, results='asis'}
# Knit to Website: texreg::htmlreg()
# Knit to PDF:     texreg::texreg()
# View on Screen:  texreg::screenreg()

texreg::htmlreg(list(fit_read_0ml, 
                     fit_read_3ml, 
                     fit_read_4ml),
                custom.model.names = c("Null", 
                                       "Level 1 only", 
                                       "Level 2 Pred"),
                caption            = "MLM: Investigate a Fixed School-Level Predictor",
                caption.above      = TRUE,
                single.row         = TRUE)
```


### Assess Significance of Effects

Likelihood Ratio Test (LRT)
```{r}
anova(fit_read_0ml, fit_read_3ml, fit_read_4ml)
```

School enrollment (or size) does not seem be related to reading scores.


<!-- ========================================================= -->
## MLM - Step 4: Explanatory variables predict Slopes, random, REML
<!-- ========================================================= -->

**Random Coefficient** models - decompose the SLOPE variance BETWEEN groups. 

The fixed effect of the predictor captures the overall association it has with the outcome (intercept), while the random effect of the predictor captures the group-to-group variation in the association (slope).  *Note: A variable can be fit as BOTH a fixed and random effect.*  

```{r}
fit_read_3re <- lme4::lmer(geread ~ gevocab*age + (1 | school), # refit the previous 'best' model via REML
                     data = data_achieve,
                     REML = TRUE)

#fit_read_5re <- lmer(geread ~ gevocab + (gevocab | school), 
#                     data = achieve,
#                     REML = TRUE)         # failed to converge :(

fit_read_5re <- lme4::lmer(geread ~ gevocab*age + (gevocab | school), 
                           data = data_achieve,
                           REML = TRUE,
                           control = lmerControl(optimizer = "optimx",    # get it to converge
                                                 calc.derivs = FALSE,
                                                 optCtrl = list(method = "nlminb",
                                                                starttests = FALSE,
                                                                kkt = FALSE))) 
```



```{r, include=FALSE}
texreg::screenreg(list(fit_read_3re, fit_read_5re))
```

```{r, results='asis'}
# Knit to Website: texreg::htmlreg()
# Knit to PDF:     texreg::texreg()
# View on Screen:  texreg::screenreg()

texreg::htmlreg(list(fit_read_3re, 
                     fit_read_5re),
                custom.model.names = c("Rand Int", 
                                       "Rand Int and Slopes"),
                caption            = "MLM: Investigate Random Effects",
                caption.above      = TRUE,
                single.row         = TRUE)
```




#### Assess Significance of Effect


```{block type='rmdlightbulb', echo=TRUE}
Likelihood Ratio Test (LRT) for Random Effects

You can use the Chi-squared LRT test based on deviances even though we fit our modesl with REML, since the models only differ in terms of including/exclusing of a random effects; they have same fixed effects.  Just make sure to include the `refit = FALSE` option.
```


```{r}
anova(fit_read_3re, fit_read_5re, refit = FALSE)
```

There is evidence the effect child vocabulary has on reading varies across schools.


#### Visualize the Model

What does the model look like?

```{r}
effects::Effect(focal.predictors = c("gevocab", "age"), 
                mod = fit_read_5re,                              # just different model
                xlevels = list(age = c(84, 108, 132))) %>% 
  data.frame() %>% 
  dplyr::mutate(age_yr = factor(age/12)) %>% 
  ggplot(aes(x = gevocab,
             y = fit,
             color = age_yr)) +
  geom_line() +
  theme_bw()
```

We are seeming much the same trends, but perhaps more separation between the lines.

<!-- ========================================================= -->
## MLM - Step 5: Cross-Level interactions between explanatory variables - fixed, ML
<!-- ========================================================= -->

Cross-level interacitons involve variables at different levels.  Here we will investigate the school-level enrollment moderating vocabulary's effect since we say that vocab's effect differs across schools (step 4).

Remember that an interaction beween fixed effects is also fixed.  

```{r}
fit_read_5ml <- lme4::lmer(geread ~ gevocab*age + (gevocab | school), 
                           data = data_achieve,
                           REML = FALSE,
                           control = lmerControl(optimizer = "optimx", 
                                                 calc.derivs = FALSE,
                                                 optCtrl = list(method = "nlminb",
                                                                starttests = FALSE,
                                                                kkt = FALSE)))

fit_read_6ml <- lme4::lmer(geread ~ gevocab*age + senroll + (gevocab | school), 
                           data = data_achieve,
                           REML = FALSE)

fit_read_7ml <- lme4::lmer(geread ~ gevocab*age + gevocab*senroll + (gevocab | school), 
                           data = data_achieve,
                           REML = FALSE)

fit_read_8ml <- lme4::lmer(geread ~ gevocab*age*senroll + (gevocab | school), 
                           data = data_achieve,
                           REML = FALSE)
```

```{block type='rmdlightbulb', echo=TRUE}
If you get the`lmer()` message: **Some predictor variables are on very different scales: consider rescaling**, you can trust your results, but you really should try re-scaling your variables.
```

We are getting this message since `gevoab` is on mostly a single digit scale,0 to 11.2, and age (in months) ranges in the low thripe-digits, 82 through 135, while school enrollment is in the mid-hundreds, 112-916.  When we compute the interactions we get much, much larger values.  Having variables on such widely different ranges of values can cause estimation problems.

```{r}
data_achieve %>% 
  dplyr::mutate(gevocab_x_age            = gevocab*age,
                gevocab_x_senroll        = gevocab*senroll,
                gevocab_x_age_x_senroll  = gevocab*senroll*age) %>% 
  dplyr::select(gevocab, age, senroll, gevocab_x_age, gevocab_x_senroll, gevocab_x_age_x_senroll) %>% 
  summary()
```

For now, let us look at the results.

```{r, include = FALSE}
texreg::screenreg(list(fit_read_3ml, fit_read_6ml, fit_read_7ml, fit_read_8ml))
```

```{r, results='asis'}
# Knit to Website: texreg::htmlreg()
# Knit to PDF:     texreg::texreg()
# View on Screen:  texreg::screenreg()

texreg::htmlreg(list(fit_read_3ml, 
                     fit_read_6ml, 
                     fit_read_7ml,
                     fit_read_8ml),
                custom.model.names = c("Level 1 only", 
                                       "Both Levels", 
                                       "Cross-Level",
                                       "3-way"),
                caption            = "MLM: Investigate a Fixed Cross-level Interaction",
                caption.above      = TRUE,
                single.row         = TRUE)
```

There is no evidence school enrollment moderates either of age or vocabulary's effects.


#### Assess Significance of Effects

Likelihood Ratio Test (LRT)

When you have a list of sequentially nested models, you can test them in order with one call to the `anova()` funtion.

```{r}
anova(fit_read_3ml, fit_read_6ml, fit_read_7ml, fit_read_8ml)
```


<!-- ========================================================= -->
## Centering Predictors: Change Center
<!-- ========================================================= -->

Centering variables measured on the lowest level only involves subtacting the mean from every value.  The spread or standard deviation is not changed.

```{block type='rmdlightbulb', echo=TRUE}
Although there are functions to automatically center and standardize variables, it is beneficial to manually create these variables, as it is more transparent and facilitates un-centering them later.
```

### Compute the Grand Means

```{r, results='asis'}
# Knit to Website: output = "html" 
# Knit to PDF:     output = "latex2"
# View on Screen:  output = ""text", or "markdown", "html"

data_achieve %>% 
  furniture::table1(gevocab, age, senroll,
                    output = "html",
                    digits = 4)
```

#### Subtract the Grand Mean

Subract the grand-mean from each observation's vale to create grand-mean centered variables.

```{r}
data_achieve_center <- data_achieve %>% 
  dplyr::mutate(gevocab_c = gevocab - 4.4938) %>% 
  dplyr::mutate(age_c     = age     - 107.5290) %>% 
  dplyr::mutate(senroll_c = senroll - 533.4148)
```



#### Compare the centered and uncentered measures

View the first and last few observations:

```{r}
data_achieve_center %>% 
  dplyr::select(id, school, 
                gevocab, gevocab_c, 
                age,     age_c, 
                senroll, senroll_c) %>% 
  headTail()
```

Compare the summary statistcs:

```{r, results='asis'}
# Knit to Website: output = "html" 
# Knit to PDF:     output = "latex2"
# View on Screen:  output = ""text", or "markdown", "html"

data_achieve_center %>% 
  furniture::table1(gevocab, gevocab_c, 
                    age,     age_c, 
                    senroll, senroll_c,
                    output = "html",
                    digits = 4)
```

### Use Centered Variables


NOTE:  The models with CENTERED variables are able to be fit with the default optimizer settings and do not return the error: "unable to evaluate scaled gradientModel failed to converge: degenerate  Hessian with 1 negative eigenvalues"

```{r}
fit_read_9ml <- lme4::lmer(geread ~ gevocab + age + (gevocab | school), 
                           data = data_achieve_center,
                           REML = FALSE,
                             control = lmerControl(optimizer = "optimx", 
                                                   calc.derivs = FALSE,
                                                   optCtrl = list(method = "nlminb",
                                                                  starttests = FALSE,
                                                                  kkt = FALSE)))

fit_read_10ml <- lme4::lmer(geread ~ gevocab*age + (gevocab | school), 
                           data = data_achieve_center,
                           REML = FALSE,
                             control = lmerControl(optimizer = "optimx", 
                                                   calc.derivs = FALSE,
                                                   optCtrl = list(method = "nlminb",
                                                                  starttests = FALSE,
                                                                  kkt = FALSE)))



fit_read_9ml_c <- lme4::lmer(geread ~ gevocab_c + age_c + (gevocab_c | school), 
                             data = data_achieve_center,
                             REML = FALSE)

fit_read_10ml_c <- lme4::lmer(geread ~ gevocab_c*age_c + (gevocab_c | school), 
                             data = data_achieve_center,
                             REML = FALSE)
```




#### Compare the Models

```{r, include=FALSE}
texreg::screenreg(list(fit_read_9ml, fit_read_10ml, fit_read_9ml_c, fit_read_10ml_c))
```


```{r, results='asis'}
# Knit to Website: texreg::htmlreg()
# Knit to PDF:     texreg::texreg()
# View on Screen:  texreg::screenreg()

texreg::htmlreg(list(fit_read_9ml, 
                     fit_read_10ml, 
                     fit_read_9ml_c, 
                     fit_read_10ml_c),
                custom.model.names = c("Main Effects", 
                                       "Interaction",
                                       "Main Effects", 
                                       "Interaction"),
                groups = list("Raw Scale" = 2:4,
                              "Mean Centered" = 5:7),
                caption            = "MLM: Investigate Centering Variables Involved in an Interaction",
                caption.above      = TRUE,
                single.row         = TRUE)
```


Notice that the interactions yield the exact same parameter estimates and significances, but the main effects (including the interactions) are different.  Model fit statistics include $-2LL$ are exactly the same, too.



```{r}
anova(fit_read_9ml, fit_read_10ml)
```

```{r}
anova(fit_read_9ml_c, fit_read_10ml_c)
```


#### Visualize the Model

What does the model look like?

First plot the model fit to the centered variables with all defaut settings.

```{r}
effects::Effect(focal.predictors = c("gevocab_c", "age_c"),
                mod = fit_read_10ml_c) %>%  
  data.frame() %>% 
  dplyr::mutate(age_c = factor(age_c)) %>% 
  ggplot(aes(x = gevocab_c,
             y = fit,
             color = age_c)) +
  geom_line() +
  theme_bw()
```

Notice that the vocab and ages are centered at zero.  This makes it hard to read the plot, especially if we are unsure what the means of the variables were.


Plot the model again, but this time UN-centering the variables by adding back the grand-mean we subtracted prior to fitting the model.

```{r}
effects::Effect(focal.predictors = c("gevocab_c", "age_c"),
                mod = fit_read_10ml_c,
                xlevels = list(age_c = c(84, 108, 132) - 107.5290)) %>%  # add back the mean of age
  data.frame() %>% 
  dplyr::mutate(age_yrs = factor((age_c + 107.5290)/12)) %>%        # add back the mean of age
  dplyr::mutate(gevocab = gevocab_c + 4.4938) %>%                   # add back the mean of vocab
  ggplot(aes(x = gevocab,
             y = fit,
             color = age_yrs)) +
  geom_line() +
  theme_bw()
```


Now the plot is back on to the origial variables.


<!-- ========================================================= -->
## Rescaling Predictors: Change Units or Standardize
<!-- ========================================================= -->


Where centering variables involved subtracting a set value, scalling a varaibles involves dividing by a set amount.  When we both center to the mean and divide by the standard deviation, the new resulting varaible is said to be standardized (not to be confusing with normalizing, which is does not do).  

To retain meaningful units, you can multiply or divide all the measured values of a variable by a set amount, like a multiple of 10.  This retains the meaning behind the units while still bringing them into line with other variables in the model and can avoid some convergence issues.

### Scale Varaibles

#### Divide by a Meaningful Value

```{r}
data_achieve_center %>% 
  dplyr::select(senroll_c, ses) %>% 
  summary()
```



For this situation, lets both center at the mean and scale (by 100) the school enrollemnt variable.  For SES, lets only divide by ten.

```{r}
data_achieve_center_scale <- data_achieve_center %>%  
  dplyr::mutate(senroll_ch = senroll_c / 100) %>%    # centered AND divided by one hundred
  dplyr::mutate(ses_t      = ses / 10)               # JUST divide by ten
```



#### Compare the scaled and unscaled measures

View the first and last few observations:

```{r}
data_achieve_center_scale %>% 
  dplyr::select(id, school, 
                age_c, gevocab_c,
                senroll, senroll_c, senroll_ch,
                ses, ses_t) %>% 
  headTail()
```

Compare the summary statistcs:

```{r, results='asis'}
# Knit to Website: output = "html" 
# Knit to PDF:     output = "latex2"
# View on Screen:  output = ""text", or "markdown", "html"

data_achieve_center_scale %>% 
  furniture::table1(senroll, senroll_c, senroll_ch,
                    ses, ses_t,
                    output = "html",
                    digits = 4)
```

### Use Scaled Variables

Using the new versions of our variables, investigate is SES has an effect, either in 2-way or 3-way interactions with age and vocabulary.

```{r}
fit_read_10ml_s <- lme4::lmer(geread ~ gevocab_c*age_c +                     # no SES
                                      (gevocab_c | school),  
                             data   = data_achieve_center_scale,
                             REML   = FALSE)


fit_read_11ml_s <- lme4::lmer(geread ~ gevocab_c*age_c + gevocab_c*ses_t +   # 2 2-way interactions
                                      (gevocab_c | school),  
                             data   = data_achieve_center_scale,
                             REML   = FALSE)

fit_read_12ml_s <- lme4::lmer(geread ~ gevocab_c*age_c*ses_t +              # 3-way interaction
                                      (gevocab_c | school),  
                             data   = data_achieve_center_scale,
                             REML  = FALSE)
```


```{r, include = FALSE}
texreg::screenreg(list(fit_read_10ml_s, fit_read_11ml_s, fit_read_12ml_s))
```

```{r, results='asis'}
# Knit to Website: texreg::htmlreg()
# Knit to PDF:     texreg::texreg()
# View on Screen:  texreg::screenreg()

texreg::htmlreg(list(fit_read_10ml_s, 
                     fit_read_11ml_s, 
                     fit_read_12ml_s),
                custom.model.names = c("no SES", 
                                       "2-way", 
                                       "3-way"),
                caption            = "MLM: Investigate More Complex Fixed Interactions",
                caption.above      = TRUE,
                single.row         = TRUE)
```


```{r}
anova(fit_read_10ml_s, fit_read_11ml_s, fit_read_12ml_s)
```

There is evidence that SES moderates the main effect of vocabualry, after accounting for the interaction between age and vocabulary.


## Final Model

Always refit the final model via REML.

```{r}
fit_read_11re_s <- lme4::lmer(geread ~ gevocab_c*age_c + gevocab_c*ses_t +   # 2 2-way interactions
                                      (gevocab_c | school),  
                             data   = data_achieve_center_scale,
                             REML   = TRUE)
```

### Table

```{r, results='asis'}
# Knit to Website: texreg::htmlreg()
# Knit to PDF:     texreg::texreg()
# View on Screen:  texreg::screenreg()

texreg::htmlreg(list(fit_read_11re_s),
                caption            = "MLM: Final Model",
                caption.above      = TRUE,
                single.row         = TRUE)
```


#### Visualize the Model

Recall the scales that the revised variables are now on:

```{r}
data_achieve_center_scale %>% 
  dplyr::select(gevocab_c, age_c, ses_t) %>% 
  summary()
```


```{r}
effects::Effect(focal.predictors = c("gevocab_c", "age_c", "ses_t"),
                mod = fit_read_11re_s,
                xlevels = list(age_c = c(84, 108, 132) - 107.5290, 
                               ses_t = c(0, 5, 10))) %>%  
  data.frame() %>% 
  dplyr::mutate(age_yrs = factor((age_c + 107.5290)/12)) %>% 
  dplyr::mutate(gevocab = gevocab_c + 4.4938) %>% 
  dplyr::mutate(ses     = factor(ses_t * 10)) %>% 
  ggplot(aes(x = gevocab,
             y = fit,
             color = age_yrs)) +
  geom_line() +
  theme_bw() +
  facet_grid(.~ ses, labeller = "label_both") +
  labs(x = "Vocabulary Score",
       y = "Reading Score\nEstimated Marginal Mean",
       color = "Student Age")
```


There is evidence that higher vocabulary scores correlate with higher reading scores.  This relationship os strongest in low SES schools and among older students.  This relationship is especially weaker in younger students attending high SES schools.


See: @nakagawa2013 for more regarding model $R^2$

From the `sjstats::r2()` documentation, for mixed models:    

* **marginal r-squared** considers only the variance of the fixed effects    
* **conditional r-squared** takes both the fixed and random effects into account

```{r}
sjstats::r2(fit_read_11re_s)
```


---- 

Helpful links:

http://maths-people.anu.edu.au/~johnm/r-book/xtras/mlm-ohp.pdf

http://ase.tufts.edu/gsc/gradresources/guidetomixedmodelsinr/mixed%20model%20guide.html 

http://web.stanford.edu/class/psych252/section_2015/Section_week9.html 

https://www.r-bloggers.com/visualizing-generalized-linear-mixed-effects-models-with-ggplot-rstats-lme4/ 

https://www.r-bloggers.com/visualizing-generalized-linear-mixed-effects-models-part-2-rstats-lme4/ 

http://www.strengejacke.de/sjPlot/sjp.lmer/

<!--chapter:end:07-example_finch_read.Rmd-->

# Centering and Standardizing Explanitory Variables



![](images/header_hox_popular2.png)

```{r, include=FALSE}
knitr::opts_chunk$set(comment     = "",
                      echo        = TRUE, 
                      warning     = FALSE, 
                      message     = FALSE,
                      fig.align   = "center", # center all figures
                      fig.width   = 6,        # set default figure width to 4 inches
                      fig.height  = 4)        # set default figure height to 3 inches
```

```{r, message=FALSE, error=FALSE}
library(tidyverse)    # all things tidy
library(broom)        # converst stats objestcs to tidy tibbles
library(haven)        # read in SPSS dataset
library(furniture)    # nice table1() descriptives
library(stargazer)    # display nice tables: summary & regression
library(texreg)       # Convert Regression Output to LaTeX or HTML Tables
library(psych)        # contains some useful functions, like headTail
library(sjstats)      # ICC calculations

library(lme4)         # non-linear mixed-effects models

library(haven)        # read in SPSS dataset
```

## Background

```{block type='rmdlink', echo=TRUE}
The text **"Multilevel Analysis: Techniques and Applications, Third Edition"** [@hox2017] has a companion [website](https://multilevel-analysis.sites.uu.nl/) which includes links to all the data files used throughout the book (housed on the [book's GitHub repository](https://github.com/MultiLevelAnalysis)).  
```


The following example is used through out @hox2017's chapater 2.

> From **Appendix E**:  
>
> The popularity data in **popular2.sav** are simulated data for **2000 pupils in 100 schools**. The purpose is to offer a very simple example for multilevel regression analysis.  The main outcome variable is the **pupil popularity**, a popularity rating on a scale of 1-10 derived by a sociometric procedure. Typically, a sociometric procedure asks all pupils in a class to rate all the other pupils, and then assigns the average received popularity rating to each pupil.  Because of the sociometric procedure, group effects as apparent from higher level variance components are rather strong. There is a second outcome variable: **pupil popularity** as rated by their teacher, on a scale from 1-10.  The explanatory variables are **pupil gender** (boy=0, girl=1), **pupil extraversion** (10-point scale) and **teacher experience** in years.  The popularity data have been generated to be a 'nice' well-behaved data set: the sample sizes at both levels are sufficient, the residuals have a normal distribution, and the multilevel effects are strong.

![](images/diagram_hox_popular2.png)


```{r}
data_raw <- haven::read_sav("https://github.com/MultiLevelAnalysis/Datasets-third-edition-Multilevel-book/raw/master/chapter%202/popularity/SPSS/popular2.sav") %>% 
  haven::as_factor()             # retain the labels from SPSS --> factor

data_pop <- data_raw %>%   
  dplyr::mutate(id = paste(class, pupil,
                           sep = "_") %>%   # create a unique id for each student (char)
                  factor()) %>%             # declare id is a factor
  dplyr::select(id, pupil:popteach)         # reduce the variables included

tibble::glimpse(data_pop)
```




```{r}
data_pop %>% 
  ggplot() +
  aes(x = extrav,
      y = popular,
      group = class) +
  geom_smooth(method = "lm",
              se = FALSE,
              color = "black",
              size = .2) +
  theme_bw() +
  geom_vline(xintercept = 0,
             color = "red") +
  labs(title = "OLS: Single Level Regression",
       subtitle = "Thin black lines are OLS regression ran independently on each class",
       x = "Student's Extroversion, as rated by their teacher",
       y = "Student's Populartity, mean rating by their peers") +
  coord_cartesian(xlim = c(0, 10),
                  ylim = c(0, 10)) +
  scale_x_continuous(breaks = seq(from = 0, to = 10, by = 2)) +
  scale_y_continuous(breaks = seq(from = 0, to = 10, by = 2))
```




## Grand-Mean-Centering and Standardizing Variables


It is best to manually determine the variable's mean (`mean()`) and standard deviation (`sd()`).

```{r}
mean(data_pop$extrav)
sd(data_pop$extrav)
```


### Grand-Mean-Centering

$$
VAR_G = VAR - mean(VAR)
$$


### Standardizing

$$
VAR_Z = \frac{VAR - mean(VAR)}{sd(VAR)}
$$




```{r}
data_pop <- data_pop %>% 
  dplyr::mutate(extravG =  extrav - 5.215) %>% 
  dplyr::mutate(extravZ = (extrav - 5.215) / 1.262368)
```




```{r, include = FALSE}
data_pop %>% 
  dplyr::select(extrav, extravG, extravZ) %>% 
  data.frame() %>% 
  stargazer::stargazer(title  = "Descriptive statistics: Three versions of Extraversion",
                       header = FALSE,
                       type   = "text")
```

```{r, results="asis"}
data_pop %>% 
  dplyr::select(extrav, extravG, extravZ) %>% 
  data.frame() %>% 
  stargazer::stargazer(title  = "Descriptive statistics: Three versions of Extraversion",
                       header = FALSE,
                       type   = "html")
```


## RI = ONLY Random Intercepts

### Fit MLM with all 3 versions of the predictor

```{r}
pop_lmer_1_raw <- lme4::lmer(popular ~ extrav + (1|class),
                           data = data_pop,
                           REML = FALSE)

pop_lmer_1_cen <- lme4::lmer(popular ~ extravG + (1|class),
                           data = data_pop,
                           REML = FALSE)

pop_lmer_1_std <- lme4::lmer(popular ~ extravZ + (1|class),
                           data = data_pop,
                           REML = FALSE)
```


```{r, include=FALSE}
texreg::screenreg(list(pop_lmer_1_raw, pop_lmer_1_cen, pop_lmer_1_std))
```


```{r, results='asis'}
# Knit to Website: texreg::htmlreg()
# Knit to PDF:     texreg::texreg()
# View on Screen:  texreg::screenreg()

texreg::htmlreg(list(pop_lmer_1_raw, 
                     pop_lmer_1_cen, 
                     pop_lmer_1_std),
                custom.model.names = c("Raw", 
                                       "Centered", 
                                       "Standardized"),
                caption            = "MLM - RI: Effect of Grand-Mean Centering and Standardizing",
                caption.above      = TRUE,
                single.row         = TRUE)
```




```{block type='rmdimportant', echo=TRUE}
** MLM - Random Intercepts ONLY**

1. Grand-Mean Centering a Predictor    

* Different than when using the Raw Predictor:    
    + fixed intercept
    
* Same as when using the Raw Predictor: 
    + fixed estimates or slopes for all predictors (main effects and interactions)    
    + random estimates, i.e. variance and covariance components, includin the residual variance
    + model fit statistics, including AIC, BIC, and the Log Loikelihood (-2LL or deviance)
    

2. Standardize a Predictor    

* Different than when using the Raw Predictor:    
    + fixed intercept (same as if using the grand-mean centered predictor)    
    + fixed estimate (slope) for that variable
    
* Stays the SAME:    
    + random estimates, i.e. variance and covariance components, includin the residual variance  
    + model fit statistics, including AIC, BIC, and the Log Loikelihood (-2LL or deviance)    
```




### Investigating a MLM-RI Model



```{r}
pop_lmer_1_raw %>% 
  broom::tidy()
```


```{r}
pop_lmer_1_raw %>% 
  broom::glance()
```


```{r}
pop_lmer_1_raw %>% 
  broom::augment() %>% 
  head()                  # onle line per observation (2000 students)
```





#### Fixed Effects: intercept and slope

There is only ONE fixed intercept and ONE fixed slope.

The `fixef()` function extracts the estimates of the fixed effects.


```{r}
fixef(pop_lmer_1_raw) 
```

```{r}
fixef(pop_lmer_1_raw)[["(Intercept)"]]
```

```{r}
fixef(pop_lmer_1_raw)[["extrav"]]
```


```{r}
data_pop %>% 
  ggplot() +
  aes(x = extrav,
      y = popular,
      group = class) +
  geom_smooth(method = "lm",
              se = FALSE,
              color = "black",
              size = .2) +
  geom_abline(intercept = fixef(pop_lmer_1_raw)[["(Intercept)"]],
              slope     = fixef(pop_lmer_1_raw)[["extrav"]],
              color = "hot pink",
              size = 2) +
  theme_bw() +
  geom_vline(xintercept = 0,
             color = "red") +
  labs(title = "MLM-RI: Extroversion = raw score",
       subtitle = "Thin black lines are OLS regression ran independently on each class",
       x = "Student's Extroversion, as rated by their teacher",
       y = "Student's Populartity, mean rating by their peers") +
  coord_cartesian(xlim = c(0, 10),
                  ylim = c(0, 10)) +
  scale_x_continuous(breaks = seq(from = 0, to = 10, by = 2)) +
  scale_y_continuous(breaks = seq(from = 0, to = 10, by = 2))
```




#### Random Effects: intercepts

There is a different random intercept for EACH CLASS.  These tell how far each class's average is off of the grand average.

The `ranef()` function extracts the random effects from a fitted model object

```{r}
ranef(pop_lmer_1_raw) %>% 
  str()
```

```{r}
ranef(pop_lmer_1_raw)$class %>% 
  head()                  # onle line per group (100 classes)
```

```{r, fig.width=3, fig.height=2.25}
ranef(pop_lmer_1_raw)$class %>% 
  dplyr::rename(Random_Intercepts = "(Intercept)") %>% 
  ggplot(aes(Random_Intercepts)) +
  geom_histogram(binwidth = .25)
```


#### Predictions


```{r}
predict(pop_lmer_1_raw) %>% 
  str()
```

```{r}
predict(pop_lmer_1_raw) %>% 
  head()                  # onle value per observation (2000 students)
```


```{r}
data_pop %>% 
  dplyr::mutate(pred = predict(pop_lmer_1_raw)) %>% 
  ggplot(aes(x = extrav,
             y = pred,
             group = class)) +
  geom_line(size = .2) +
  geom_abline(intercept = fixef(pop_lmer_1_raw)[["(Intercept)"]],
              slope     = fixef(pop_lmer_1_raw)[["extrav"]],
              color = "hot pink",
              size = 2) +
  theme_bw() +
  geom_vline(xintercept = 0,
             color = "red") +
  geom_vline(xintercept = 5.215,
             color = "blue") +
  labs(title = "MLM-RI: Extroversion = raw score",
       subtitle = "Thin black lines are group-wise predictions, one per class",
       x = "Student's Extroversion, as rated by their teacher",
       y = "Predicted\nStudent's Populartity, mean rating by their peers") +
  coord_cartesian(xlim = c(0, 10),
                  ylim = c(0, 10)) +
  scale_x_continuous(breaks = seq(from = 0, to = 10, by = 2)) +
  scale_y_continuous(breaks = seq(from = 0, to = 10, by = 2))
```



#### Combined Effects

The `coef()` function computes the sum of the random and fixed effects coefficients for each explanatory variable for each level of each grouping factor.

```{r}
coef(pop_lmer_1_raw) %>% 
  str()
```

```{r}
coef(pop_lmer_1_raw)$class %>% 
  head()                  # onle line per group (100 classes)
```


```{r}
data_pop %>% 
  dplyr::mutate(pred = predict(pop_lmer_1_raw)) %>% 
  ggplot() +
  aes(x = extrav,
      y = pred,
      group = class) +
  geom_rect(aes(xmin = 0 - 0.25, 
                xmax = 0 + 0.25,
                ymin = fixef(pop_lmer_1_raw)[["(Intercept)"]]- 2.5,
                ymax = fixef(pop_lmer_1_raw)[["(Intercept)"]]+ 2.5),
            fill = "yellow",
            alpha = 0.05) +
  geom_abline(data = coef(pop_lmer_1_raw)$class %>% dplyr::rename(Intercept = "(Intercept)"),
              aes(intercept = Intercept,
                  slope     = extrav),
              color = "gray",
              size = .1) +
  geom_line(size = .2) +
  geom_abline(intercept = fixef(pop_lmer_1_raw)[["(Intercept)"]],
              slope     = fixef(pop_lmer_1_raw)[["extrav"]],
              color = "hot pink",
              size = 2) +
  theme_bw() +
  geom_vline(xintercept = 0,
             color = "red") +
  geom_vline(xintercept = 5.215,
             color = "blue") +
  labs(title = "MLM-RI: Extroversion = raw score",
       subtitle = "Thin black lines are group-wise predictions, one per class EXTRAPOLATED OUT",
       x = "Student's Extroversion, as rated by their teacher",
       y = "Predicted\nStudent's Populartity, mean rating by their peers") +
  coord_cartesian(xlim = c(0, 10),
                  ylim = c(0, 10)) +
  scale_x_continuous(breaks = seq(from = 0, to = 10, by = 2)) +
  scale_y_continuous(breaks = seq(from = 0, to = 10, by = 2)) 
```




### Comapre the Centered Version

```{r}
data_pop %>% 
  dplyr::mutate(pred = predict(pop_lmer_1_cen)) %>%
  ggplot() +
  aes(x = extravG,
      y = pred,
      group = class) +
  geom_rect(aes(xmin = -5.215 - 0.25, 
                xmax = -5.215 + 0.25,
                ymin = fixef(pop_lmer_1_raw)[["(Intercept)"]]- 2.5,
                ymax = fixef(pop_lmer_1_raw)[["(Intercept)"]]+ 2.5),
            fill = "yellow",
            alpha = 0.05) +
  geom_rect(aes(xmin = 0 - 0.25, 
                xmax = 0 + 0.25,
                ymin = fixef(pop_lmer_1_cen)[["(Intercept)"]]- 2.5,
                ymax = fixef(pop_lmer_1_cen)[["(Intercept)"]]+ 2.5),
            fill = "yellow",
            alpha = 0.05) +
  geom_abline(data = coef(pop_lmer_1_cen)$class %>% dplyr::rename(Intercept = "(Intercept)"),
              aes(intercept = Intercept,
                  slope     = extravG),
              color = "gray",
              size = .1) +
  geom_line(size = .2) +
  geom_abline(intercept = fixef(pop_lmer_1_cen)[["(Intercept)"]],
              slope     = fixef(pop_lmer_1_cen)[["extravG"]],
              color = "hot pink",
              size = 2) +
  theme_bw() +
  geom_vline(xintercept = -5.215,
             color = "blue") +
  geom_vline(xintercept = 0,
             color = "red") +
  labs(title = "MLM-RI: Extroversion = grand-mean centered",
       subtitle = "Thin black lines are group-wise predictions, one per class EXTRAPOLATED OUT",
       x = "GRAND-MEAN CENTERED Student's Extroversion, as rated by their teacher",
       y = "Predicted\nStudent's Populartity, mean rating by their peers") +
  coord_cartesian(xlim = c(-5, 5),
                  ylim = c(0, 10)) +
  scale_x_continuous(breaks = seq(from = -4, to =  4, by = 2)) +
  scale_y_continuous(breaks = seq(from =  0, to = 10, by = 2))
```



### Comapre the Standardized Version

```{r}
data_pop %>% 
  dplyr::mutate(pred = predict(pop_lmer_1_std)) %>% 
  ggplot() +
  aes(x = extravZ,
      y = pred,
      group = class) +
  geom_rect(aes(xmin = 0 - 0.25, 
                xmax = 0 + 0.25,
                ymin = fixef(pop_lmer_1_cen)[["(Intercept)"]]- 2.5,
                ymax = fixef(pop_lmer_1_cen)[["(Intercept)"]]+ 2.5),
            fill = "yellow",
            alpha = 0.05) +
  geom_abline(data = coef(pop_lmer_1_std)$class %>% dplyr::rename(Intercept = "(Intercept)"),
              aes(intercept = Intercept,
                  slope     = extravZ),
              color = "gray",
              size = .1) +
  geom_line(size = .2) +
  geom_abline(intercept = fixef(pop_lmer_1_std)[["(Intercept)"]],
              slope     = fixef(pop_lmer_1_std)[["extravZ"]],
              color = "hot pink",
              size = 2) +
  theme_bw() +
  geom_vline(xintercept = 0,
             color = "red") +
  geom_vline(xintercept = -5.215,
             color = "blue") +
  labs(title = "MLM-RI: Extroversion = standardized",
       subtitle = "Thin black lines are group-wise predictions, one per class EXTRAPOLATED OUT",
       x = "STANDARDIZED Student's Extroversion, as rated by their teacher",
       y = "Predicted\nStudent's Populartity, mean rating by their peers") +
  coord_cartesian(xlim = c(-5, 5),
                  ylim = c(0, 10)) +
  scale_x_continuous(breaks = seq(from = -4, to =  4, by = 2)) +
  scale_y_continuous(breaks = seq(from =  0, to = 10, by = 2))
```





## RIAS = Random Intercepts AND Slopes

### Fit MLM with all 3 versions of the predictor

```{r}
pop_lmer_2_raw <- lme4::lmer(popular ~ extrav + (extrav|class),
                           data = data_pop,
                           REML = FALSE)

pop_lmer_2_cen <- lme4::lmer(popular ~ extravG + (extravG|class),
                           data = data_pop,
                           REML = FALSE)

pop_lmer_2_std <- lme4::lmer(popular ~ extravZ + (extravZ|class),
                           data = data_pop,
                           REML = FALSE)
```


```{r, include=FALSE}
texreg::screenreg(list(pop_lmer_2_raw, pop_lmer_2_cen, pop_lmer_2_std))
```


```{r, results='asis'}
# Knit to Website: texreg::htmlreg()
# Knit to PDF:     texreg::texreg()
# View on Screen:  texreg::screenreg()

texreg::htmlreg(list(pop_lmer_2_raw, 
                     pop_lmer_2_cen, 
                     pop_lmer_2_std),
                custom.model.names = c("Raw", 
                                       "Centered", 
                                       "Standardized"),
                caption            = "MLM - RIAS: Effect of Grand-Mean Centering and Standardizing",
                caption.above      = TRUE,
                single.row         = TRUE)
```



```{block type='rmdimportant', echo=TRUE}
** MLM - Random Intercepts AND Slopes**

1. Grand-Mean Centering a Predictor    

* Different than when using the Raw Predictor:    
    + fixed intercept
    + random estimates, i.e. variance and covariance components, includin the residual variance
    
* Same as when using the Raw Predictor: 
    + fixed estimates or slopes for all predictors (main effects and interactions)    
    + model fit statistics, including AIC, BIC, and the Log Loikelihood (-2LL or deviance)
    

2. Standardize a Predictor    

* Different than when using the Raw Predictor:    
    + fixed intercept (same as if using the grand-mean centered predictor)    
    + fixed estimate (slope) for that variable
    + random estimates, i.e. variance and covariance components, includin the residual variance  
    
* Stays the SAME:    
    + model fit statistics, including AIC, BIC, and the Log Loikelihood (-2LL or deviance)    
```


### Investigating a MLM-RI Model


```{r}
pop_lmer_2_raw %>% 
  broom::tidy()
```


```{r}
pop_lmer_2_raw %>% 
  broom::glance()
```


```{r}
pop_lmer_2_raw %>% 
  broom::augment() %>% 
  head()                  # onle line per observation (2000 students)
```





#### Fixed Effects: intercept and slope

There is only ONE fixed intercept and ONE fixed slope.

The `fixef()` function extracts the estimates of the fixed effects.


```{r}
fixef(pop_lmer_2_raw) 
```

```{r}
fixef(pop_lmer_2_raw)[["(Intercept)"]]
```

```{r}
fixef(pop_lmer_2_raw)[["extrav"]]
```


```{r}
data_pop %>% 
  ggplot() +
  aes(x = extrav,
      y = popular,
      group = class) +
  geom_smooth(method = "lm",
              se = FALSE,
              color = "black",
              size = .2) +
  geom_abline(intercept = fixef(pop_lmer_2_raw)[["(Intercept)"]],
              slope     = fixef(pop_lmer_2_raw)[["extrav"]],
              color = "hot pink",
              size = 2) +
  theme_bw() +
  geom_vline(xintercept = 0,
             color = "red") +
  geom_vline(xintercept = 5.215,
             color = "blue") +
  labs(title = "MLM-RIAS: Extroversion = raw score",
       subtitle = "Thin black lines are OLS regression ran independently on each class",
       x = "Student's Extroversion, as rated by their teacher",
       y = "Student's Populartity, mean rating by their peers") +
  coord_cartesian(xlim = c(0, 10),
                  ylim = c(0, 10)) +
  scale_x_continuous(breaks = seq(from = 0, to = 10, by = 2)) +
  scale_y_continuous(breaks = seq(from = 0, to = 10, by = 2))
```



#### Random Effects: intercepts

There is a different random intercept AND random slope for EACH CLASS.  These tell how far each class's average is off of the grand average AND how far each class's slope is off of the grand average sope.

The `ranef()` function extracts the random effects from a fitted model object

```{r}
ranef(pop_lmer_2_raw) %>% 
  str()
```

```{r}
ranef(pop_lmer_2_raw)$class %>% 
  head()                  # onle line per group (100 classes)
```

```{r, fig.width=3, fig.height=2.25}
ranef(pop_lmer_2_raw)$class %>% 
  dplyr::rename(Random_Intercepts = "(Intercept)") %>% 
  ggplot(aes(Random_Intercepts)) +
  geom_histogram()
```

```{r, fig.width=3, fig.height=2.25}
ranef(pop_lmer_2_raw)$class %>% 
  ggplot(aes(extrav)) +
  geom_histogram()
```




#### Predictions


```{r}
predict(pop_lmer_2_raw) %>% 
  str()
```

```{r}
predict(pop_lmer_2_raw) %>% 
  head()                  # onle value per observation (2000 students)
```


```{r}
data_pop %>% 
  dplyr::mutate(pred = predict(pop_lmer_2_raw)) %>% 
  ggplot(aes(x = extrav,
             y = pred,
             group = class)) +
  geom_line(size = .2) +
  geom_abline(intercept = fixef(pop_lmer_2_raw)[["(Intercept)"]],
              slope     = fixef(pop_lmer_2_raw)[["extrav"]],
              color = "hot pink",
              size = 2) +
  theme_bw() +
  geom_vline(xintercept = 0,
             color = "red") +
  geom_vline(xintercept = 5.215,
             color = "blue") +
  labs(title = "MLM-RIAS: Extroversion = raw score",
       subtitle = "Thin black lines are group-wise predictions, one per class",
       x = "Student's Extroversion, as rated by their teacher",
       y = "Predicted\nStudent's Populartity, mean rating by their peers") +
  coord_cartesian(xlim = c(0, 10),
                  ylim = c(0, 10)) +
  scale_x_continuous(breaks = seq(from = 0, to = 10, by = 2)) +
  scale_y_continuous(breaks = seq(from = 0, to = 10, by = 2))
```




#### Combined Effects

The `coef()` function computes the sum of the random and fixed effects coefficients for each explanatory variable for each level of each grouping factor.

```{r}
coef(pop_lmer_1_raw) %>% 
  str()
```

```{r}
coef(pop_lmer_1_raw)$class %>% 
  head()                  # onle line per group (100 classes)
```


```{r}
data_pop %>% 
  dplyr::mutate(pred = predict(pop_lmer_2_raw)) %>% 
  ggplot() +
  aes(x = extrav,
      y = pred,
      group = class) +
  geom_rect(aes(xmin = 0 - 0.25, 
                xmax = 0 + 0.25,
                ymin = fixef(pop_lmer_2_raw)[["(Intercept)"]]- 4.5,
                ymax = fixef(pop_lmer_2_raw)[["(Intercept)"]]+ 4.5),
            fill = "yellow",
            alpha = 0.05) +
  geom_abline(data = coef(pop_lmer_2_raw)$class %>% dplyr::rename(Intercept = "(Intercept)"),
              aes(intercept = Intercept,
                  slope     = extrav),
              color = "gray",
              size = .1) +
  geom_line(size = .2) +
  geom_abline(intercept = fixef(pop_lmer_2_raw)[["(Intercept)"]],
              slope     = fixef(pop_lmer_2_raw)[["extrav"]],
              color = "hot pink",
              size = 2) +
  theme_bw() +
  geom_vline(xintercept = 0,
             color = "red") +
  geom_vline(xintercept = 5.215,
             color = "blue") +
  labs(title = "MLM-RIAS: Extroversion = raw score",
       subtitle = "Thin black lines are group-wise predictions, one per class EXTRAPOLATED OUT",
       x = "Student's Extroversion, as rated by their teacher",
       y = "Predicted\nStudent's Populartity, mean rating by their peers") +
  coord_cartesian(xlim = c(0, 10),
                  ylim = c(0, 10)) +
  scale_x_continuous(breaks = seq(from = 0, to = 10, by = 2)) +
  scale_y_continuous(breaks = seq(from = 0, to = 10, by = 2)) 
```





### Comapre the Centered Version

```{r}
data_pop %>% 
  dplyr::mutate(pred = predict(pop_lmer_2_cen)) %>%
  ggplot() +
  aes(x = extravG,
      y = pred,
      group = class) +
  geom_rect(aes(xmin = -5.215 - 0.25, 
                xmax = -5.215 + 0.25,
                ymin = fixef(pop_lmer_2_raw)[["(Intercept)"]]- 4.5,
                ymax = fixef(pop_lmer_2_raw)[["(Intercept)"]]+ 4.5),
            fill = "yellow",
            alpha = 0.05) +
  geom_rect(aes(xmin = 0 - 0.25, 
                xmax = 0 + 0.25,
                ymin = fixef(pop_lmer_2_cen)[["(Intercept)"]]- 2.5,
                ymax = fixef(pop_lmer_2_cen)[["(Intercept)"]]+ 2.5),
            fill = "yellow",
            alpha = 0.05) +
  geom_abline(data = coef(pop_lmer_2_cen)$class %>% dplyr::rename(Intercept = "(Intercept)"),
              aes(intercept = Intercept,
                  slope     = extravG),
              color = "gray",
              size = .1) +
  geom_line(size = .2) +
  geom_abline(intercept = fixef(pop_lmer_2_cen)[["(Intercept)"]],
              slope     = fixef(pop_lmer_2_cen)[["extravG"]],
              color = "hot pink",
              size = 2) +
  theme_bw() +
  geom_vline(xintercept = -5.215,
             color = "blue") +
  geom_vline(xintercept = 0,
             color = "red") +
  labs(title = "MLM-RIAS: Extroversion = grand-mean centered",
       subtitle = "Thin black lines are group-wise predictions, one per class EXTRAPOLATED OUT",
       x = "GRAND-MEAN CENTERED Student's Extroversion, as rated by their teacher",
       y = "Predicted\nStudent's Populartity, mean rating by their peers") +
  coord_cartesian(xlim = c(-5, 5),
                  ylim = c(0, 10)) +
  scale_x_continuous(breaks = seq(from = -4, to =  4, by = 2)) +
  scale_y_continuous(breaks = seq(from =  0, to = 10, by = 2))
```






### Comapre the Standardized Version

```{r}
data_pop %>% 
  dplyr::mutate(pred = predict(pop_lmer_2_std)) %>% 
  ggplot() +
  aes(x = extravZ,
      y = pred,
      group = class) +
  geom_rect(aes(xmin = 0 - 0.25, 
                xmax = 0 + 0.25,
                ymin = fixef(pop_lmer_2_cen)[["(Intercept)"]]- 2.5,
                ymax = fixef(pop_lmer_2_cen)[["(Intercept)"]]+ 2.5),
            fill = "yellow",
            alpha = 0.05) +
  geom_abline(data = coef(pop_lmer_2_std)$class %>% dplyr::rename(Intercept = "(Intercept)"),
              aes(intercept = Intercept,
                  slope     = extravZ),
              color = "gray",
              size = .1) +
  geom_line(size = .2) +
  geom_abline(intercept = fixef(pop_lmer_2_std)[["(Intercept)"]],
              slope     = fixef(pop_lmer_2_std)[["extravZ"]],
              color = "hot pink",
              size = 2) +
  theme_bw() +
  geom_vline(xintercept = 0,
             color = "red") +
  geom_vline(xintercept = -5.215,
             color = "blue") +
  labs(title = "MLM-RIAS: Extroversion = standardized",
       subtitle = "Thin black lines are group-wise predictions, one per class EXTRAPOLATED OUT",
       x = "STANDARDIZED Student's Extroversion, as rated by their teacher",
       y = "Predicted\nStudent's Populartity, mean rating by their peers") +
  coord_cartesian(xlim = c(-5, 5),
                  ylim = c(0, 10)) +
  scale_x_continuous(breaks = seq(from = -4, to =  4, by = 2)) +
  scale_y_continuous(breaks = seq(from =  0, to = 10, by = 2))
```

<!--chapter:end:08-example_hox3_popular2.Rmd-->

# Variance Explained


@nakagawa2013 

https://ecologyforacrowdedplanet.wordpress.com/2013/08/27/r-squared-in-mixed-models-the-easy-way/


## For Generalized MLMs

https://stats.stackexchange.com/questions/111150/calculating-r2-in-mixed-models-using-nakagawa-schielzeths-2013-r2glmm-me


I am answering by pasting Douglas Bates's reply in the R-Sig-ME mailing list, on 17 Dec 2014 on the question of **how to calculate an $R^2$ statistic for generalized linear mixed models**, which I believe is required reading for anyone interested in such a thing. Bates is the original author of the `lme4` package for $R$ and co-author of `nlme`, as well as co-author of a well-known book on mixed models, and CV will benefit from having the text in an answer, rather than just a link to it.

>I must admit to getting a little twitchy when people speak of the "$R^2$ for GLMMs". $R^2$ for a linear model is well-defined and has many desirable properties. For other models one can define different quantities that reflect some but not all of these properties. But this is not calculating an $R^2$ in the sense of obtaining a number having all the properties that the $R^2$ for linear models does. Usually there are several different ways that such a quantity could be defined. Especially for GLMs and GLMMs before you can define "proportion of response variance explained" you first need to define what you mean by "response variance". The whole point of GLMs and GLMMs is that a simple sum of squares of deviations does not meaningfully reflect the variability in the response because the variance of an individual response depends on its mean.
>
> Confusion about what constitutes $R^2$ or degrees of freedom of any of the other quantities associated with linear models as applied to other models comes from confusing the formula with the concept. Although formulas are derived from models the derivation often involves quite sophisticated mathematics. To avoid a potentially confusing derivation and just "cut to the chase" it is easier to present the formulas. But the formula is not the concept. **Generalizing a formula is not equivalent to generalizing the concept.** And those formulas are almost never used in practice, especially for generalized linear models, analysis of variance and random effects. I have a "meta-theorem" that the only quantity actually calculated according to the formulas given in introductory texts is the sample mean.
>
>It may seem that **I am being a grumpy old man about this, and perhaps I am, but the danger is that people expect an "$R^2$-like" quantity **to have all the properties of an $R^2$ for linear models. It can't. There is no way to generalize all the properties to a much more complicated model like a GLMM.
>
> I was once on the committee reviewing a thesis proposal for Ph.D. candidacy. The proposal was to examine I think 9 different formulas that could be considered ways of computing an $R^2$ for a nonlinear regression model to decide which one was "best". Of course, this would be done through a simulation study with only a couple of different models and only a few different sets of parameter values for each. My suggestion that this was an entirely meaningless exercise was not greeted warmly.




<!--chapter:end:09-rsqured.Rmd-->

# sjPlot Package

![](images/header_sjPlot.png)


```{block type='rmdlink', echo=TRUE}
[Daniel Ldecke](http://www.danielluedecke.de/) is German researcher that has put together several GREAT packages, including `sjPlot` which we will detail here.  Documentation can be found at: http://www.strengejacke.de/sjPlot/index.html 
```



```{r, include=FALSE}
knitr::opts_chunk$set(comment     = "",
                      echo        = TRUE, 
                      warning     = FALSE, 
                      message     = FALSE,
                      fig.align   = "center", # center all figures
                      fig.width   = 6,        # set default figure width to 4 inches
                      fig.height  = 4)        # set default figure height to 3 inches
```

```{r, message=FALSE, error=FALSE}
library(tidyverse)    # all things tidy
library(texreg)       # Convert Regression Output to LaTeX or HTML Tables

library(lme4)         # Linear, generalized linear, & nonlinear mixed modelsts models

library(haven)        # read in SPSS dataset

library(sjPlot)       # Quick predicitive and diagnostic plots 
```


Read the SPSS data in with the `haven` package and prepare it (see previous chapter).

```{r}
data_raw <- haven::read_sav("http://www.mlminr.com/data-sets/Achieve.sav?attredirects=0")

data_achieve_center_scale <- data_raw %>% 
  dplyr::mutate_at(vars(id, region, corp, school, class), factor) %>% 
  dplyr::mutate(gender = gender %>% 
                  factor(labels = c("Female", "Male"))) %>% 
  dplyr::mutate(classize = classize %>% 
                  factor(labels = c("12-17", "18-21", 
                                    "22-26", ">26"))) %>% 
  dplyr::select(id, region, corp, school, class,           # Identifiers
                gender, age, geread, gevocab,              # Pupil-level vars
                classize,                                  # Class-Level vars
                senroll, ses) %>%                          # School-level vars
  dplyr::mutate(gevocab_c = gevocab - 4.4938) %>% 
  dplyr::mutate(age_c     = age     - 107.5290) %>% 
  dplyr::mutate(senroll_c = senroll - 533.4148) %>%  
  dplyr::mutate(senroll_ch = senroll_c / 100) %>%        # centered AND divided by one hundred
  dplyr::mutate(ses_t      = ses / 10)                   # JUST divide by ten
```


Fit the final model (see previous chapter)

```{r}
fit_read_11re_s <- lme4::lmer(geread ~ gevocab_c*age_c + gevocab_c*ses_t +   # 2 2-way interactions
                                      (gevocab_c | school),  
                             data   = data_achieve_center_scale,
                             REML   = TRUE)
```


```{r, include=FALSE}
texreg::screenreg(list(fit_read_11re_s), single.row = TRUE)
```



```{r, results='asis'}
# Knit to Website: texreg::htmlreg()
# Knit to PDF:     texreg::texreg()
# View on Screen:  texreg::screenreg()

texreg::htmlreg(list(fit_read_11re_s),
                custom.model.names = c("Final"), 
                caption            = "MLM: Final Model",
                caption.above      = TRUE,
                single.row         = TRUE)
```




Now we will show some of the things the `sjPlot` package can do!


## Plotting Coefficients


Select `terms` that should be plotted. All other term are removed from the output. 

Note that the term names must match the names of the model's coefficients. For factors, this means that the variable name is suffixed with the related factor level, and each category counts as one term. E.g. `rm.terms = "t_name [2,3]"` would remove the terms `t_name2` and `t_name3` (assuming that the variable t_name is categorical and has at least the factor levels 2 and 3). 

Another example for the iris-dataset: `terms = "Species"` would not work, instead you would write `terms = "Species [versicolor, virginica]"` to remove these two levels, or `terms = "Speciesversicolor"` if you just want to remove the level versicolor from the plot.


### Fixed Effects



```{r}
sjPlot::plot_model(fit_read_11re_s,
                   type = "est")
```



```{r}
sjPlot::plot_model(fit_read_11re_s,
                   type = "est",
                   show.values = TRUE)  # Logical, whether values should be plotted or not.
```



```{r}
sjPlot::plot_model(fit_read_11re_s,
                   type = "std")
```

Determines in which way estimates are sorted in the plot with the option: `sort.est = `

* If `NULL` (default), no sorting is done and estimates are sorted in the same order as they appear in the model formula.    
* If `TRUE`, estimates are sorted in descending order, with highest estimate at the top.    
* If `sort.est = "sort.all"`, estimates are re-sorted for each coefficient (only applies if `type = "re"` and `grid = FALSE`), i.e. the estimates of the random effects for each predictor are sorted and plotted to an own plot.    
* If `type = "re"`, specify a predictor's / coefficient's name to sort estimates according to this random effect.

```{r}
sjPlot::plot_model(fit_read_11re_s,
                   type = "std",
                   sort.est = TRUE)
```


```{r}
sjPlot::plot_model(fit_read_11re_s,
                   type = "std",
                   sort.est = TRUE,
                   show.values = TRUE)  # Logical, whether values should be plotted or not.
```


Plots standardized beta values, however, standardization follows @gelman2008 suggestion, rescaling the estimates by dividing them by two standard deviations instead of just one. Resulting coefficients are then directly comparable for untransformed **binary predictors**.


```{r}
sjPlot::plot_model(fit_read_11re_s,
                   type = "std2")
```



### Random Effects

```{r, fig.width=3, fig.height=8}
sjPlot::plot_model(fit_read_11re_s,
                   type = "re")
```



```{r, fig.width=3, fig.height=8}
sjPlot::plot_model(fit_read_11re_s,
                   type = "re",
                   grid = FALSE,
                   sort.est = TRUE)
```


## Plotting Marginal Effects

Here `terms` indicates for which terms marginal effects should be displayed. At least one term is required to calculate effects, maximum length is three terms, where the second and third term indicate the groups, i.e. predictions of first term are grouped by the levels of the second (and third) term. 

`terms` may also indicate higher order terms (e.g. interaction terms).

Indicating levels in square brackets allows for selecting only specific groups. Term name and levels in brackets must be separated by a whitespace character, e.g. `terms = c("age", "education [1,3]")`. 

It is also possible to specify a range of numeric values for the predictions with a colon, for instance `terms = c("education [1,3]", "age [30:50]")`. 

Furthermore, it is possible to specify a function name. Values for predictions will then be transformed, e.g. `terms = "income [exp]"`. This is useful when model predictors were transformed for fitting the model and should be **back-transformed** to the original scale for predictions. 

Finally, using pretty for numeric variables (e.g. `terms = "age [pretty]"`) calculates a pretty range of values for the term, roughly of proportional length to the term's value range. For more details, see the documentation for the `ggpredict` package.



### Predicted Values

Based on (i.e. is a wrapper for): `ggeffects::ggpredict()`

```{r}
sjPlot::plot_model(fit_read_11re_s,
                   type = "pred",
                   terms = c("gevocab_c", "ses_t", "age_c"))
```

The `pred.type = ` option only applies for Marginal Effects plots with **mixed effects models**. Indicates whether predicted values should be **conditioned on random effects** (`pred.type = "re"`) or fixed effects only (`pred.type = "fe"`, the default). For details, see documentation of the type-argument in `ggpredict()` function.

```{r}
sjPlot::plot_model(fit_read_11re_s,
                   type = "pred",
                   pred.type = "re",
                   terms = c("gevocab_c", "ses_t", "age_c"))
```





### Effect Plots

Based on (i.e. is a wrapper for): `ggeffects::ggeffect()`


Similar to `type = "pred"`, however, discrete predictors are held constant at their proportions (not reference level). See the `ggeffect` package documentation for details.


```{r}
sjPlot::plot_model(fit_read_11re_s,
                   type = "eff",
                   terms = c("gevocab_c", "ses_t", "age_c"))
```

### Interaction Plots

A shortcut for marginal effects plots, where *interaction terms are automatically detected* and used as terms-argument. 

Furthermore, if the moderator variable (the second - and third - term in an interaction) is continuous, `type = "int"` automatically chooses useful values based on the mdrt.values-argument, which are passed to terms. Then, `ggpredict` is called. 

`type = "int"` plots the interaction term that appears:

* **first** in the formula along the x-axis, while the 
* **second**  (and possibly third) variable in an interaction is used as grouping factor(s) (moderating variable). 

Use `type = "pred"` or `type = "eff"` and specify a certain order in the terms-argument to indicate which variable(s) should be used as moderator.


```{r}
sjPlot::plot_model(fit_read_11re_s,
                   type = "int")
```

The `mdrt.values = ` option indicates which values of the **moderator variable** should be used when plotting interaction terms (i.e. `type = "int"`).

* `minmax` (default) minimum and maximum values (lower and upper bounds) of the moderator are used to plot the interaction between independent variable and moderator(s).

* `meansd` uses the mean value of the moderator as well as one standard deviation below and above mean value to plot the effect of the moderator on the independent variable (following the convention suggested by Cohen and Cohen and popularized by Aiken and West (1991), i.e. using the mean, the value one standard deviation above, and the value one standard deviation below the mean as values of the moderator, see Grace-Martin K: 3 Tips to Make Interpreting Moderation Effects Easier).

* `zeromax` is similar to the `minmax` option, however, $0$ is always used as minimum value for the moderator. This may be useful for predictors that don't have an empirical zero-value, but absence of moderation should be simulated by using $0$ as minimum.

* `quart` calculates and uses the quartiles (lower, median and upper) of the moderator value.

* `all` uses all values of the moderator variable.


```{r}
sjPlot::plot_model(fit_read_11re_s,
                   type = "int",
                   mdrt.values = "meansd")
```



## Model Diagnostics


Note: For mixed models, the diagnostic plots like linear relationship or check for Homoscedasticity, do not take the uncertainty of random effects into account, but is only based on the fixed effects part of the model.




### Slope of Coefficentes

Slope of coefficients for each single predictor, against the response (linear relationship between each model term and response).

```{r}
sjPlot::plot_model(fit_read_11re_s,
                   type = "slope")
```

### Residuals

Slope of coefficients for each single predictor, against the residuals (linear relationship between each model term and residuals).


```{r}
sjPlot::plot_model(fit_read_11re_s,
                   type = "resid")
```

### Diagnostics

Check model assumptions.




```{r}
sjPlot::plot_model(fit_read_11re_s,
                   type = "diag")
```

<!--chapter:end:10-sjPlot.Rmd-->

# Longitudinal Intro:  Example - Autism

```{r, include=FALSE}
knitr::opts_chunk$set(comment     = "",
                      echo        = TRUE, 
                      warning     = FALSE, 
                      message     = FALSE,
                      fig.align   = "center", # center all figures
                      fig.width   = 6,        # set default figure width to 4 inches
                      fig.height  = 4)        # set default figure height to 3 inches
```

```{r, message=FALSE, error=FALSE}
library(tidyverse)    # all things tidy
library(pander)       # nice looking genderal tabulations
library(furniture)    # nice table1() descriptives
library(texreg)       # Convert Regression Output to LaTeX or HTML Tables
library(psych)        # contains some useful functions, like headTail
library(sjstats)      # ICC calculations
library(sjPlot)       # Quick predicitive and diagnostic plots 
library(effects)      # Estimated Marginal Means
library(VIM)          # Visualization and Imputation of Missing Values 
library(naniar)       # Summaries and Visualisations for Missing Data

library(lme4)         # Linear, generalized linear, & nonlinear mixed models

library(HLMdiag)      # package with the dataset
```

## Background

 
The source:  http://www-personal.umich.edu/~kwelch/ 


This data was collected by researchers at the University of Michigan [@anderson2007, @anderson2009] as part of a prospective longitudinal study of 214 children. The children were divided into three diagnostic groups (`bestest2`) when they were 2 years old: Autism (`autism`), Pervasive Developmental Disorder (`pdd`), and non-spectrum children (none in this sample). The study was designed to collect information on each child at approximately 2, 3, 5, 9, and 13 years of age, although not all children were measured for each age. One of the study objectives was to assess the relative influence of the initial diagnostic category, language proficiency at age 2, and other covariates on the developmental trajectories of the socialization (`vsae`) of these children. 

Study participants were children who had had consecutive referrals to one of two autism clinics before the age of 3 years. Social development was assessed at each age using the Vineland Adaptive Behavior Interview survey form, a parent-reported measure of socialization. **VSAE** (Vineland Socialization Age Equivalent), was a combined score that included assessments of interpersonal relationships, play/leisure time activities, and coping skills. Initial language development was assessed using the Sequenced Inventory of Communication Development (SICD) scale; children were placed into one of three groups (`sicdegp`) based on their initial SICD scores on the expressive language subscale at age 2. 

* `childid` Child's identification number for this study

* `sicdegp` Sequenced Inventory of Communication Development group *(an assessment of expressive language development)* - a factor. Levels are `low`, `med`, and `high`

* `age2` Age (in years) centered around age 2 (age at diagnosis)

* `vsae` Vineland Socialization Age Equivalent, Parent-reported measure of socialization, including measures of:
    + interpersonal relationships 
    + play/leisure time activities
    + coping skills

* `gender` Child's gender - a factor. Levels are `male` and `female`

* `race` Child's race - a factor. Levels are `white` and `nonwhite`

* `bestest2` Diagnosis at age 2 - a factor. Levels are `autism` and `pdd` (pervasive developmental disorder)


```{r}
data(autism, package = "HLMdiag")   # make the dataset 'active' from this package
```


```{r}
tibble::glimpse(autism)             # first look at the dataset and its varaibles
```

### Long Format

```{r}
data_long <- autism %>%                                    # save the dataset as a new name
  dplyr::mutate(childid = childid %>% factor) %>%          # declare grouping var a factor
  dplyr::mutate(age = 2 + age2) %>%                        # create the original age variable (unequally spaced)
  dplyr::mutate(obs = age %>% factor %>% as.numeric) %>%   # Observation Number = 1, 2, 3, 4, 5 (equally spaced)
  dplyr::select(childid,                                   # choose variables and order to keep
                gender, race, bestest2, sicdegp, 
                obs, age, age2, vsae) %>% 
  dplyr::arrange(childid, age2)                            # sort observations
```


```{r}
data_long %>% 
  psych::headTail(top = 11, bottom = 6)
```


### Wide Format


```{r}
data_wide <- data_long %>%           # save the dataset as a new name
  dplyr::select(-age, -obs) %>%      # delete (by deselecting) this variable 
  tidyr::spread(key = age2,          # name the varaible that specifies how to spread
                value = vsae,        # name the variable to be spread out
                sep = "_") %>%       # add to combine the key-variables name before its value
  dplyr::arrange(childid)            # sort observations
```


Notice the missing values, displayed as `NA`.

```{r}
data_wide %>% 
  psych::headTail()
```


## Exploratory Data Analysis

### Demographic Summary


#### Using the WIDE formatted dataset

Each person's data is only stored on a single line

```{r, results="asis"}
# Knit to Website: output = "html" 
# Knit to PDF:     output = "latex2"
# View on Screen:  output = ""text", or "markdown", "html"

data_wide %>% 
  furniture::table1(bestest2, gender, race,    # variables to summarize
                    splitby = ~ sicdegp,       # how split into columns
                    test = TRUE,               # compare the groups
                    output = "html")           # for website
```


#### Using the LONG formatted dataset

Each person's data is stored on multiple lines, one for each time point.  To ensure the summary table is correct, you must choose a single time point per person.


```{r, results="asis"}
# Knit to Website: output = "html" 
# Knit to PDF:     output = "latex2"
# View on Screen:  output = ""text", or "markdown", "html"

data_long %>% 
  dplyr::filter(age == 2) %>%                  # restrict to one-line per person
  furniture::table1(bestest2, gender, race,    # variables to summarize
                    splitby = ~ sicdegp,       # how split into columns
                    test = TRUE,               # compare the groups
                    output = "html")           # for website
```


### Baseline Summary


<!-- #### Using the WIDE formatted dataset -->

<!-- Each person's data is only stored on a single line -->

<!-- ```{r, results="asis"} -->
<!-- # Knit to Website: output = "html"  -->
<!-- # Knit to PDF:     output = "latex2" -->
<!-- # View on Screen:  output = ""text", or "markdown", "html" -->

<!-- data_wide %>%  -->
<!--   furniture::table1(age2_0,  -->
<!--                     splitby = ~ sicdegp, -->
<!--                     test = TRUE, -->
<!--                     output = "html") -->
<!-- ``` -->


#### Using the LONG formatted dataset

Each person's data is stored on multiple lines, one for each time point.  To ensure the summary table is correct, you must choose a single time point per person.

```{r, results="asis"}
# Knit to Website: output = "html" 
# Knit to PDF:     output = "latex2"
# View on Screen:  output = ""text", or "markdown", "html"

data_long %>% 
  dplyr::filter(age == 2) %>% 
  furniture::table1(vsae, 
                    splitby = ~ sicdegp,
                    test = TRUE,
                    output = "html")
```


### Missing Data & Attrition

#### `VIM` package

Plot the amount of missing vlaues and the amount of each patter of missing values.

```{r}
data_wide %>% 
  VIM::aggr(numbers = TRUE,   # shows the number to the far right
            prop = FALSE)     # shows counts instead of proportions
```

#### `naniar` package

```{r}
data_wide %>% 
  naniar::vis_miss()
```

```{r}
data_wide %>% 
  naniar::gg_miss_var()
```

```{r}
data_wide %>% 
  naniar::gg_miss_var(show_pct = TRUE,     # x-axis is PERCENT, not count
                      facet = sicdegp) +   # create seperate panels
  theme_bw()                               # add ggplot layers as normal
```

```{r}
data_wide %>% 
  naniar::gg_miss_upset() 
```

```{r}
data_wide %>% 
  naniar::gg_miss_upset(sets = c("age2_0_NA",
                                 "age2_1_NA",
                                 "age2_3_NA",
                                 "age2_7_NA",
                                 "age2_11_NA"),
                        keep.order = TRUE) 
```


### Means Across Time

#### Using the WIDE formatted dataset


> Default = COMPLETE CASES ONLY!!!  

Note - the sample size at each time point is the same, but subjects are only included if they have data at every time point

```{r, results="asis"}
# Knit to Website: output = "html"
# Knit to PDF:     output = "latex2"
# View on Screen:  output = ""text", or "markdown", "html"

data_wide %>%
  furniture::table1(age2_0, age2_1, age2_3, age2_7, age2_11,
                    splitby = ~ sicdegp,
                    test = TRUE,
                    na.rm = TRUE,           # default: COMPLETE CASES ONLY!!!!!
                    output = "html")
```


> Specify All data: 

note -  that the smaple sizes will be different for each time point

```{r, results="asis"}
# Knit to Website: output = "html"
# Knit to PDF:     output = "latex2"
# View on Screen:  output = ""text", or "markdown", "html"

data_wide %>%
  furniture::table1(age2_0, age2_1, age2_3, age2_7, age2_11,
                    splitby = ~ sicdegp,
                    test = TRUE,
                    na.rm = FALSE,           # INCLUDES ALL DATA !!!!
                    output = "html")
```

#### Using the LONG formatted dataset

Each person's data is stored on multiple lines, one for each time point.


> FOR ALL DATA!

```{r}
data_sum_all <- data_long %>% 
  dplyr::group_by(sicdegp, age2) %>%              # specify the groups
  dplyr::summarise(vsae_n    = n(),                      # count of valid scores
                   vsae_mean = mean(vsae),               # mean score
                   vsae_sd   = sd(vsae),                 # standard deviation of scores
                   vsae_sem  = vsae_sd / sqrt(vsae_n))   # stadard error for the mean of scores

data_sum_all
```



> FOR COMPLETE CASES ONLY!!!

```{r}
data_sum_cc <- data_long %>% 
  dplyr::group_by(childid) %>%        # group-by child
  dplyr::mutate(child_vsae_n = n()) %>%    # count the number of valid VSAE scores
  dplyr::filter(child_vsae_n == 5) %>%     # restrict to only thoes children with 5 valid scores
  dplyr::group_by(sicdegp, age2) %>%              # specify the groups
  dplyr::summarise(vsae_n    = n(),                      # count of valid scores
                   vsae_mean = mean(vsae),               # mean score
                   vsae_sd   = sd(vsae),                 # standard deviation of scores
                   vsae_sem  = vsae_sd / sqrt(vsae_n))   # stadard error for the mean of scores

data_sum_cc
```


### Person Profile Plots

Use the data in LONG format

#### Unequally Spaced

```{r, fig.width=8, fig.height=6}
data_long %>% 
  dplyr::mutate(sicdegp = fct_recode(sicdegp,
                                     "Low Communication" = "low",
                                     "Medium Communication" = "med",
                                     "High Communication" = "high")) %>% 
  ggplot(aes(x = age,
             y = vsae)) +
  geom_point(size = 0.75) +
  geom_line(aes(group = childid),
            alpha = .5,
            size = 1) +
  facet_grid(. ~ sicdegp)  +
  theme_bw() +
  scale_x_continuous(breaks = c(2, 3, 5, 9, 13)) +
  labs(x = "Age of Child, Years",
       y = "Vineland Socialization Age Equivalent",
       color = "Sequenced Inventory of Communication Development") +
  geom_smooth(aes(color = "Flexible"),
              method = "loess",
              se = FALSE,) +
  geom_smooth(aes(color = "Linear"),
              method = "lm",
              se = FALSE) +
  scale_color_manual(name = "Smoother Type: ",
                     values = c("Flexible" = "blue", 
                                "Linear"    = "red")) +
  theme(legend.position = "bottom",
        legend.key.width = unit(2, "cm"))
```

#### Equally Spaced

```{r, fig.width=8, fig.height=6}
data_long %>% 
  dplyr::mutate(sicdegp = fct_recode(sicdegp,
                                     "Low Communication" = "low",
                                     "Medium Communication" = "med",
                                     "High Communication" = "high")) %>% 
  ggplot(aes(x = obs,
             y = vsae)) +
  geom_point(size = 0.75) +
  geom_line(aes(group = childid),
            alpha = .5,
            size = 1) +
  facet_grid(. ~ sicdegp)  +
  theme_bw() +
  labs(x = "Observation Number",
       y = "Vineland Socialization Age Equivalent",
       color = "Sequenced Inventory of Communication Development") +
  geom_smooth(aes(color = "Flexible"),
              method = "loess",
              se = FALSE,) +
  geom_smooth(aes(color = "Linear"),
              method = "lm",
              se = FALSE) +
  scale_color_manual(name = "Smoother Type: ",
                     values = c("Flexible" = "blue", 
                                "Linear"    = "red")) +
  theme(legend.position = "bottom",
        legend.key.width = unit(2, "cm"))
```



### Side-by-side Boxplots

```{r, fig.width=8, fig.height=6}
data_long %>% 
  ggplot(aes(x = sicdegp,
             y = vsae,
             fill = sicdegp)) +
  geom_boxplot() +
  theme_bw() +
  facet_grid(. ~ age, 
             labeller = "label_both") +
  theme(legend.position = "top")
```

### Means Plots

#### Default `stat_summary`

It is nice that the `stat_summary()` layer computes the standard error for the mean for you using the data in LONG format

```{r, fig.width=8, fig.height=6}
data_long %>% 
  ggplot(aes(x = age,
             y = vsae,
             color = sicdegp)) +
  stat_summary() +                       # default: points at MEAN and extend vertically 1 standard error for the mean
  stat_summary(fun.y = "mean",           # plot the means
               geom = "line") +          # ...and connect with lines
  theme_bw() +
  scale_x_continuous(breaks = c(2, 3, 5, 9, 13)) +
  theme(legend.position = c(0, 1),
        legend.justification = c(-0.25, 1.25),
        legend.background = element_rect(color = "black"))
```


```{r, fig.width=8, fig.height=6}
data_long %>% 
  ggplot(aes(x = obs,
             y = vsae,
             color = sicdegp)) +
  stat_summary() +                       # default: points at MEAN and extend vertically 1 standard error for the mean
  stat_summary(fun.y = "mean",           # plot the means
               geom = "line") +          # ...and connect with lines
  theme_bw() +
  theme(legend.position = c(0, 1),
        legend.justification = c(-0.25, 1.25),
        legend.background = element_rect(color = "black"))
```




#### Manually Summarized


```{r, fig.width=8, fig.height=6}
data_sum_all %>% 
  dplyr::mutate(age = age2 + 2) %>% 
  ggplot() +
  aes(x = age,
      y = vsae_mean,
      color = sicdegp) +
  geom_errorbar(aes(ymin = vsae_mean - vsae_sem,   # mean +/- one SE for the mean
                    ymax = vsae_mean + vsae_sem),
                width = .25) +
  geom_point(aes(shape = sicdegp),
             size = 3) +
  geom_line(aes(group = sicdegp)) +
  theme_bw() +
  scale_x_continuous(breaks = c(2, 3, 5, 9, 13)) +
  labs(x = "Age of Child, Years",
       y = "Vineland Socialization Age Equivalent",
       color = "Sequenced Inventory of Communication Development:",
       shape = "Sequenced Inventory of Communication Development:",
       linetype = "Sequenced Inventory of Communication Development:") +
  theme(legend.position = "bottom",
        legend.key.width = unit(2, "cm"))
```



## Model 1: Full model with loaded mean structure

Take top-down approach: Quadratic regression model, describing `vsae` as a function of `age2`

> Each child has a unique parabolic trajectory over time, with coefficients that vary randomly around fixed-effects defining a mean growth curve for each SICD group.  Since there is no `age` = 0 in our data, we will use the `age2` variables, which is `age` -2,  so that intercept has meaning (mean at baseline age).


* Fixed-effects    
    + `age2` age
    + `I(age2^2)` quadratic age or age-squared, the `I()` denotes an internal calculated variable
    + `sicdegp` SICD group (reference group = low)
    + SICD group x age/age-squared interactions

* Random-effects    
    + intercep
    + age and age-squared 


### Fit the Model

```{r}
fit_lmer_1_re <- lmer(vsae ~ age2*sicdegp + I(age2^2)*sicdegp + 
                        (1 + age2 + I(age2^2) | childid), 
                      data = data_long,
                      REML = TRUE)
```


### Table of Prameter Estimates

```{r, include = FALSE}
texreg::screenreg(fit_lmer_1_re, single.row = TRUE)
```

```{r, results='asis'}
# Knit to Website: texreg::htmlreg()
# Knit to PDF:     texreg::texreg()
# View on Screen:  texreg::screenreg()

texreg::htmlreg(list(fit_lmer_1_re),
                caption            = "MLM: Full Model",
                caption.above      = TRUE,
                single.row         = TRUE)
```



### Plot of the Estimated Marginal Means

Note: the $x-axis$ is the `age2` (age - 2) variable, so it represents time since age 2 (or baseline)

```{r}
sjPlot::plot_model(fit_lmer_1_re,
                   type = "pred",
                   terms = c("age2", "sicdegp"),
                   title = "Model 1: Loaded Means Structure")
```



## Model 2A: Drop Random Intercepts

Note: There seems to be relatively little variation in baseline measurements of VSAE across individuals in the same SICD group, so the variation at age 2 can be attributed to random error, rather than between-subject variation.

This indicates we may want to try removing the random intercepts, while retaining the same fixed- and other random-effects.

This new model implies that children have common initial VSAE value at age 2, given their SICD group.


### Fit the Model

```{r}
fit_lmer_2a_re <- lmer(vsae ~ age2*sicdegp + I(age2^2)*sicdegp + 
                        (-1 + age2 + I(age2^2) | childid), 
                      data = data_long,
                      REML = TRUE)
```


### Assess the Signifcance

```{r}
anova(fit_lmer_1_re, fit_lmer_2a_re, refit = FALSE)
```

The more complicated model (including random intercepts) does NOT fit better, thus the random intercepts may be removed from the model.  Model 2a is bettern than Model 1




## Model 2B: Drop Random Quadratic Slope

We should formally test the necessity of quadratic age random-effect.

Comparison of nested models with REML-based LRT using a 50:50 mixture 2-distribution with 1 and 2 df
Difference of 2 covariance parameters

### Fit the Model

```{r}
fit_lmer_2b_re <- lmer(vsae ~ age2*sicdegp + I(age2^2)*sicdegp + 
                        (-1 + age2  | childid), 
                      REML = TRUE, 
                      data = data_long)
```


### Assess the Signifcance

```{r}
anova(fit_lmer_2a_re, fit_lmer_2b_re, refit = FALSE)
```


The more complicated model (including random intercepts) DOES fit better, thus the random sopes for both the linear AND the quadratic effect of age should be retained in the model.  Model 2a is better than model 2b




## Model 3: Drop Quadratic Time Fixed Effect

Fit the previous 'best' model via ML, not REML to compare nested model that differe in terms of fixed effects only

### Fit the Models

```{r}
fit_lmer_2a_ml <- lmer(vsae ~ age2*sicdegp + I(age2^2)*sicdegp + 
                        (-1 + age2 + I(age2^2) | childid),  
                      data = data_long, 
                      REML = FALSE)

fit_lmer_3_ml <- lmer(vsae ~ age2*sicdegp  + 
                        (-1 + age2 + (age2^2) | childid), 
                      data = data_long, 
                      REML = FALSE)
```

### Assess the Signifcance

```{r}
anova(fit_lmer_2a_ml, fit_lmer_3_ml)
```


The more complicated model (including fixed interaction between quadratic time and SICD group) DOES fit better, thus the higher level interaction should be retained in the model.  Model 2a is better than model 3.






## Final Model

### Table of Parameter Esitmates


```{r, include = FALSE}
texreg::screenreg(fit_lmer_2a_re, single.row = TRUE)
```

```{r, results='asis'}
# Knit to Website: texreg::htmlreg()
# Knit to PDF:     texreg::texreg()
# View on Screen:  texreg::screenreg()

texreg::htmlreg(list(fit_lmer_2a_re),
                caption            = "MLM: Final Model",
                caption.above      = TRUE,
                single.row         = TRUE,
                digits             = 4)
```



### Interpretation of Fixed Effects

#### Reference Group: `low` SICD group

* $\gamma_{0}$ = `r  fixef(fit_lmer_2a_re)["(Intercept)"] %>% round(3)` is the estimated marginal mean VSAE score for children in the `low` SICD, at 2 years of age    

* $\gamma_{a}$ = `r  fixef(fit_lmer_2a_re)["age2"] %>% round(3)` and $\gamma_{a^2}$ = `r  fixef(fit_lmer_2a_re)["I(age2^2)"] %>% round(3)` are the fixed effects for age and age-squared on VSAE for children in the `low` SICD  group (change over time)

Thus the equation for the estimated marginal mean VASE trajectory for the `low` SICD group is:

$$
\begin{align*}
VASE =& \gamma_{0} + 
        \gamma_{a}   (AGE - 2) + 
        \gamma_{a^2} (AGE - 2)^2 \\
     =& `r  fixef(fit_lmer_2a_re)["(Intercept)"] %>% round(3)` + 
        `r  fixef(fit_lmer_2a_re)["age2"]        %>% round(3)` (AGE - 2)  + 
        `r  fixef(fit_lmer_2a_re)["I(age2^2)"]   %>% round(3)` (AGE - 2)^2 \\ 
\end{align*}
$$


#### First Comparison Group: `medium` SICD group

* $\gamma_{med}$ = `r  fixef(fit_lmer_2a_re)["sicdegpmed"] %>% round(3)` is the DIFFERENCE in the estimated marginal mean VSAE score for children in the `medium` vs. the `low` SICD, at 2 years of age    

* $\gamma_{med:\;a}$ = `r  fixef(fit_lmer_2a_re)["age2:sicdegpmed"] %>% round(3)` and $\gamma_{med:\;a^2}$ = `r  fixef(fit_lmer_2a_re)["sicdegpmed:I(age2^2)"] %>% round(3)` are the DIFFERENCE in the fixed effects for age and age-squared on VSAE for children in the `medium` vs. the `low` SICD  group

Thus the equation for the estimated marginal mean VASE trajectory for the `medium` SICD group is:

$$
\begin{align*}
VASE =& (\gamma_{0}   + \gamma_{med}) + 
        (\gamma_{a}   + \gamma_{med:\;a})  (AGE - 2) + 
        (\gamma_{a^2} + \gamma_{med:\;a^2})(AGE - 2)^2 \\
     =& (`r  fixef(fit_lmer_2a_re)["(Intercept)"] %>% round(3)` + 
         `r  fixef(fit_lmer_2a_re)["sicdegpmed"] %>% round(3)`) + 
        (`r  fixef(fit_lmer_2a_re)["age2"]            %>% round(3)` + 
         `r  fixef(fit_lmer_2a_re)["age2:sicdegpmed"] %>% round(3)`)  (AGE - 2) + 
        (`r  fixef(fit_lmer_2a_re)["I(age2^2)"]            %>% round(3)` + 
         `r  fixef(fit_lmer_2a_re)["sicdegpmed:I(age2^2)"] %>% round(3)`)(AGE - 2)^2 \\
     =& `r  (fixef(fit_lmer_2a_re)["(Intercept)"] + 
             fixef(fit_lmer_2a_re)["sicdegpmed"] ) %>% round(3)` + 
        `r  (fixef(fit_lmer_2a_re)["age2"] + 
             fixef(fit_lmer_2a_re)["age2:sicdegpmed"]) %>% round(3)`  (AGE - 2) + 
        `r  (fixef(fit_lmer_2a_re)["I(age2^2)"] + 
             fixef(fit_lmer_2a_re)["sicdegpmed:I(age2^2)"]) %>% round(3)` (AGE - 2)^2 \\
\end{align*}
$$




#### Second Comparison Group: `high` SICD group

* $\gamma_{hi}$ = `r  fixef(fit_lmer_2a_re)["sicdegphigh"] %>% round(3)` is the DIFFERENCE in the estimated marginal mean VSAE score for children in the `high` vs. the `low` SICD, at 2 years of age    

* $\gamma_{hi:\;a}$ = `r  fixef(fit_lmer_2a_re)["age2:sicdegphigh"] %>% round(3)` and $\gamma_{hi:\;a^2}$ = `r  fixef(fit_lmer_2a_re)["sicdegphigh:I(age2^2)"] %>% round(3)` are the DIFFERENCE in the fixed effects for age and age-squared on VSAE for children in the `high` vs. the `low` SICD  group

Thus the equation for the estimated marginal mean VASE trajectory for the `high` SICD group is:

$$
\begin{align*}
VASE =& (\gamma_{0}   + \gamma_{hi}) + 
        (\gamma_{a}   + \gamma_{hi:\;a})  (AGE - 2) + 
        (\gamma_{a^2} + \gamma_{hi:\;a^2})(AGE - 2)^2 \\
     =& (`r  fixef(fit_lmer_2a_re)["(Intercept)"] %>% round(3)` + 
         `r  fixef(fit_lmer_2a_re)["sicdegphigh"] %>% round(3)`) + 
        (`r  fixef(fit_lmer_2a_re)["age2"]            %>% round(3)` + 
         `r  fixef(fit_lmer_2a_re)["age2:sicdegphigh"] %>% round(3)`)  (AGE - 2) + 
        (`r  fixef(fit_lmer_2a_re)["I(age2^2)"]            %>% round(3)` + 
         `r  fixef(fit_lmer_2a_re)["sicdegphigh:I(age2^2)"] %>% round(3)`)(AGE - 2)^2 \\
     =& `r  (fixef(fit_lmer_2a_re)["(Intercept)"] + 
             fixef(fit_lmer_2a_re)["sicdegphigh"] ) %>% round(3)` + 
        `r  (fixef(fit_lmer_2a_re)["age2"] + 
             fixef(fit_lmer_2a_re)["age2:sicdegphigh"]) %>% round(3)`  (AGE - 2) + 
        `r  (fixef(fit_lmer_2a_re)["I(age2^2)"] + 
             fixef(fit_lmer_2a_re)["sicdegphigh:I(age2^2)"]) %>% round(3)` (AGE - 2)^2 \\
\end{align*}
$$

### Interpretation of Random Effects

```{r}
lme4::VarCorr(fit_lmer_2a_re)%>% 
  print(comp = c("Variance", "Std.Dev"),
        digits = 3)
```


```{r, include=FALSE}
sjstats::re_var(fit_lmer_2a_re)
sjstats::re_var(fit_lmer_2a_re) %>% names()
```


**Here a group of observations = a CHILD**

#### Residual Varaince 

**Within-child-variance**

* $e_{ti}$ the residuals associated with observation at time $t$ on child $i$


$$
\sigma^2 = \sigma^2_e 
         = VAR[e_{ti}] 
         = `r sjstats::re_var(fit_lmer_2a_re)["_sigma_2"] %>% round(3)`
$$


#### 2 Variance Components

**Between-children slope variances** 

Random LINEAR effect of age variance

* $u_{1i}$ the DIFFERENCE between child $i$'s specific linear component for age and the fixed linear component for age, given their SICD group

$$
\tau_{11} = \sigma^2_{u1} 
          = VAR[u_{1i}] 
          = `r sjstats::re_var(fit_lmer_2a_re)["childid_tau.00"] %>% round(2)`
$$

Random QUADRATIC effect of age variance

* $u_{2i}$ the DIFFERENCE between child $i$'s specific quadratic component for age and the fixed quadratic component for age, given their SICD group

$$
\tau_{22} = \sigma^2_{u2} 
          = VAR[u_{2i}] 
          = `r sjstats::re_var(fit_lmer_2a_re)["childid.I(age2^2)_tau.11"] %>% round(2)`
$$


#### 1 Covariance (or correlation) Components


**Slope-slope covariance** 

Random LINEAR  and Quadratic effect of age covariance: 

* correlation = `r sjstats::re_var(fit_lmer_2a_re)["childid_rho.01"] %>% round(2)`

$$
\tau_{12} = \sigma^2_{u12} 
          = COV[u_{1i}, u_{2i}] 
          = `r sjstats::re_var(fit_lmer_2a_re)["childid.age2_tau.01"] %>% round(2)`
$$




### Assumption Checking

The residuals are:

* Assumed to be normally, independently, and identically distributed (conditional on other random-effects)    

* Assumed independent of random-effects

$$
e_{ti}  \sim  N(0, \sigma^2)
$$



```{r}
sjPlot::plot_model(fit_lmer_2a_re, type = "diag")
```



### Plot of the Estimated Marginal Means

#### Quick and Default 

Note: the $x-axis$ is the `age2` (age - 2) variable, so it represents time since age 2 (or baseline)

```{r}
sjPlot::plot_model(fit_lmer_2a_re,
                   type = "pred",                 # estimated marginal means (no random effects)
                   terms = c("age2", "sicdegp"),  # 1st = x-axiz, 2nd = seperate lines
                   title = "Final Model (2a)")    # Optional title
```



#### More Customized - Color

This version would look better on a poster or in a slide presentation.

```{r}
effects::Effect(focal.predictors = c("age2","sicdegp"),  # variables involved in interactions
                mod = fit_lmer_2a_re,
                xlevels = list(age2 = seq(from = 0, to = 11, by = .1))) %>%   # add more values to smooth out the prediction lines and ribbons
  data.frame() %>% 
  dplyr::mutate(age = age2 + 2) %>%     # trandform back to standard years
  dplyr::mutate(sicdegp = factor(sicdegp,
                                 levels = c("high", "med", "low"),
                                 labels = c("High", "Medium", "Low"))) %>% 
  ggplot(aes(x = age,
             y = fit,
             group = sicdegp)) +
  geom_ribbon(aes(ymin = lower,        # 95% Confidence Intervals
                  ymax = upper,
                  fill = sicdegp),
              alpha = .3) +
  geom_line(aes(linetype = sicdegp,
                color = sicdegp),
            size = 1) +
  scale_x_continuous(breaks = c(2, 3, 5, 9, 13)) +                  # mark values that were actually measured
  scale_y_continuous(breaks = seq(from = 0, to = 120, by = 20)) +
  scale_linetype_manual(values = c("solid", "longdash", "dotted")) +
  theme_bw() +
  theme(legend.position = c(.2, .8),
        legend.background = element_rect(color = "black"),
        legend.key.width = unit(2.5, "cm")) +
  labs(x = "Age, in years",
       y = "Estimated Marginal Mean\nVineland Socialization Age Equivalent",
       linetype = "Communication",
       fill     = "Communication",
       color    = "Communication")
```

#### More Customized - Black and White

This version would be better for a publication.

```{r}
effects::Effect(focal.predictors = c("age2","sicdegp"),
                mod = fit_lmer_2a_re,
                xlevels = list(age2 = seq(from = 0, to = 11, by = .1))) %>% 
  data.frame() %>% 
  dplyr::mutate(age = age2 + 2) %>% 
  dplyr::mutate(sicdegp = factor(sicdegp,
                                 levels = c("high", "med", "low"),
                                 labels = c("High", "Medium", "Low"))) %>% 
  ggplot(aes(x = age,
             y = fit,
             group = sicdegp)) +
  geom_ribbon(aes(ymin = lower,
                  ymax = upper,
                  fill = sicdegp),
              alpha = .4) +
  geom_line(aes(linetype = sicdegp),
            size = .7) +
  scale_x_continuous(breaks = c(2, 3, 5, 9, 13)) +
  scale_y_continuous(breaks = seq(from = 0, to = 120, by = 20)) +
  scale_linetype_manual(values = c("solid", "longdash", "dotted")) +
  scale_fill_manual(values = c("gray10", "gray40", "gray60")) +
  theme_bw() +
  theme(legend.position = c(.15, .8),
        legend.background = element_rect(color = "black"),
        legend.key.width = unit(2, "cm")) +
  labs(x = "Age, in years",
       y = "Estimated Marginal Mean\nVineland Socialization Age Equivalent",
       linetype = "Communication",
       fill     = "Communication")
```



### Blups vs. Fixed Effects

**BLUP** = Best Linear Unbiased Predictor

A BLUP is the specific prediction for an individual supject, showin by black lines below.  This includes the fixed effects as well as the specific random effects for a given individual.  

Comparatively, the blue lines below display the predictions for fixed effects only.


```{r}
data_long %>% 
  dplyr::mutate(sicdegp = fct_recode(sicdegp,
                                     "Low Communication" = "low",
                                     "Medium Communication" = "med",
                                     "High Communication" = "high")) %>% 
  dplyr::mutate(pred_fixed = predict(fit_lmer_2a_re, re.form = NA)) %>% # fixed effects only
  dplyr::mutate(pred_wrand = predict(fit_lmer_2a_re)) %>%               # fixed and random effects together
  ggplot(aes(x = age2,
             y = vsae)) +
  geom_line(aes(y = pred_wrand,           # BLUP = fixed and random effects together
                group = childid,
                color = "BLUP",
                size  = "BLUP")) +
  geom_line(aes(y = pred_fixed,           # fixed effects only
                group = sicdegp,
                color = "Fixed",
                size  = "Fixed")) +
  scale_color_manual(name = "Model: ",
                     values = c("BLUP"  = "black",
                                "Fixed" = "blue")) +
  scale_size_manual(name = "Model: ",
                    values = c("BLUP"  = .5,
                               "Fixed" = 1.5)) +
  facet_grid(. ~ sicdegp) +
  theme_bw() +
  labs(x = "Age, in years",
       y = "Estimated Marginal Mean\nVineland Socialization Age Equivalent") +
  theme(legend.position = "bottom",
        legend.key.width = unit(1.5, "cm"))
```




```{r, fig.height=8, fig.width=8}
data_long %>% 
  dplyr::mutate(pred_fixed = predict(fit_lmer_2a_re, re.form = NA)) %>% 
  dplyr::mutate(pred_wrand = predict(fit_lmer_2a_re)) %>% 
  dplyr::filter(childid %in% sample(levels(data_long$childid), 25)) %>%  # 25 randomly sampled children
  ggplot(aes(x = age,
             y = vsae)) +
  geom_point(aes(color = sicdegp),
             size = 3) +
  geom_line(aes(y = pred_wrand,
                linetype = "BLUP",
                size     = "BLUP"),
            color = "black") +
  geom_line(aes(y = pred_fixed,
                color = sicdegp,
                linetype = "Fixed",
                size     = "Fixed")) +
  scale_linetype_manual(name = "Model: ",
                        values = c("BLUP"  = "longdash",
                                   "Fixed" = "solid")) +
  scale_size_manual(name = "Model: ",
                    values = c("BLUP"  = .5,
                               "Fixed" = 1)) +
  facet_wrap(. ~ childid, labeller = "label_both") +
  theme_bw() +
  theme(legend.position = "bottom",
        legend.key.width = unit(1.5, "cm")) +
  labs(x = "Age, in years",
       y = "Estimated Marginal Mean\nVineland Socialization Age Equivalent",
       color = "Communication:")
```






<!--chapter:end:11-example_autism.Rmd-->

# Longitudinal MLM: Hedeker & Gibbons - Depression


```{r, echo=FALSE}
library(pander)

panderOptions('digits', 2)
panderOptions('round', 2)
panderOptions('keep.trailing.zeros', TRUE)
panderOptions('keep.line.breaks', TRUE)
```


```{r}
library(tidyverse)    # all things tidy
library(pander)       # nice looking genderal tabulations
library(furniture)    # nice table1() descriptives
library(texreg)       # Convert Regression Output to LaTeX or HTML Tables
library(psych)        # contains some useful functions, like headTail
library(sjstats)      # ICC calculationsv
library(effects)      # Estimated Marginal Means
library(VIM)          # Visualization and Imputation of Missing Values 
library(naniar)       # Summaries and Visualisations for Missing Data
library(corrplot)     # Vizualize correlation matrix

library(lme4)         # Linear, generalized linear, & nonlinear mixed models

library(haven)        # read in SPSS dataset
```


## Background

Starting in chapter 4, @hedeker2006 details analysis of a psychiatric study described by @reisby1977.  This study focues on the relationship between Imipramine (IMI) and Desipramine (DMI) plasma levels and clinical response in 66 depressed inpatients (37 endogenous and 29 non-endogenous).  The IMI and DMI measures were only taken in the later weeks, but are not used here.

Dependent or outcome variable:   

* `hamd` Hamilton Depression Scores (HD)
    
    
Independent or predictor variables:  

* `endog` Prepression Diagnosis 
    + endogenous  
    + non-endogenous/reactive 
    
* IMI (imipramine) drug-plasma levels (g/l)     
    + antidepressant given 225 mg/day, weeks 3-6   
    
* DMI (desipramine) drug-plasma levels (g/l)
    + metabolite of imipramine


```{r}
data_raw <- haven::read_spss("http://www.uic.edu/~hedeker/riesby.sav") %>%         # read from teh webpage 
  dplyr::select(-intrcpt, -endweek)                                                # de-select or delete some variables 
```


```{r}
data_raw %>% 
  psych::headTail(top = 11, bottom = 8)
```

### Long Format


```{r}
data_long <- data_raw %>%                                        # save the dataset as a new name
  dplyr::filter(!is.na(hamd)) %>%                                # remove NA or missing scores
  dplyr::mutate(id = factor(id)) %>%                             # declare grouping var a factor
  dplyr::mutate(endog = factor(endog,                            # attach labels to a grouping variable
                               levels = c(0, 1),                 # order of the levels should match levels
                               labels = c("Reactive",            # order matters!
                                          "Endogenous"))) %>% 
  dplyr::select(id, week, endog, hamd) %>%                       # select the order of variables to include
  dplyr::arrange(id, week)                                       # sort observations 
```


```{r}
data_long %>% 
  psych::headTail(top = 11, bottom = 8)
```

### Wide Format


```{r}
data_wide <- data_long %>%     # save the dataset as a new name
  tidyr::spread(key = week,    # name the varaible that specifies how to spread
                value = hamd,  # name the variable to be spread out
                sep = "_")     # add to combine the key-variables name before its value
```


Notice the missing values, displayed as `NA`.

```{r}
data_wide %>% 
  psych::headTail()
```



## Exploratory Data Analysis

### Diagnosis Group

```{r, results="asis"}
# Knit to Website: output = "html"
# Knit to PDF:     output = "latex2"
# View on Screen:  output = ""text", or "markdown", "html"

data_long %>% 
  dplyr::filter(week == 0) %>% 
  furniture::table1("Depression Type" = endog,
                    output = "html")
```

### Missing Data & Attrition

Plot the amount of missing vlaues and the amount of each patter of missing values.

#### `VIM` package

```{r}
data_wide %>% 
  VIM::aggr(numbers = TRUE,   # shows the number to the far right
            prop = FALSE)     # shows counts instead of proportions
```



#### `naniar` package


```{r}
data_wide %>% 
  naniar::gg_miss_upset(sets = c("week_0_NA",
                                 "week_1_NA",
                                 "week_2_NA",
                                 "week_3_NA",
                                 "week_4_NA",
                                 "week_5_NA"),
                        keep.order = TRUE) 
```





### Depression Over Time, by Group


#### Table of Means

> Default = COMPLETE CASES ONLY!!!  

Note - the sample size at each time point is the same, but subjects are only included if they have data at every time point

```{r, results='asis'}
# Knit to Website: output = "html"
# Knit to PDF:     output = "latex2"
# View on Screen:  output = ""text", or "markdown", "html"

data_wide %>%          
  furniture::table1(week_0, week_1, week_2, 
                    week_3, week_4, week_5,
                    splitby = ~ endog,
                    test = TRUE,
                    na.rm = TRUE,              # default: COMPLETE CASES ONLY!!!!!
                    output = "html")           
```



> Specify All data: 

note -  that the smaple sizes will be different for each time point

```{r, results='asis'}
# Knit to Website: output = "html"
# Knit to PDF:     output = "latex2"
# View on Screen:  output = ""text", or "markdown", "html"

data_wide %>%          
  furniture::table1(week_0, week_1, week_2, 
                    week_3, week_4, week_5,
                    splitby = ~ endog,
                    test = TRUE,
                    na.rm = FALSE,           # INCLUDES ALL DATA !!!!
                    output = "html")   
```


#### Using the LONG formatted dataset

Each person's data is stored on multiple lines, one for each time point.


> FOR ALL DATA!

```{r}
data_sum_all <- data_long %>% 
  dplyr::group_by(endog, week) %>%                # specify the groups
  dplyr::summarise(hamd_n    = n(),                      # count of valid scores
                   hamd_mean = mean(hamd),               # mean score
                   hamd_sd   = sd(hamd),                 # standard deviation of scores
                   hamd_sem  = hamd_sd / sqrt(hamd_n))   # stadard error for the mean of scores

data_sum_all
```



> FOR COMPLETE CASES ONLY!!!

```{r}
data_sum_cc <- data_long %>% 
  dplyr::group_by(id) %>%               # group-by participant
  dplyr::mutate(person_vsae_n = n()) %>%    # count the number of valid VSAE scores
  dplyr::filter(person_vsae_n == 6) %>%     # restrict to only thoes children with 5 valid scores
  dplyr::group_by(endog, week) %>%                # specify the groups
  dplyr::summarise(hamd_n    = n(),                      # count of valid scores
                   hamd_mean = mean(hamd),               # mean score
                   hamd_sd   = sd(hamd),                 # standard deviation of scores
                   hamd_sem  = hamd_sd / sqrt(hamd_n))   # stadard error for the mean of scores

data_sum_cc
```






#### Person-Profile Plot or Spaghetti Plot

Use the data in LONG format.

A scatterplot of all observations of depression scores over time, joining the dots of each individual's data.

> NOTE: Not all lines have a point for every week!

```{r}
data_long %>% 
  ggplot(aes(x = week,
             y = hamd)) +
  geom_point() +
  geom_line(aes(group = id))   # join points that belong to the same "id"
```


```{r}
data_long %>% 
  ggplot(aes(x = week,
             y = hamd,
             color = endog)) +    # color points and lines by the "endog" variable
  geom_point() +
  geom_line(aes(group = id))
```

```{r}
data_long %>% 
  ggplot(aes(x = week,
             y = hamd)) +
  geom_point() +
  geom_line(aes(group = id)) +
  facet_grid( ~ endog)            # side-by-side pandels by the "endog" variable
```

```{r}
data_long %>% 
  ggplot(aes(x = week %>% factor(),
             y = hamd)) +
  geom_boxplot() +                   # compare center and spread
  facet_grid( ~ endog)           
```

```{r}
data_long %>% 
  ggplot(aes(x = week %>% factor(),
             y = hamd)) +
  geom_violin() +                   # similar to boxplots to show distribution
  facet_grid( ~ endog)           
```

```{r}
data_long %>% 
  ggplot(aes(x = week,
             y = hamd)) +
  geom_point() +
  geom_line(aes(group = id)) +
  facet_grid( ~ endog) +
  geom_smooth() +                     # DEFAULTS: method = "loess", se = TRUE, color = "blue"
  geom_smooth(method = "lm",
              se = FALSE,
              color = "hot pink")
```


```{r}
data_long %>% 
  ggplot(aes(x = week,
             y = hamd)) +
  geom_point() +
  geom_line(aes(group = id)) +
  facet_grid( ~ endog) +
  geom_smooth(aes(color = "Flexible"),
              method = "loess",
              se = FALSE,) +
  geom_smooth(aes(color = "Linear"),
              method = "lm",
              se = FALSE) +
  scale_color_manual(name = "Smoother Type: ",
                     values = c("Flexible" = "blue", 
                                "Linear"    = "red")) +
  theme_bw() +
  theme(legend.position = "bottom")
```



## Patterns in the Outcome Over Time

### Variance-Covariance

#### Full Matrix

* Variances are down the diagonal    
     + Increasing variance over time violates the ANOVA assumption of *homogeity of variance*
     
```{r}
data_wide %>% 
  dplyr::select(starts_with("week_")) %>%  # just the outcome(s)
  cov(use = "complete.obs")  %>%           # covariance matrix, LIST-wise deletion
  round(3)
```

```{r}
data_wide %>% 
  dplyr::select(starts_with("week_")) %>%  # just the outcome(s)
  cov(use = "pairwise.complete.obs")  %>%  # covariance matrix, PAIR-wise deletion
  round(3)
```

#### Just Variances

Notice the variance in scores increases over time, which is seen in the side-by-side boxplots.

```{r}
data_wide %>% 
  dplyr::select(starts_with("week_")) %>%  # just the outcome(s)
  cov(use = "pairwise.complete.obs")  %>%  # covariance matrix, PAIR-wise deletion
  diag()                                   #  extracts just the variances
```

### Correlation

#### Full Matrix

Pairwise relationships are easier to eye-ball magnitude when presented as correlations, rather than covariances, due to the relative scale.

```{r}
data_wide %>% 
  dplyr::select(starts_with("week_")) %>% # just the outcome(s)
  cor(use = "complete.obs") %>%           # correlation matrix - LIST-wise deletion
  round(2)                                
```

```{r}
data_wide %>% 
  dplyr::select(starts_with("week_")) %>% # just the outcome(s)
  cor(use = "pairwise.complete.obs") %>%   # correlation matrix - PAIR-wise deletion
  round(2)                                
```


#### Visualization

Looking for patterns is always easier with a plot.  All RM or mixed ANOVA assume sphericity or compound symmetry, meaning that all the correlations in the matrix would be the same.  This is not the case for these data.  Instead we see a classic pattern of corralary decay.  Measures taken close in time, say 1 week apart, exhibit the highest degree of correlation.  The farther apart in time that two measures are taken, the less correlated they are.  Note that the adjacent measures become more highly correlated, too.  This can be due to attrition; later time points having a smaller sample size.


```{r}
data_wide %>% 
  dplyr::select(starts_with("week_")) %>% # just the outcome(s)
  cor(use = "pairwise.complete.obs") %>%   # correlation matrix
  corrplot::corrplot.mixed(upper = "ellipse")
```

### For Each Group 

It can be a good ideal to investigate if the groups exhibit a similar pattern in correlation.

> Reactive Depression

```{r}
data_wide %>% 
  dplyr::filter(endog == "Reactive") %>%    # filter observations for the REACTIVE group
  dplyr::select(starts_with("week_")) %>% 
  cor(use = "pairwise.complete.obs") %>%   
  corrplot::corrplot.mixed(upper = "ellipse")
```


> Endogenous Depression

```{r}
data_wide %>% 
  dplyr::filter(endog == "Endogenous") %>%    # filter observations for the Endogenous group
  dplyr::select(starts_with("week_")) %>%
  cor(use = "pairwise.complete.obs") %>%   
  corrplot::corrplot.mixed(upper = "ellipse")
```





## MLM - Null or Emptly Models


###  Fit the model

> Random Intercepts, with Fixed Intercept and Time Slope (i.e. Trend)....@hedeker2006 section 4.3.5, starting on page 55

Since this situation deals with longitudinal data, it is more appropriate to start off including the time variable in the null model as a fixed effect only.

```{r}
fit_lmer_week_RI_reml <- lme4::lmer(hamd ~ week + (1|id), 
                                    data = data_long,
                                    REML = TRUE)
```


### Table of Parameter Estimates

```{r, include = FALSE}
texreg::screenreg(fit_lmer_week_RI_reml, single.row = TRUE)
```


```{r mlmRI, results='asis'}
# Knit to Website: texreg::htmlreg()
# Knit to PDF:     texreg::texreg()
# View on Screen:  texreg::screenreg()

texreg::htmlreg(fit_lmer_week_RI_reml, 
                single.row = TRUE,
                caption = "MLM: Random Intercepts Null Model fit w/REML",
                caption.above = TRUE,
                custom.note = "Reproduction of Hedeker's table 4.3 on page 55, except using REML here instead of ML")
```


On average, patients start off with HDRS scores of `r fixef(fit_lmer_week_RI_reml)["(Intercept)"] %>% round(2)` and then change by `r fixef(fit_lmer_week_RI_reml)["week"] %>% round(2)` points each week.  This weekly improvement of about 2 points a week is statistically significant via the Wald test.



### Estimated Marginal Means Plot

> Multilevel model on page 55 [@hedeker2006]

$$
\hat{y} = `r fixef(fit_lmer_week_RI_reml)["(Intercept)"] %>% round(3)` + 
          `r fixef(fit_lmer_week_RI_reml)["week"] %>% round(3)` week
$$


The fastest way to plot a model is to use the `sjPlot::plot_model()` function.

```{r}
sjPlot::plot_model(fit_lmer_week_RI_reml,
                   type = "pred",
                   terms = c("week"))
```


### Estimated Marginal Means and Emperical Bayes Plots

With a bit more code we can plot not only the **marginal model** (fixed effects only), but add the Best Linear Unbiased Predictions (**BLUP**s) or person-specific specific models (both fixed and random effects).

```{r}
data_long %>% 
  dplyr::mutate(pred_fixed = predict(fit_lmer_week_RI_reml, re.form = NA)) %>% # fixed effects only
  dplyr::mutate(pred_wrand = predict(fit_lmer_week_RI_reml)) %>%               # fixed and random effects together
  ggplot(aes(x = week,
             y = hamd,
             group = id)) +
  geom_line(aes(y        = pred_wrand,
                color    = "BLUP",
                size     = "BLUP",
                linetype = "BLUP")) +
  geom_line(aes(y        = pred_fixed,
                color    = "Marginal",
                size     = "Marginal",
                linetype = "Marginal")) +
  theme_bw() +
  scale_color_manual(name   = "Type of Prediction",
                     values = c("BLUP"     = "gray50",
                                "Marginal" = "blue"))  +
  scale_size_manual(name    = "Type of Prediction",
                    values = c("BLUP"      = .5,
                                "Marginal" = 1.25))  +
  scale_linetype_manual(name   = "Type of Prediction",
                        values = c("BLUP"     = "longdash",
                                   "Marginal" = "solid"))  +
  theme(legend.position = c(0, 0),
        legend.justification = c(-0.1, -0.1),
        legend.background = element_rect(color = "black"),
        legend.key.width = unit(1.5, "cm")) +
  labs(x = "Weeks Since Baseline",
       y = "Hamilton Depression Scores")
```

Notice that in this model, all the BLUPs are parallel.  That is becuase we are only letting the intercept vary from person-to-person while keeping the effect of time (slope) constant.



> Reproduce Table 4.4 on page 55 [@hedeker2006]

One way to judge a model is to compare the estimated means to the observed means to see how accuratedly they are represented by the model.  This excellent fit of the estimated marginal means to the observed data supports the hypothesis that the change in depression across time is LINEAR.

```{r}
obs <- data_long %>% 
  dplyr::group_by(week) %>% 
  dplyr::summarise(observed = mean(hamd, na.rm = TRUE)) 

effects::Effect(focal.predictors = "week",
                mod = fit_lmer_week_RI_reml,
                xlevels = list(week = 0:5)) %>% 
  data.frame() %>% 
  dplyr::rename(estimated = fit) %>% 
  dplyr::left_join(obs, by = "week") %>% 
  dplyr::select(week, observed, estimated) %>% 
  dplyr::mutate(diff = observed - estimated) %>% 
  pander::pander(caption = "Observed and Estimated Means")
```



### Intra-individual Correlation (ICC)

```{r}
sjstats::icc(fit_lmer_week_RI_reml)
```

**Interpretation**  Nearly HALF of the variance in depression scores not explained by the linear effect of time is attributable to person-to-person differences.  Thus, subjects display considerable heterogeneity in depression levels.

This value of 46% is an oversimplification of the correlation matrix above.



### Compare to the Single-Level Null: No Random Effects

> Simple Linear Regression, @hedeker2006

To compare, fit the single level regression model

```{r}
fit_lm_week_ml <- lm(hamd ~ week,
               data = data_long)
```

#### Table of Parameter Estimates

```{r, include = FALSE}
texreg::screenreg(list(fit_lm_week_ml, fit_lmer_week_RI_reml))
```

```{r olsvsmlm, results='asis'}
# Knit to Website: texreg::htmlreg()
# Knit to PDF:     texreg::texreg()
# View on Screen:  texreg::screenreg()

texreg::htmlreg(list(fit_lm_week_ml, fit_lmer_week_RI_reml),
                custom.model.names = c("Single-Level", "Multilevel"),
                caption = "MLM: Longitudinal Null Models",
                caption.above = TRUE,
                custom.note = "The singel-level model treats are observations as being independent and unrelated to each other, even if they were made on the same person.")
```


For the multilevel model, the Wald tests indicated the fixed intercept is significant (no surprized that the depressions scores are not zero at baseline).  More of note is the significance of the fixed effect of time.  This signifies that depression scores are declining over time.  On average, patients are improving across time, by an average of 2.4 points a week.



#### Residual Variance


Note: the fixed estimates are very similar for the two models, but the standard errors are different.  Additionally, whereas the single-level regression lumps all remaining variance together ($\sigma^2$), the multilevel model seperates it into within-subjects ($\sigma^2_{u0}$ or $\tau_{00}$) and between-subjects variance ($\sigma^2_{e}$ or $\sigma^2$).


```{r}
sigma(fit_lm_week_ml)^2
```


```{r}
sjstats::re_var(fit_lmer_week_RI_reml)  # in longitudinal data, a group of observations = a participant or person
```

> "One statistician's error term is another's career!"
>
> @hedeker2006, page 56







## MLM: Add Random Slope for Time (i.e. Trend)

### Fit the Model

```{r}
fit_lmer_week_RIAS_reml <- lme4::lmer(hamd ~ week + (week|id), #     MLM-RIAS
                                      data = data_long,
                                      REML = TRUE)
```


### Table of Prameter Estimates

```{r, include = FALSE}
texreg::screenreg(list(fit_lmer_week_RI_reml, fit_lmer_week_RIAS_reml), single.row = TRUE)
```


```{r mlmRS, results='asis'}
# Knit to Website: texreg::htmlreg()
# Knit to PDF:     texreg::texreg()
# View on Screen:  texreg::screenreg()

texreg::htmlreg(list(fit_lmer_week_RI_reml, 
                     fit_lmer_week_RIAS_reml),
                custom.model.names = c("Random Intercepts",
                                       " And Random Slopes"),
                caption = "MLM: Null models fit w/REML",
                caption.above = TRUE,
                custom.note = "Hedeker table 4.4 on page 55 and table 4.5 on page 58, except using REML here instead of ML")
```


Visually, we can see that the unexplained or residual variance is less (12.21 vs 19.10) for the model that includes person-specific slopes (trajectories over time).

Note: the negative covariance between random intercepts and random slopes ($\sigma_{u01} = \tau_{01} = -1.48$): 

> "This suggests that patients who are initially more depressed (i.e. greater intercepts) improve at a greater rate (i.e. more pronounced negative slopes).  An alternative explainatio, though,is that of a floor effect due to the HDRS rating scale.  Simply put, patients with less depressed intitial scores have a more limited range of lower scores than those with higher initial scores."
>
> @hedeker2006, page 58


### Likelihood Ratio Test

```{r}
anova(fit_lmer_week_RI_reml, fit_lmer_week_RIAS_reml, 
      model.names = c("RI", "RIAS"),
      refit = FALSE) %>% 
  pander::pander(caption = "LRT: Assess Significance of Random Slopes")
```

Including the random slope for time significantly improved the model fit via the formal **Likelihood Ratio Test**.  This rejects the assumption of compound symmetry.


### Estimated Marginal Means Plot

```{r}
sjPlot::plot_model(fit_lmer_week_RIAS_reml,
                   type = "pred",
                   terms = c("week"))
```

Adding the random slopes didn't change the estimates for the fixed effects much.


### Estimated Marginal Means and Emperical Bayes Plots

```{r}
data_long %>% 
  dplyr::mutate(pred_fixed = predict(fit_lmer_week_RIAS_reml, re.form = NA)) %>% # fixed effects only
  dplyr::mutate(pred_wrand = predict(fit_lmer_week_RIAS_reml)) %>%               # fixed and random effects together
  ggplot(aes(x = week,
             y = hamd,
             group = id)) +
  geom_line(aes(y        = pred_wrand,
                color    = "BLUP",
                size     = "BLUP",
                linetype = "BLUP")) +
  geom_line(aes(y        = pred_fixed,
                color    = "Marginal",
                size     = "Marginal",
                linetype = "Marginal")) +
  theme_bw() +
  scale_color_manual(name   = "Type of Prediction",
                     values = c("BLUP"     = "gray50",
                                "Marginal" = "blue"))  +
  scale_size_manual(name    = "Type of Prediction",
                    values = c("BLUP"      = .5,
                                "Marginal" = 1.25))  +
  scale_linetype_manual(name   = "Type of Prediction",
                        values = c("BLUP"     = "longdash",
                                   "Marginal" = "solid"))  +
  theme(legend.position = c(0, 0),
        legend.justification = c(-0.1, -0.1),
        legend.background = element_rect(color = "black"),
        legend.key.width = unit(1.5, "cm")) +
  labs(x = "Weeks Since Baseline",
       y = "Hamilton Depression Scores")
```

BLUPs are also refered to as **Empirical Bayes Estimates** and may be extracted from a model fit.  In this cases there will be a specific intercept (`(Intercept)`) and time slope (`week`) for each individual or person (`id`).

#### Fixed Effects 

Marginal Model = within-subject effects


```{r}
fixef(fit_lmer_week_RIAS_reml)
```


#### Random Effects

between-subjects effects


```{r}
ranef(fit_lmer_week_RIAS_reml)$id %>% 
  head()
```

#### BLUPs or Empirical Bayes Estimates

fixed effects + random effects

```{r}
coef(fit_lmer_week_RIAS_reml)$id %>% 
  head()
```


We can create a scatterplot of these to see the correlation between them.

```{r}
coef(fit_lmer_week_RIAS_reml)$id %>% 
  ggplot(aes(x = week,
             y = `(Intercept)`)) +
  geom_point() +
  geom_hline(yintercept = fixef(fit_lmer_week_RIAS_reml)["(Intercept)"],
             linetype = "dashed") +
  geom_vline(xintercept = fixef(fit_lmer_week_RIAS_reml)["week"],
             linetype = "dashed") +
  geom_smooth(method = "lm") +
  labs(title = "Hedeker's Figure 4.4 on page 59",
       subtitle = "Reisby data: Estimated random effects",
       x = "Week Change in Depression",
       y = "Baseline Depression Level") 
  
```


## MLM: Coding of Time

So far we have used the variable `week` to denote time as weeks since baseline = `week` $\in 0, 1, 2, 3, 4, 5$


```{r}
data_long_wc <- data_long %>% 
  dplyr::mutate(weekc = week - 2.5)

head(data_long_wc)
```

### Fit the Model

```{r}
fit_lmer_week_RIAS_reml_wc <- lme4::lmer(hamd ~ weekc + (weekc|id), #     MLM-RIAS
                                        data = data_long_wc,
                                        REML = TRUE)
```

### Table of Parameter Estimates

```{r, include = FALSE}
texreg::screenreg(list(fit_lmer_week_RIAS_reml, fit_lmer_week_RIAS_reml_wc), single.row = TRUE)
```


```{r mlmwc, results='asis'}
# Knit to Website: texreg::htmlreg()
# Knit to PDF:     texreg::texreg()
# View on Screen:  texreg::screenreg()

texreg::htmlreg(list(fit_lmer_week_RIAS_reml, 
                     fit_lmer_week_RIAS_reml_wc),
                custom.model.names = c("Random Intercepts",
                                       " And Random Slopes"),
                caption = "MLM: Null models fit w/REML",
                caption.above = TRUE,
                custom.note = "Hedeker table table 4.5 on page 58 and table 4.6 on page 61, except using REML here instead of ML")
```

* Unchanged    
    + model fit: AIC, BIC, -2LL, residual variance    
    + fixed effect of week    
    + variance for random intercepts     
    
* Changed    
    + fixed intercept    
    + variance for random slopes   
    + covariance between random intercepts and random slopes

### Estimated Marginal Means and Emperical Bayes Plots

```{r}
data_long_wc %>% 
  dplyr::mutate(pred_fixed = predict(fit_lmer_week_RIAS_reml_wc, re.form = NA)) %>% # fixed effects only
  dplyr::mutate(pred_wrand = predict(fit_lmer_week_RIAS_reml_wc)) %>%               # fixed and random effects together
  ggplot(aes(x = weekc,
             y = hamd,
             group = id)) +
  geom_line(aes(y        = pred_wrand,
                color    = "BLUP",
                size     = "BLUP",
                linetype = "BLUP")) +
  geom_line(aes(y        = pred_fixed,
                color    = "Marginal",
                size     = "Marginal",
                linetype = "Marginal")) +
  theme_bw() +
  scale_color_manual(name   = "Type of Prediction",
                     values = c("BLUP"     = "gray50",
                                "Marginal" = "blue"))  +
  scale_size_manual(name    = "Type of Prediction",
                    values = c("BLUP"      = .5,
                                "Marginal" = 1.25))  +
  scale_linetype_manual(name   = "Type of Prediction",
                        values = c("BLUP"     = "longdash",
                                   "Marginal" = "solid"))  +
  theme(legend.position = c(0, 0),
        legend.justification = c(-0.1, -0.1),
        legend.background = element_rect(color = "black"),
        legend.key.width = unit(1.5, "cm")) +
  labs(x = "Weeks Centered at Mid-study",
       y = "Hamilton Depression Scores")
```

Again, centering time doesn't change the interpretation at all.







## MLM: Effect of DIagnosis on Time Trends (Fixed Interaction)


The researcher specifically wants to know if the trajectory over time differs for the two types of depression.  This translates into a fixed effects interaction between time and group.  

> Start by comapring random intercepts only (RI) to a random intercetps and slopes (RIAS) model. 

### Fit the Models

```{r}
fit_lmer_week_RIAS_ml <- lme4::lmer(hamd ~ week + (week|id), 
                                    data = data_long,
                                    REML = FALSE)

fit_lmer_wkdx_RIAS_ml <- lme4::lmer(hamd ~ week*endog + (week|id), 
                                    data = data_long,
                                    REML = FALSE)
```


### Estimated Marginal Meanse Plot

```{r}
sjPlot::plot_model(fit_lmer_wkdx_RIAS_ml,
                   type = "pred",
                   terms = c("week", "endog"),
                   title = "Hedeker's Table 4.7 on page 64")
```

### Likelihood Ratio Test

```{r}
anova(fit_lmer_week_RIAS_ml, fit_lmer_wkdx_RIAS_ml, 
      model.names = c("Just Time", "Time X Dx")) %>% 
  pander::pander(caption = "LRT: Assess Significance of Diagnosis Moderation of Trend")
```

The more complicated model (including the moderating effect of diagnosis) is NOT supported.





## MLM: Quadratic Trend

### Fit the Model

```{r}
fit_lmer_quad_RIAS_ml <- lme4::lmer(hamd ~ week + I(week^2) + (week+ I(week^2)|id), 
                                    data = data_long,
                                    REML = FALSE)
```


### Table of Parameter Estimates

```{r, include = FALSE}
texreg::screenreg(list(fit_lmer_week_RIAS_ml, fit_lmer_quad_RIAS_ml), single.row = TRUE)
```


```{r mlmquad, results='asis'}
# Knit to Website: texreg::htmlreg()
# Knit to PDF:     texreg::texreg()
# View on Screen:  texreg::screenreg()

texreg::htmlreg(list(fit_lmer_week_RIAS_ml,
                     fit_lmer_quad_RIAS_ml),
                custom.model.names = c("Linear Trend",
                                       "QUadratic Trend"),
                caption = "MLM: RIAS models fit w/ML",
                caption.above = TRUE,
                custom.note = "Hedeker table 4.5 on page 58 and table 5.1 on page 84")
```

### Likelihood Ratio Test


```{r}
anova(fit_lmer_week_RIAS_ml, fit_lmer_quad_RIAS_ml)
```

Even though the Wald test did not find the quadratic fixed time trend to be significant at the population level (marginal), the LRT finds that including the quadratic terms improves the model's fit.  




### Estimated Marginal Means Plot

```{r}
fixef(fit_lmer_quad_RIAS_ml)
```


```{r}
sjPlot::plot_model(fit_lmer_quad_RIAS_ml,
                   type = "pred",
                   terms = "week")
```

At the population level, the curviture is very slight.


### BLUPs or Emperical Bayes Estimates

```{r}
coef(fit_lmer_quad_RIAS_ml)$id
```

For Illustration, two cases have been hand selected: `id` = 115 and 610.

```{r}
fun_115 <- function(week){
  coef(fit_lmer_quad_RIAS_ml)$id["115", "(Intercept)"] +
  coef(fit_lmer_quad_RIAS_ml)$id["115", "week"] * week +
  coef(fit_lmer_quad_RIAS_ml)$id["115", "I(week^2)"] * week^2
}


fun_610 <- function(week){
  coef(fit_lmer_quad_RIAS_ml)$id["610", "(Intercept)"] +
  coef(fit_lmer_quad_RIAS_ml)$id["610", "week"] * week +
  coef(fit_lmer_quad_RIAS_ml)$id["610", "I(week^2)"] * week^2
}
```



```{r, fig.cap="Two Example BLUPS for two different participants"}
data_long %>% 
  dplyr::mutate(pred_fixed = predict(fit_lmer_quad_RIAS_ml, re.form = NA)) %>% # fixed effects only
  dplyr::mutate(pred_wrand = predict(fit_lmer_quad_RIAS_ml)) %>%               # fixed and random effects together
  ggplot(aes(x = week,
             y = hamd,
             group = id)) +
  stat_function(fun = fun_115) +          # add cure for ID = 115
  stat_function(fun = fun_610) +          # add cure for ID = 610
  geom_line(aes(y        = pred_fixed),
                color    = "blue",
                size     = 1.25)  +
  theme_bw() +
  theme(legend.position = c(0, 0),
        legend.justification = c(-0.1, -0.1),
        legend.background = element_rect(color = "black"),
        legend.key.width = unit(1.5, "cm")) +
  labs(x = "Weeks Since Baseline",
       y = "Hamilton Depression Scores",
       title = "Similar to Hedeker's Figure 5.3 on page 84",
       subtitle = "Marginal Mean show in thinker blue")
```

These two individuals have quite different curvitures and illustrated how this type of curvatures in person-specific trajectories may end up cancelling each other out to arive at a fairly linear marginal model.


### Estimated Marginal Means and Emperical Bayes Plots
 
Note: although the BLUPs are shown for all participants, the predictions are just connects and are therefore slightly jagged and now smoother like the lines on the plot above.

```{r, fig.cap = "EStimated curvilinear trends"}
data_long %>% 
  dplyr::mutate(pred_fixed = predict(fit_lmer_quad_RIAS_ml, re.form = NA)) %>% # fixed effects only
  dplyr::mutate(pred_wrand = predict(fit_lmer_quad_RIAS_ml)) %>%               # fixed and random effects together
  ggplot(aes(x = week,
             y = hamd,
             group = id)) +
  geom_line(aes(y        = pred_wrand,
                color    = "BLUP",
                size     = "BLUP",
                linetype = "BLUP")) +
  geom_line(aes(y        = pred_fixed,
                color    = "Marginal",
                size     = "Marginal",
                linetype = "Marginal")) +
  theme_bw() +
  scale_color_manual(name   = "Type of Prediction",
                     values = c("BLUP"     = "gray50",
                                "Marginal" = "blue"))  +
  scale_size_manual(name    = "Type of Prediction",
                    values = c("BLUP"      = .5,
                                "Marginal" = 1.25))  +
  scale_linetype_manual(name   = "Type of Prediction",
                        values = c("BLUP"     = "longdash",
                                   "Marginal" = "solid"))  +
  theme(legend.position = c(0, 0),
        legend.justification = c(-0.1, -0.1),
        legend.background = element_rect(color = "black"),
        legend.key.width = unit(1.5, "cm")) +
  labs(x = "Weeks Since Baseline",
       y = "Hamilton Depression Scores",
       title = "Hedeker's Figure 5.4 on page 85")
```

At the person-level, the curviture is very diverse (heterogeneous).  Some individuals have accelerating downward tend while other have accelerating upward trends.  

Th improvement that the curvilinear model provides in describing change across time is perhaps modest.




<!--chapter:end:12-example_hedeker4_reisby.Rmd-->

# Longitudinal MLM: Hox ch 5 - student GPA


```{r, echo=FALSE}
library(pander)

panderOptions('digits', 2)
panderOptions('round', 2)
panderOptions('keep.trailing.zeros', TRUE)
panderOptions('keep.line.breaks', TRUE)
```


```{r}
library(tidyverse)    # all things tidy
library(pander)       # nice looking genderal tabulations
library(furniture)    # nice table1() descriptives
library(texreg)       # Convert Regression Output to LaTeX or HTML Tables
library(psych)        # contains some useful functions, like headTail
library(sjstats)      # ICC calculations
library(sjPlot)       # Visualization for Models
library(effects)      # Effec displays for Models

library(lme4)         # non-linear mixed-effects models

library(haven)        # read in SPSS dataset
```


## Background


```{block type='rmdlink', echo=TRUE}
The text **"Multilevel Analysis: Techniques and Applications, Third Edition"** [@hox2017] has a companion [website](https://multilevel-analysis.sites.uu.nl/) which includes links to all the data files used throughout the book (housed on the [book's GitHub repository](https://github.com/MultiLevelAnalysis)).  
```


The following example is used through out @hox2017's chapater 5.

The GPA for 200 college students were followed for 6 consecutive semesters (simulated).  Job status was also measured as number of hours worked for the same size occations.  Time-invariant covariates are the student's gender and high school GPA.  The variable `admitted` will not be used.  


```{r}
data_raw <- haven::read_sav("https://github.com/MultiLevelAnalysis/Datasets-third-edition-Multilevel-book/raw/master/chapter%205/GPA2/gpa2long.sav") %>% 
  haven::as_factor()             # retain the labels from SPSS --> factor

tibble::glimpse(data_raw) 
```

```{r}
data_raw %>% 
  dplyr::select(occas, job) %>% 
  table(useNA = "always")
```



```{r}
data_long <- data_raw %>% 
  dplyr::mutate(student = factor(student)) %>% 
  dplyr::mutate(sem = case_when(occas == "year 1 semester 1" ~ 1,
                                occas == "year 1 semester 2" ~ 2,
                                occas == "year 2 semester 1" ~ 3,
                                occas == "year 2 semester 2" ~ 4,
                                occas == "year 3 semester 1" ~ 5,
                                occas == "year 3 semester 2" ~ 6)) %>% 
  dplyr::mutate(semc = sem - 1) %>% 
  dplyr::mutate(job = fct_drop(job)) %>% 
  dplyr::mutate(hrs = case_when(job == "no job" ~ 0,
                                job == "1 hour" ~ 1,
                                job == "2 hours" ~ 2,
                                job == "3 hours" ~ 3,
                                job == "4 or more hours" ~ 4)) %>%  
  dplyr::select(student, sex, highgpa, sem, semc, job, hrs, gpa) %>% 
  dplyr::arrange(student, sem)

psych::headTail(data_long, top = 10)
```


```{r}
data_wide <- data_long %>% 
  furniture::wide(v.names = c("job", "hrs", "gpa"),
                  timevar = "sem",
                  id = "student")


psych::headTail(data_wide)
```


```{r}
data_wide %>% 
  furniture::table1(highgpa, gpa.1, job.1, hrs.1,
                    splitby = ~ sex,
                    output = "html",
                    test = TRUE)
```



```{r}
data_wide %>% 
  furniture::table1(gpa.1, gpa.2, gpa.3, gpa.4, gpa.5, gpa.6,
                    splitby = ~ sex,
                    output = "html")
```

## MLM

### Null Models and ICC



```{r}
fit_lmer_0_re <- lme4::lmer(gpa ~ 1 + (1|student),
                            data = data_long,
                            REML = TRUE)
```

```{r}
sjstats::icc(fit_lmer_0_re)
```


Over a third of the variance in the 6 GPA measures is variance between individuals, and about two-thirds is variance within individuals across time.


```{r}
fit_lmer_1_re <- lme4::lmer(gpa ~ semc + (1|student),
                            data = data_long,
                            REML = TRUE)
```

```{r}
sjstats::icc(fit_lmer_1_re)
```

After accounting for the linear change in GPA over semesters, about half of the remaining variance in GPA scores is attributable person-to-person differences.


### Fixed Effects


```{r}
fit_lmer_0_ml <- lme4::lmer(gpa ~ 1 + (1|student),
                            data = data_long,
                            REML = FALSE)

fit_lmer_1_ml <- lme4::lmer(gpa ~ semc + (1|student),
                            data = data_long,
                            REML = FALSE)


fit_lmer_2_ml <- lme4::lmer(gpa ~ semc + hrs + (1|student),
                            data = data_long,
                            REML = FALSE)


fit_lmer_3_ml <- lme4::lmer(gpa ~ semc + hrs + highgpa + sex + (1|student),
                            data = data_long,
                            REML = FALSE)
```


```{r}
screenreg(list(fit_lmer_0_ml, fit_lmer_1_ml, fit_lmer_2_ml, fit_lmer_3_ml),
          digits = 3)
```

```{r}
anova(fit_lmer_0_ml, fit_lmer_1_ml, fit_lmer_2_ml, fit_lmer_3_ml)
```

### Variance Explained by linear TIME at Level ONE

```{r}
sjstats::re_var(fit_lmer_0_ml)  # baseilne
```

```{r}
sjstats::re_var(fit_lmer_1_ml)  # model to compare
```

#### Raudenbush and Bryk

* Explained variance is a proportion of first-level variance only
* A good option when the multilevel sampling process is is close to two-stage simple random sampling

```{block type='genericEq', echo=TRUE}
**Raudenbush and Bryk Approximate Formula - Level 1 ** *approximate*
$$
approx \;R^2_1 = \frac{\sigma^2_{e-BL} - \sigma^2_{e-MC}}
             {\sigma^2_{e-BL} }
\tag{Hox 4.8}
$$
```



```{r}
(0.098 - 0.058) / 0.098
```


#### Snijders and Bosker


```{block type='genericEq', echo=TRUE}
**Snijders and Bosker Formula - Level 1 ** 

Random Intercepts Models Only, *address potential negative $R^2$ issue*
$$
R^2_1 = 1 - \frac{\sigma^2_{e-MC} + \sigma^2_{u0-MC}}
                 {\sigma^2_{e-BL} + \sigma^2_{u0-BL}}
$$
```




```{r}
1 - (0.058 + 0.063)/(0.098 + 0.057)
```


### Variance Explained by linear TIME at Level TWO

#### Raudenbush and Bryk

```{block type='genericEq', echo=TRUE}
**Raudenbush and Bryk Approximate Formula - Level 2 ** 
$$
approx \; R^2_s = \frac{\sigma^2_{u0-BL} - \sigma^2_{u0-MC}}
             {\sigma^2_{u0-BL} }
\tag{Hox 4.9}
$$
```





```{r}
(0.057 - 0.063)/ 0.057
```

YIKES!  Negative Variance explained!


#### Snijders and Bosker


```{block type='genericEq', echo=TRUE}
**Snijders and Bosker Formula Extended - Level 2 ** 
$$
R^2_2 = 1 - \frac{\frac{\sigma^2_{e-MC}}{B} + \sigma^2_{u0-MC}}
                 {\frac{\sigma^2_{e-BL}}{B} + \sigma^2_{u0-BL}}
$$

$B$ is the average size of the Level 2 units.  Technically, you should use the *harmonic mean*, but unless the clusters differ greatly in size, it doesn't make a huge difference.
```


```{r}
1 - (0.058/6 + 0.063) / (0.098/6 + 0.057)
```

Reason: The intercept only model overestimates the variance at the occasion level and underestimates the variance at the subject level (se chapter 4 of @hox2017)


### Random Effects



```{r}
fit_lmer_3_re <- lme4::lmer(gpa ~ semc + hrs + highgpa + sex + (1|student),
                            data = data_long,
                            REML = TRUE)


fit_lmer_4_re <- lme4::lmer(gpa ~ semc + hrs + highgpa + sex + (semc|student),
                            data = data_long,
                            REML = TRUE)
```


```{r}
anova(fit_lmer_3_re, fit_lmer_4_re, refit = FALSE)
```

### Cross-Level Interaction

```{r}
fit_lmer_4_ml <- lme4::lmer(gpa ~ semc + hrs + highgpa + sex + (semc|student),
                            data = data_long,
                            REML = FALSE)

fit_lmer_4_re <- lme4::lmer(gpa ~ semc + hrs + highgpa + sex + (semc|student),
                            data = data_long,
                            REML = TRUE)



fit_lmer_5_ml <- lme4::lmer(gpa ~ semc + hrs + highgpa + sex + semc:sex + (semc|student),
                            data = data_long,
                            REML = FALSE)

fit_lmer_5_re <- lme4::lmer(gpa ~ semc + hrs + highgpa + sex + semc:sex + (semc|student),
                            data = data_long,
                            REML = FALSE)
```


```{r}
texreg::screenreg(list(fit_lmer_4_ml, fit_lmer_5_ml, fit_lmer_5_re))
```


```{r}
anova(fit_lmer_4_ml, fit_lmer_5_ml)
```


```{r}
sjPlot::plot_model(fit_lmer_5_re,
                   type = "pred",
                   terms = c("semc", "sex"))
```






<!--chapter:end:13-longitudinal_gpa.Rmd-->

# Longitudinal MLM: RCT - Exercise and Diet

```{r, include=FALSE}
knitr::opts_chunk$set(comment     = "",
                      echo        = TRUE, 
                      warning     = FALSE, 
                      message     = FALSE,
                      fig.align   = "center", # center all figures
                      fig.width   = 6,        # set default figure width to 4 inches
                      fig.height  = 4)        # set default figure height to 3 inches
```

```{r, message=FALSE, error=FALSE}
library(tidyverse)    # all things tidy
library(pander)       # nice looking genderal tabulations
library(furniture)    # nice table1() descriptives
library(texreg)       # Convert Regression Output to LaTeX or HTML Tables
library(psych)        # contains some useful functions, like headTail
library(sjstats)      # ICC calculations
library(sjPlot)       # Visualization for Models
library(effects)      # Effec displays for Models

library(lme4)         # non-linear mixed-effects models
```

## The dataset

This comes from a **Randomized Controled Trial**.

```{r}
data_raw <- read.table("https://raw.githubusercontent.com/CEHS-research/data/master/MLM/exercise_diet.txt",
                  header = TRUE, 
                  sep = ",")
```

```{r}
tibble::glimpse(data_raw)
```



```{r}
data_long <- data_raw %>% 
  dplyr::mutate(id = id %>% factor) %>% 
  dplyr::mutate(exertype = exertype %>% 
                  factor(levels = 1:3,
                         labels = c("At Rest",
                                    "Leisurely Walking",
                                    "Moderate Running"))) %>% 
  dplyr::mutate(diet = diet %>% 
                  factor(levels = 1:2,
                         labels = c("low-fat",
                                    "non-fat"))) %>% 
  dplyr::mutate(time_min = time / 60)
```




```{r}
data_long %>% 
  psych::headTail(top = 10, bottom = 10) %>% 
  pander::pander(caption = "Raw Data")
```

## Exploratory Data Analysis

### Demographic Summary

```{r, results='asis'}
data_long %>% 
  dplyr::filter(time == 0) %>% 
  furniture::table1(diet, pulse,
                    splitby = ~ exertype,
                    caption = "Baseline Descriptives",
                    output = "html",
                    test = TRUE)
```

### Baseline Summary

```{r}
data_long %>% 
  dplyr::filter(time == 0) %>% 
  dplyr::group_by(exertype, diet) %>% 
  dplyr::summarise(mean = mean(pulse)) %>% 
  tidyr::spread(key = diet,
                value = mean) %>% 
  pander::pander(caption = "Baseline Pulse, Means")
  
```

### Raw Trajectories - Person Profile Plot

#### Connect the dots

```{r}
data_long %>% 
  ggplot(aes(x = time_min,
             y = pulse)) +
  geom_point() +
  geom_line(aes(group = id)) +
  facet_grid(diet ~ exertype) +
  theme_bw()
```

#### Loess - Moving Average Smoothers

```{r}
data_long %>% 
  ggplot(aes(x = time_min,
             y = pulse,
             color = diet)) +
  geom_line(aes(group = id)) +
  facet_grid(~ exertype) +
  theme_bw() +
  geom_smooth(method = "loess",
              se = FALSE,
              size = 2,
              span = 5) +
  theme(legend.position = c(0.08, 0.85),
        legend.background = element_rect(color = "black")) +
  labs(title = "Raw Pulse Trajectories",
       subtitle = "By Exercise and Diet Groupings",
       x = "Time (Minutes Post-Baseline)",
       y = "Pulse (Beats per Minute)",
       color = "Diet Plan")
```

## Multilevel Modeling

### Null Model

```{r}
fit_lmer_0re <- lme4::lmer(pulse ~ 1 + (1 | id),
                           data = data_long)
```


```{r, include=FALSE}
screenreg(fit_lmer_0re)
```


```{r, results='asis'}
texreg::htmlreg(fit_lmer_0re)
```

### ICC

```{r}
sjstats::icc(fit_lmer_0re)
```

### Add fixed effects: level specific

#### Fit nested models

```{r}
# Null Model (random intercept only)
fit_lmer_0ml <- lme4::lmer(pulse ~ 1 + (1 | id),
                           data = data_long,
                           REML = FALSE)

# Add quadratic time
fit_lmer_1ml <- lme4::lmer(pulse ~ time_min + I(time_min^2) + (1 | id),
                           data = data_long,
                           REML = FALSE)

# Add main effects for 2 interventions (person-specific, i.e. level-2 factors)
fit_lmer_2ml <- lme4::lmer(pulse ~ diet + exertype + time_min + I(time_min^2) + (1 | id),
                           data = data_long,
                           REML = FALSE)

# Add interaction between level-2 factors
fit_lmer_3ml <- lme4::lmer(pulse ~ diet*exertype + time_min + I(time_min^2) + (1 | id),
                           data = data_long,
                           REML = FALSE)

# Add exercise interacting with [time & time-squared]
fit_lmer_4ml <- lme4::lmer(pulse ~ diet*exertype + exertype*time_min + exertype*I(time_min^2) + (1 | id),
                           data = data_long,
                           REML = FALSE)

# Add diet interacting with [time & time-squared]
fit_lmer_5ml <- lme4::lmer(pulse ~ diet*exertype*time_min + diet*exertype*I(time_min^2) + (1 | id),
                           data = data_long,
                           REML = FALSE)
```


```{r, include=FALSE}
screenreg(list(fit_lmer_1ml, fit_lmer_2ml, fit_lmer_3ml, fit_lmer_4ml, fit_lmer_5ml))
```


```{r, results='asis'}
texreg::htmlreg(list(fit_lmer_1ml, 
                     fit_lmer_2ml, 
                     fit_lmer_3ml, 
                     fit_lmer_4ml, 
                     fit_lmer_5ml))
```

#### Evaluate Model Fit, i.e. variable significance

```{r}
anova(fit_lmer_1ml, 
      fit_lmer_2ml, 
      fit_lmer_3ml, 
      fit_lmer_4ml, 
      fit_lmer_5ml)
```


### Final Model

Refit via REML

```{r}
fit_lmer_5re <- lme4::lmer(pulse ~ diet*exertype*time_min + 
                                   diet*exertype*I(time_min^2) + (1 | id),
                           data = data_long,
                           REML = TRUE)
```


#### Visualize

```{r}
sjPlot::plot_model(fit_lmer_5re,
                   type = "pred",
                   terms = c("time_min", "diet", "exertype"))
```


```{r}
effects::Effect(focal.predictors = c("diet", "exertype", "time_min"),
                mod = fit_lmer_5re) %>% 
  data.frame %>% 
  ggplot(aes(x = time_min,
             y = fit,
             fill = diet,
             color = diet)) +
  geom_line(size = 1.5) +
  theme_bw() +
  facet_grid(~ exertype) +
  theme(legend.position = c(0.08, 0.85),
        legend.background = element_rect(color = "black")) +
  labs(title = "Raw Pulse Trajectories",
       subtitle = "By Exercise and Diet Groupings",
       x = "Time (Minutes Post-Baseline)",
       y = "Estimated Marginal Mean\nPulse (Beats per Minute)",
       fill = "Diet Plan",
       color = "Diet Plan")
```


```{r}
effects::Effect(focal.predictors = c("diet", "exertype", "time_min"),
                mod = fit_lmer_5re,
                xlevels = list("time_min" = seq(from = 0, 
                                                to   = 12, 
                                                by   = 0.5))) %>% 
  data.frame %>% 
  dplyr::mutate(diet = fct_rev(diet)) %>%  # reverse the order of the levels
  ggplot(aes(x = time_min,
             y = fit)) +
  geom_ribbon(aes(ymin = fit - se,
                  ymax = fit + se,
                  fill = diet),
              alpha = 0.3) +
  geom_line(aes(color = diet,
                linetype = diet),
                size = 1) +
  theme_bw() +
  facet_grid(~ exertype) +
  theme(legend.position = c(0.12, 0.85),
        legend.background = element_rect(color = "black"),
        legend.key.width = unit(2, "cm")) +
  labs(title = "Raw Pulse Trajectories",
       subtitle = "By Exercise and Diet Groupings",
       x = "Time (Minutes Post-Baseline)",
       y = "Estimated Marginal Mean\nPulse (Beats per Minute)",
       fill = "Diet Plan",
       color = "Diet Plan",
       linetype = "Diet Plan") +
  scale_color_manual(values = c("gray50", "black")) +
  scale_fill_manual(values = c("gray50", "black")) +
  scale_x_continuous(breaks = seq(from = 0, to = 14, by = 5))
```






<!--chapter:end:15-exercise_diet.Rmd-->

# GEE, Continuous Outcome: Beat the Blues

```{r, include=FALSE}
knitr::opts_chunk$set(comment     = "",
                      echo        = TRUE, 
                      warning     = FALSE, 
                      message     = FALSE,
                      fig.align   = "center", # center all figures
                      fig.width   = 6,        # set default figure width to 4 inches
                      fig.height  = 4)        # set default figure height to 3 inches
```

```{r, message=FALSE, error=FALSE}
library(tidyverse)    # all things tidy
library(pander)       # nice looking genderal tabulations
library(furniture)    # nice table1() descriptives
library(texreg)       # Convert Regression Output to LaTeX or HTML Tables
library(psych)        # contains some useful functions, like headTail

library(lme4)         # Linear, generalized linear, & nonlinear mixed models

library(corrplot)     # Vizualize correlation matrix
library(gee)          # Genderalized Estimation Equation Solver
library(geepack)      # Genderalized Estimation Equation Package 
library(MuMIn)        # Multi-Model Inference (caluclate QIC)

library(HSAUR)        # package with the dataset
```

## Prepare and get to know the dataset

### Read in the data

This data set is in the **HSAUR** package.  It is from a clinical trial of an interactive multimedia program called 'Beat the Blues'. The variables are as follows:   

  * `drug` did the patient take anti-depressant drugs (No or Yes)    
  * `length`  the length of the current episode of depression, a factor with levels:    
    + "<6m" *less than six months*     
    + ">6m" *more than six months*   
  * `treatment` treatment group, a factor with levels:   
    + "TAU" *treatment as usual*     
    + "BtheB" *Beat the Blues*    
  * `bdi.pre` Beck Depression Inventory II, before treatment    
  * `bdi.2m` Beck Depression Inventory II, after 2 months    
  * `bdi.4m` Beck Depression Inventory II, after 4 months    
  * `bdi.6m` Beck Depression Inventory II, after 6 months    
  * `bdi.8m` Beck Depression Inventory II, after 8 months    


```{r}
data(BtheB, package = "HSAUR")

BtheB %>% 
  psych::headTail()
```


### Tidy up the dataset

```{r}
btb_wide <- BtheB %>% 
  dplyr::mutate(id = row_number()) %>%           # create a new variable to ID participants
  dplyr::select(id, treatment,                    # specify that ID variable is first
                drug, length,
                bdi.pre, bdi.2m, bdi.4m, bdi.6m, bdi.8m)
```


```{r, results='asis'}
btb_wide %>% 
  furniture::table1(bdi.pre, bdi.2m, bdi.4m, bdi.6m, bdi.8m,
                    splitby = ~ treatment,
                    test = TRUE,
                    output = "html")
```

### Restructure to long format

```{r}
btb_long <- btb_wide %>% 
  tidyr::gather(key   = month,
                value = bdi,
                bdi.2m, bdi.4m, bdi.6m, bdi.8m) %>% 
  dplyr::mutate(month = case_when(month == "bdi.2m"  ~ 2,
                                  month == "bdi.4m"  ~ 4,
                                  month == "bdi.6m"  ~ 6,
                                  month == "bdi.8m"  ~ 8)) %>% 
  dplyr::filter(complete.cases(id, bdi, treatment, month)) %>% 
  dplyr::arrange(id, month) %>% 
  dplyr::select(id, treatment, drug, length, bdi.pre, month, bdi)
```


```{r}
btb_long %>% 
  psych::headTail(top = 10, bottom = 10) 
```


### Visualize: Person-profile Plots

Create spaghetti plots of the raw, observed data

```{r}
btb_long %>% 
  ggplot(aes(x = month,
             y = bdi)) +
  geom_point() +
  geom_line(aes(group = id), 
            size = 1, 
            alpha = 0.3) +
  geom_smooth(method = "lm") +
  theme_bw() +
  facet_grid(.~ treatment) +
  labs(title = "BtheB - Observed Data Across Time with LM Smoother",
       subtitle = "Seperate by Treatment")
```


```{r}
btb_long %>% 
  ggplot(aes(x = month,
             y = bdi)) +
  geom_point() +
  geom_line(aes(group = id), 
            size = 1, 
            alpha = 0.3) +
  geom_smooth(method = "lm") +
  facet_grid(drug~ treatment, labeller = label_both) +
  theme_bw() +
  labs(title = "BtheB - Observed Data Across Time with LM Smoother",
       subtitle = "Seperate by Treatment & Antidepressant Use")
```

```{r}
btb_long %>% 
  ggplot(aes(x = month,
             y = bdi)) +
  geom_point() +
  geom_line(aes(group = id,
                color = length), 
            size = 1, 
            alpha = 0.3) +
  geom_smooth(aes(color = length),
              method = "lm",
              size = 1.25,
              se = FALSE) +
  facet_grid(drug~ treatment, labeller = label_both) +
  theme_bw() +
  labs(title = "BtheB - Observed Data Across Time with LM Smoother",
       subtitle = "Seperate by Treatment, Antidepressant Use, & Length of Current Episode")
```



```{r}
btb_long %>% 
  ggplot(aes(x = month,
             y = bdi,
             color = treatment,
             fill = treatment)) +
  geom_smooth(method = "lm") +
  theme_bw() +
  labs(title = "BtheB - Predictions from TWO Seperate Single Simple Linear Models (lm)",
       subtitle = "Assumes Independence of Repeated Measures")
```

### Calculate the Observed Correlation Structure


```{r}
bdi_corr <- btb_wide %>% 
  dplyr::select(starts_with("bdi")) %>% 
  stats::cor(use="pairwise.complete.obs")

bdi_corr
```


### Plot the correlation matrix to get a better feel for the pattern

```{r}
corrplot::corrplot.mixed(bdi_corr)
```




## Multiple Regression (OLS)

This ignores any correlation between repeated measures on the same individual and treats all observations as independent.

### Fit the models

```{r}
btb_lm_1 <- stats::lm(bdi ~ bdi.pre + length + drug + treatment + month,
                    data = btb_long)

btb_lm_2 <- stats::lm(bdi ~ bdi.pre + length + drug + treatment*month,
                    data = btb_long)

btb_lm_3 <- stats::lm(bdi ~ bdi.pre + length + drug + treatment + drug*month,
                    data = btb_long)

btb_lm_4 <- stats::lm(bdi ~ bdi.pre + length + drug*treatment*month,
                    data = btb_long)
```


### Parameter Estimates Table


```{r, include=FALSE}
texreg::screenreg(list(btb_lm_1, btb_lm_2, btb_lm_3, btb_lm_4))
```

```{r, results='asis'}
# Knit to Website: texreg::htmlreg()
# Knit to PDF:     texreg::texreg()
# View on Screen:  texreg::screenreg()

texreg::htmlreg(list(btb_lm_1, btb_lm_2, btb_lm_3, btb_lm_4),
                caption = "OLS")
```

### Plot the model predictions

```{r}
effects::Effect(focal.predictors = c("treatment", "month"), 
                mod = btb_lm_1) %>% 
  data.frame %>% 
  dplyr::mutate(treatment = fct_reorder2(treatment, month, fit)) %>%  
  ggplot(aes(x = month,
             y = fit)) +
  geom_line(aes(color = treatment)) +
  geom_ribbon(aes(ymin = lower,
                  ymax = upper,
                  fill = treatment), 
              alpha = 0.3) +
  geom_ribbon(aes(ymin = fit - se,
                  ymax = fit + se,
                  fill = treatment), 
              alpha = 0.3) +
  theme_bw() +
  labs(title = "BtheB - Predictions from a Single Linear Model (lm)",
       subtitle = "Assumes Independence of Repeated Measures") +
  theme(legend.position = c(1, 1),
        legend.justification = c(1.1, 1.1),
        legend.background = element_rect(color = "black"))
```


## Multilevel Models (MLM)

### Fit the models


```{r}
btb_lmer_RI   <- lme4::lmer(bdi ~ bdi.pre + length + drug + treatment + month + (1 | id), 
                            data = btb_long, 
                            REML = TRUE)

btb_lmer_RIAS <- lme4::lmer(bdi ~ bdi.pre + length + drug + treatment + month + (month | id), 
                            data = btb_long, 
                            REML = TRUE)
```


### Parameter Estimates Table

```{r, include=FALSE}
texreg::screenreg(list(btb_lm_1, btb_lmer_RI, btb_lmer_RIAS), 
          custom.model.names = c("OLS", "MLM-RI", "MLM-RIAS"))
```

```{r, results='asis'}
# Knit to Website: texreg::htmlreg()
# Knit to PDF:     texreg::texreg()
# View on Screen:  texreg::screenreg()

texreg::htmlreg(list(btb_lm, btb_lmer_RI, btb_lmer_RIAS), 
                custom.model.names = c("OLS", "MLM-RI", "MLM-RIAS"))
```


### Likelihood Ratio Test


```{r}
anova(btb_lmer_RI, 
      btb_lmer_RIAS, 
      refit = FALSE)
```


### Plot the model predictions

```{r}
effects::Effect(c("treatment", "month", "drug"), 
                mod = btb_lmer_RI) %>% 
  data.frame %>%   
  dplyr::mutate(treatment = fct_reorder2(treatment, month, fit)) %>%
  ggplot(aes(x = month,
             y = fit)) +
  geom_line(aes(color = treatment)) +
  geom_ribbon(aes(ymin = lower,
                  ymax = upper,
                  fill = treatment), 
              alpha = 0.3) +
  theme_bw() +
  facet_grid(.~ drug, labeller = label_both) +
  labs(title = "BtheB - Predictions from a Multilevel Model (lmer)") +
  theme(legend.position = c(0, 0),
        legend.justification = c(-0.1, -0.1),
        legend.background = element_rect(color = "black"))
```




## General Estimating Equations, GEE


### Fit the models

Use the `gee()` function from the **gee** package for the results to be used in a `texreg()` table.

```{r}
btb_gee_in <- gee::gee(bdi ~ bdi.pre + length + drug + treatment + month, 
                       data = btb_long, 
                       id = id, 
                       family = gaussian, 
                       corstr = 'independence')

btb_gee_ex <- gee::gee(bdi ~ bdi.pre + length + drug + treatment + month, 
                       data = btb_long, 
                       id = id, 
                       family = gaussian, 
                       corstr = 'exchangeable')

# The AR-1 fails if any subjects have only 1 observation
# to use this one, we would need to remove participants with only 1 BDI
# btb_gee_ar <- gee(bdi ~ bdi.pre + length + drug + treatment + month,
#                  data = btb_long,
#                  id = id,
#                  family = gaussian,
#                  corstr = 'AR-M',
#                  Mv = 1)

btb_gee_un <- gee::gee(bdi ~ bdi.pre + length + drug + treatment + month, 
                       data = btb_long, 
                       id = id, 
                       family = gaussian, 
                       corstr = 'unstructured')
```

```{r}
summary(btb_gee_in)
```

```{r}
summary(btb_gee_ex)
```


```{r}
summary(btb_gee_un)
```

### Parameter Estimates Table

```{r, include=FALSE}
texreg::screenreg(list(btb_lm_1, 
                      btb_lmer_RI, 
                      btb_gee_in, 
                      btb_gee_ex, 
                      btb_gee_un))
```


```{r, results='asis'}
# Knit to Website: texreg::htmlreg()
# Knit to PDF:     texreg::texreg()
# View on Screen:  texreg::screenreg()

texreg::htmlreg(list(btb_lm, 
                      btb_lmer_RI, 
                      btb_gee_in, 
                      btb_gee_ex, 
                      btb_gee_un),
                  custom.model.names = c("OLS", 
                                        "MLM-RI", 
                                        "GEE-in", 
                                        "GEE-ex", 
                                        "GEE-un"))
```





### Re-Fit Models

Use the `geeglm()` function from the **geepack** package for the results to be used in a `anova()` table.


```{r}
btb_geeglm_in <- geeglm(bdi ~ bdi.pre + length + drug + treatment + month, 
                        data = btb_long, 
                        id = id,
                        wave = month,
                        family = gaussian, 
                        corstr = 'independence')

btb_geeglm_ex <- geeglm(bdi ~ bdi.pre + length + drug + treatment + month, 
                        data = btb_long, 
                        id = id, 
                        wave = month,
                        family = gaussian, 
                        corstr = 'exchangeable')


btb_geeglm_ar <- geeglm(bdi ~ bdi.pre + length + drug + treatment + month, 
                        data = btb_long, 
                        id = id, 
                        wave = month,
                        family = gaussian, 
                        corstr = 'ar1')

btb_geeglm_un <- geeglm(bdi ~ bdi.pre + length + drug + treatment + month, 
                        data = btb_long, 
                        id = id,
                        wave = month,
                        family = gaussian, 
                        corstr = 'unstructured')
```


### Can't Use the Likelihood Ratio Test

The `anova()` function is used to compare nested models for parameters (fixed effects), not correlation structures.

```{r}
anova(btb_geeglm_in, btb_geeglm_ex)
anova(btb_geeglm_in, btb_geeglm_ar)
anova(btb_geeglm_in, btb_geeglm_un)
```



### Variaous QIC Measures of Fit

References:

* Pan, W. 2001. Akaike's information criterion in generalized estimating equations. Biometrics 57:120-125. https://onlinelibrary.wiley.com/doi/abs/10.1111/j.0006-341X.2001.00120.x 

* Burnham, K. P. and D. R. Anderson. 2002. Model selection and multimodel inference: a practical information-theoretic approach. Second edition. Springer Science and Business Media, Inc., New York.
https://cds.cern.ch/record/1608735/files/9780387953649_TOC.pdf 



The `QIC()` is one way to **try** to measure model fit.  You can enter more than one model into a single function call.

QIC(I) based on independence model  <-- suggested by Pan (Biometric, March 2001), asymptotically unbiased estimator (choose the correlation stucture that produces the smallest QIC(I), p122)

```{r}
MuMIn::QIC(btb_geeglm_in, 
           btb_geeglm_ex, 
           btb_geeglm_ar, 
           btb_geeglm_un, 
           typeR = FALSE) # default
```


QIC(R) is based on quasi-likelihood of a working correlation R model, can **NOT** be used to select the working correlation matrix.

```{r}
MuMIn::QIC(btb_geeglm_in, 
           btb_geeglm_ex, 
           btb_geeglm_ar, 
           btb_geeglm_un, 
           typeR = TRUE)    # NOT the default
```


QIC_U(R) approximates QIC(R), and while both are useful for variable selection, they can NOT be applied to select the working correlation matrix.

```{r}
MuMIn::QICu(btb_geeglm_in, 
            btb_geeglm_ex, 
            btb_geeglm_ar, 
            btb_geeglm_un) 
```





```{r}
MuMIn::model.sel(btb_geeglm_in, 
                 btb_geeglm_ex, 
                 btb_geeglm_ar, 
                 btb_geeglm_un, 
                 rank = "QIC")    #sorts the best to the TOP, uses QIC(I)
```






### Plot the model predictions

```{r}
summary(btb_long)
```



Do not worry about confidence intervals.

```{r}
expand.grid(bdi.pre = 23,
            length = "<6m",
            drug = "No",
            treatment = levels(btb_long$treatment),
            month = seq(from = 2, to = 8, by = 2)) %>%  
  mutate(fit_in = predict(btb_geeglm_in,
                       newdata = .,
                       type = "response")) %>% 
  mutate(fit_ex = predict(btb_geeglm_ex,
                       newdata = .,
                       type = "response")) %>% 
  mutate(fit_ar = predict(btb_geeglm_ar,
                       newdata = .,
                       type = "response")) %>% 
  mutate(fit_un = predict(btb_geeglm_un,
                       newdata = .,
                       type = "response")) %>% 
  gather(key = variable,
         value = fit,
         starts_with("fit")) %>% 
  separate(col = variable,
           into = c("junk", "covR")) %>% 
  select(-junk) %>% 
  mutate(covR = factor(covR, 
                       levels = c("un", "ar", "ex", "in"),
                       labels = c("Unstructured",
                                  "Auto-Regressive",
                                  "Compound Symetry",
                                  "Independence"))) %>% 
  ggplot(aes(x = month,
             y = fit,
             linetype = treatment)) +
  geom_line(alpha = 0.6) +
  theme_bw() +
  labs(title    = "BtheB - Predictions from four GEE models (geeglm)",
       linetype = "Treatment") +
  scale_linetype_manual(values = c("solid", "longdash")) +
  scale_size_manual(values     = c(2, 1, 1, 1)) +
  scale_color_manual(values    = c("red", 
                                   "dodgerblue",
                                   "blue",
                                   "darkgreen")) +
  theme(legend.key.width = unit(1, "cm")) +
  facet_wrap(~ covR)
```









<!--chapter:end:30_example_gee_BtheB.Rmd-->

# GEE, Binary Outcome: Respiratory Illness

```{r, include=FALSE}
knitr::opts_chunk$set(comment     = "",
                      echo        = TRUE, 
                      warning     = FALSE, 
                      message     = FALSE,
                      fig.align   = "center", # center all figures
                      fig.width   = 6,        # set default figure width to 4 inches
                      fig.height  = 4)        # set default figure height to 3 inches
```

```{r, message=FALSE, error=FALSE}
library(tidyverse)    # all things tidy
library(pander)       # nice looking genderal tabulations
library(furniture)    # nice table1() descriptives
library(texreg)       # Convert Regression Output to LaTeX or HTML Tables
library(psych)        # contains some useful functions, like headTail

library(lme4)         # Linear, generalized linear, & nonlinear mixed models

library(corrplot)     # Vizualize correlation matrix
library(gee)          # Genderalized Estimation Equation Solver
library(geepack)      # Genderalized Estimation Equation Package 
library(MuMIn)        # Multi-Model Inference (caluclate QIC)

library(HSAUR)        # package with the dataset
```

## Prepare and get to know the dataset

### Read in the data

This data set is in the **HSAUR** package. 

```{r}
data("respiratory", package = "HSAUR")

str(respiratory)

psych::headTail(respiratory)
```

### Wide Format

```{r}
data_wide <- respiratory %>% 
  tidyr::spread(key = month,
                value = status,
                sep = "_") %>% 
  dplyr::rename("BL_status" = "month_0") %>% 
  dplyr::arrange(subject) %>% 
  dplyr::select(subject, centre, sex, age, treatment, BL_status, starts_with("month"))  

str(data_wide)

psych::headTail(data_wide)
```

### Long Format

```{r}
data_long <- data_wide%>% 
  tidyr::gather(key = month,
                value = status,
                starts_with("month")) %>% 
  dplyr::mutate(month = str_sub(month, start = -1) %>% as.numeric) %>% 
  dplyr::mutate(status = case_when(status == "poor" ~ 0,
                                   status == "good" ~ 1)) %>% 
  dplyr::arrange(subject, month) %>% 
  dplyr::select(subject, centre, sex, age, treatment, BL_status, month, status) 


str(data_long)

psych::headTail(data_long)
```


## Exploratory Data Analysis

### Summary Statustics

#### Demographics and Baseline Measure


```{r}
data_wide %>% 
  furniture::table1(centre, sex, age, BL_status, 
                    splitby = ~ treatment,
                    output = "html")
```

#### Status  Over Time

```{r}
data_wide %>% 
  furniture::table1(month_1, month_2, month_3, month_4, 
                    splitby = ~ treatment,
                    output = "html")
```


```{r}
data_month_trt_prop <- data_long %>% 
  dplyr::group_by(treatment, month) %>% 
  dplyr::summarise(n = n(),
                   prop_good = mean(status),
                   prop_sd = sd(status),
                   prop_se = prop_sd/n)

psych::headTail(data_month_trt_prop)
```


### Visualization

#### Status Over Time


```{r}
data_month_trt_prop %>% 
  ggplot(aes(x = month,
             y = prop_good,
             group = treatment,
             color = treatment)) +
  geom_errorbar(aes(ymin = prop_good - prop_se,
                    ymax = prop_good + prop_se),
                width = .25) +
  geom_point() +
  geom_line() +
  theme_bw()
```

## Logisitc Regression


```{r}
resp_glm <- glm(status ~ centre + treatment + sex + BL_status + I(age-33) + I((age-33)^2),
                data = data_long,
                family = binomial(link = "logit"))

summary(resp_glm)
```


```{r}
sjPlot::tab_model(resp_glm)
```


## GEE

### Indepdendence

```{r}
resp_gee_in <- gee::gee(status ~ centre + treatment + sex + BL_status + I(age-33) + I((age-33)^2),
                        data = data_long,
                        family = binomial(link = "logit"),
                        id = subject,
                        corstr = "independence",
                        scale.fix = TRUE,
                        scale.value = 1)

summary(resp_gee_in)
```

The results for GEE fit with the independence correlation structure produces results that are nearly identical to the GLM model.

The robust (sandwhich) standard errors are however much larger than the naive stadard errors


### Exchangeable

```{r}
resp_gee_ex <- gee::gee(status ~ centre + treatment + sex + BL_status + I(age-33) + I((age-33)^2),
                        data = data_long,
                        family = binomial(link = "logit"),
                        id = subject,
                        corstr = "exchangeable",
                        scale.fix = TRUE,
                        scale.value = 1)

summary(resp_gee_ex)
```

Notice that the naive stadard errors are more similar to the robust (sandwhich) standard errors, supporting that this is a better fitting model

### Paramgeter Estimates Table

The GEE models display the robus (sandwhich) standard errors.


```{r}
texreg::screenreg(list(resp_glm, resp_gee_in, resp_gee_ex),
                  custom.model.names = c("GLM", "GEE-INDEP", "GEE-EXCH"),
                  caption = "Estimates = log odds ratios",
                  digits = 4)
```

Comparing the two GEE models: parameters are identical and so are the robust (sandwhich) standard errors.



```{r}
summary(resp_gee_ex) %>% names
```

```{r}
summary(resp_gee_ex)$coeff
```


```{r}
resp_gee_ex %>% coef() %>% exp()
```







### refit


```{r}
resp_geeglm_ex <- geepack::geeglm(status ~ centre + treatment + sex + BL_status + I(age-33) + I((age-33)^2),
                        data = data_long,
                        family = binomial(link = "logit"),
                        id = subject,
                        waves = month,
                        corstr = "exchangeable")
```


```{r}
summary(resp_geeglm_ex)
```

```{r}
resp_geeglm_ex %>% coef() %>% exp()
```



```{r}
summary(data_long)
```

```{r}
expand.grid(centre = "1",
            treatment = levels(data_long$treatment),
            sex = "female",
            age = seq(from = 11, to = 68, by = 1),
            BL_status = levels(data_long$BL_status)) %>% 
  dplyr::mutate(fit = predict(resp_geeglm_ex,
                              newdata = .,
                              type = "response")) %>% 
  ggplot(aes(x = age,
             y = fit,
             linetype = treatment)) +
  geom_line() +
  theme_bw() + 
  facet_grid(.~ BL_status) +
  labs(x = "Age, years",
       y = "Predicted Probability of GOOD Respiratory Status",
       title = "For Females at Center 1")
```

<!--chapter:end:31_example_gee_Respiratory.Rmd-->

`r if (knitr:::is_html_output()) '
# References {-}
'`

```{r include=FALSE}
# automatically create a bib database for R packages
knitr::write_bib(c(.packages(), 
                   'bookdown',
                   'knitr', 
                   'rmarkdown'), 
                 'packages.bib')
```

<!--chapter:end:99-refs.Rmd-->

