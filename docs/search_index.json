[
["index.html", "Encyclopedia of Quantitative Methods in R, vol. 5: Multilevel Models Welcome Blocked Notes Code and Output The Authors", " Encyclopedia of Quantitative Methods in R, vol. 5: Multilevel Models Sarah Schwartz &amp; Tyson Barrett Last updated: 2018-09-11 Welcome Backgroup and links to other volumes of this encyclopedia may be found at the Encyclopedia’s Home Website. Blocked Notes Thoughout all the eBooks in this encyclopedia, several small secitons will be blocked out in the following ways: These blocks denote an area UNDER CONSTRUCTION, so check back often. This massive undertaking started during the summer of 2018 and is far from complete. The outline of seven volumes is given above despite any one being complete. Feedback is welcome via either author’s email. These blocks denote something EXTREMELY IMPORTANT. Do NOT skip these notes as they will be used very sparingly. These blocks denote something to DOWNLOAD. This may include software installations, example datasets, or notebook code files. These blocks denote something INTERESTING. These point out information we found of interest or added value. These blocks denote LINKS to other websites. This may include instructional video clips, articles, or blog posts. We are all about NOT re-creating the wheel. If somebody else has described or illustrated a topic well, we celebrate it! Code and Output This is how \\(R\\) code is shown: 1 + 1 This is what the output of the \\(R\\) code above will look: ## [1] 2 The Authors Dr. Sarah Schwartz Dr. Tyson Barrett www.SarahSchwartzStats.com www.TysonBarrett.com Sarah.Schwartz@usu.edu Tyson.Barrett@usu.edu Statistical Consulting Studio Data Science and Discover Unit Why choose R ? Check it out: an article from Fall 2016… No more excuses: R is better than SPSS for psychology undergrads, and students agree FYI This entire encyclopedia is written in \\(R Markdown\\), using \\(R Studio\\) as the text editor and the bookdown package to turn a collection of markdown documents into a coherent whole. The book’s source code is hosted on GitHub. If you notice typos or other issues, feel free to email either of the authors. This work is licensed under the Attribution-NonCommercial-NoDerivatives 4.0 International License. "],
["hox-chap-2-classroom-popularity.html", "1 Hox, chap 2. - Classroom Popularity 1.1 Background 1.2 Exploratory Data Analysis 1.3 Multilevel Regression Analysis", " 1 Hox, chap 2. - Classroom Popularity library(tidyverse) library(haven) # read in SPSS dataset library(furniture) # nice table1() descriptives library(stargazer) # display nice tables: summary &amp; regression library(texreg) # Convert Regression Output to LaTeX or HTML Tables library(RColorBrewer) # nice color palettes for plots library(gridExtra) # place ggplots together as one plot library(psych) # contains some useful functions, like headTail library(car) # Companion to Applied Regression library(nlme) # non-linear mixed-effects models library(lme4) # Linear, generalized linear, &amp; nonlinear mixed models library(lmerTest) # Tests on lmer objects library(HLMdiag) # Diagnostic Tools for for nlme &amp; lmer4 library(sjstats) # ICC calculations 1.1 Background The text “Multilevel Analysis: Techniques and Applications, Third Edition” (Hox, Moerbeek, and Van de Schoot 2017) has a companion website which includes links to all the data files used throughout the book (housed on the book’s GitHub repository). From Appendix E: The popularity data in popular2.sav are simulated data for 2000 pupils in 100 schools. The purpose is to offer a very simple example for multilevel regression analysis. The main outcome variable is the pupil popularity, a popularity rating on a scale of 1-10 derived by a sociometric procedure. Typically, a sociometric procedure asks all pupils in a class to rate all the other pupils, and then assigns the average received popularity rating to each pupil. Because of the sociometric procedure, group effects as apparent from higher level variance components are rather strong. There is a second outcome variable: pupil popularity as rated by their teacher, on a scale from 1-10. The explanatory variables are pupil gender (boy=0, girl=1), pupil extraversion (10-point scale) and teacher experience in years. The popularity data have been generated to be a ‘nice’ well-behaved data set: the sample sizes at both levels are sufficient, the residuals have a normal distribution, and the multilevel effects are strong.* raw &lt;- haven::read_sav(&quot;https://github.com/MultiLevelAnalysis/Datasets-third-edition-Multilevel-book/raw/master/chapter%202/popularity/SPSS/popular2.sav&quot;) %&gt;% haven::as_factor() # retain the labels from SPSS --&gt; factor tibble::glimpse(raw) Observations: 2,000 Variables: 15 $ pupil &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 1... $ class &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1... $ extrav &lt;dbl&gt; 5, 7, 4, 3, 5, 4, 5, 4, 5, 5, 5, 5, 5, 5, 5, 6, 4, 4... $ sex &lt;fct&gt; girl, boy, girl, girl, girl, boy, boy, boy, boy, boy... $ texp &lt;dbl&gt; 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, ... $ popular &lt;dbl&gt; 6.3, 4.9, 5.3, 4.7, 6.0, 4.7, 5.9, 4.2, 5.2, 3.9, 5.... $ popteach &lt;dbl&gt; 6, 5, 6, 5, 6, 5, 5, 5, 5, 3, 5, 5, 5, 6, 5, 5, 2, 3... $ Zextrav &lt;dbl&gt; -0.1703149, 1.4140098, -0.9624772, -1.7546396, -0.17... $ Zsex &lt;dbl&gt; 0.9888125, -1.0108084, 0.9888125, 0.9888125, 0.98881... $ Ztexp &lt;dbl&gt; 1.48615283, 1.48615283, 1.48615283, 1.48615283, 1.48... $ Zpopular &lt;dbl&gt; 0.88501327, -0.12762911, 0.16169729, -0.27229230, 0.... $ Zpopteach &lt;dbl&gt; 0.66905609, -0.04308451, 0.66905609, -0.04308451, 0.... $ Cextrav &lt;dbl&gt; -0.215, 1.785, -1.215, -2.215, -0.215, -1.215, -0.21... $ Ctexp &lt;dbl&gt; 9.737, 9.737, 9.737, 9.737, 9.737, 9.737, 9.737, 9.7... $ Csex &lt;dbl&gt; 0.5, -0.5, 0.5, 0.5, 0.5, -0.5, -0.5, -0.5, -0.5, -0... 1.1.1 Unique Identifiers We will restrict ourselves to a few of the variables and create a distinct identifier variable for each student. pop &lt;- raw %&gt;% dplyr::mutate(id = paste(class, pupil, sep = &quot;_&quot;) %&gt;% # create a unique id for each student (char) factor()) %&gt;% # declare id is a factor dplyr::select(id, pupil:popteach) # reduce the variables included tibble::glimpse(pop) Observations: 2,000 Variables: 8 $ id &lt;fct&gt; 1_1, 1_2, 1_3, 1_4, 1_5, 1_6, 1_7, 1_8, 1_9, 1_10, 1_... $ pupil &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16... $ class &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,... $ extrav &lt;dbl&gt; 5, 7, 4, 3, 5, 4, 5, 4, 5, 5, 5, 5, 5, 5, 5, 6, 4, 4,... $ sex &lt;fct&gt; girl, boy, girl, girl, girl, boy, boy, boy, boy, boy,... $ texp &lt;dbl&gt; 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 2... $ popular &lt;dbl&gt; 6.3, 4.9, 5.3, 4.7, 6.0, 4.7, 5.9, 4.2, 5.2, 3.9, 5.7... $ popteach &lt;dbl&gt; 6, 5, 6, 5, 6, 5, 5, 5, 5, 3, 5, 5, 5, 6, 5, 5, 2, 3,... 1.1.2 Scope out the structure and variables Its a good idea to visually inspect the first few lines in the datast to get a sense of how it is organized. pop %&gt;% psych::headTail(top = 25, bottom = 5) %&gt;% pander::pander() id pupil class extrav sex texp popular popteach 1_1 1 1 5 girl 24 6.3 6 1_2 2 1 7 boy 24 4.9 5 1_3 3 1 4 girl 24 5.3 6 1_4 4 1 3 girl 24 4.7 5 1_5 5 1 5 girl 24 6 6 1_6 6 1 4 boy 24 4.7 5 1_7 7 1 5 boy 24 5.9 5 1_8 8 1 4 boy 24 4.2 5 1_9 9 1 5 boy 24 5.2 5 1_10 10 1 5 boy 24 3.9 3 1_11 11 1 5 girl 24 5.7 5 1_12 12 1 5 girl 24 4.8 5 1_13 13 1 5 boy 24 5 5 1_14 14 1 5 girl 24 5.5 6 1_15 15 1 5 girl 24 6 5 1_16 16 1 6 girl 24 5.7 5 1_17 17 1 4 boy 24 3.2 2 1_18 18 1 4 boy 24 3.1 3 1_19 19 1 7 girl 24 6.6 7 1_20 20 1 4 boy 24 4.8 4 2_1 1 2 8 girl 14 6.4 6 2_2 2 2 4 boy 14 2.4 3 2_3 3 2 6 boy 14 3.7 4 2_4 4 2 5 girl 14 4.4 4 2_5 5 2 5 girl 14 4.3 4 NA … … … NA … … … 100_16 16 100 4 girl 7 4.3 5 100_17 17 100 4 boy 7 2.6 2 100_18 18 100 8 girl 7 6.7 7 100_19 19 100 5 boy 7 2.9 3 100_20 20 100 9 boy 7 5.3 5 Visual inspection reveals that most of the variables are measurements at level 1 and apply to specific pupils (extrav, sex, popular, and popteach), while the teacher’s years of experiene is a level 2 variable since it applies to the entire class. Notice how the texp variable is identical for all pupils in the same class. This is call Disaggregated data. 1.2 Exploratory Data Analysis 1.2.1 Summarize Descriptive Statistics Most posters, journal articles, and reports start with a table of descriptive statistics. Since it tends to come first, this type of table is often refered to as Table 1. The stargazer() function can be used to create such a table, but only for the entire dataset (Hlavac 2018). I haven’t been able to find a way to get it to summarize subsamples and compare them in the standard format. pop %&gt;% dplyr::select(-id) %&gt;% data.frame() %&gt;% stargazer::stargazer(title = &quot;Descriptive statistics, aggregate over entire sample&quot;, header = FALSE, type = &quot;html&quot;) Descriptive statistics, aggregate over entire sample Statistic N Mean St. Dev. Min Pctl(25) Pctl(75) Max pupil 2,000 10.649 5.968 1 6 16 26 class 2,000 50.370 29.078 1 25 76 100 extrav 2,000 5.215 1.262 1 4 6 10 texp 2,000 14.263 6.552 2 8 20 25 popular 2,000 5.076 1.383 0.000 4.100 6.000 9.500 popteach 2,000 5.061 1.404 1 4 6 10 1.2.2 Summarize Descriptive Statistics - furniture Tyson Barrett’s furniture package includes the extremely useful function table1() which simplifies the common task of creating a stratified, comparative table of descriptive statistics. Full documentation can be accessed by executing ?furniture::table1. pop %&gt;% table1(&quot;Pupil&#39;s Extraversion (10 pt)&quot; = extrav, &quot;Teacher&#39;s Experience (years)&quot; = texp, &quot;Popularity, Sociometric Score&quot; = popular, &quot;Popularity, Teacher Evaluated&quot; = popteach, splitby = ~ sex, # var to divide sample by test = TRUE, # test groups different? output = &quot;html&quot;, # output for latex align = c(&quot;l&quot;, &quot;r&quot;, &quot;r&quot;, &quot;r&quot;), # column alignment caption = &quot;Compare genders on four main variables&quot;) # title Table 1.1: Compare genders on four main variables boy girl P-Value n = 989 n = 1011 Pupil.s.Extraversion..10.pt. &lt;.001 5.1 (1.2) 5.3 (1.3) Teacher.s.Experience..years. 0.001 13.8 (6.3) 14.7 (6.8) Popularity..Sociometric.Score &lt;.001 4.3 (1.1) 5.9 (1.1) Popularity..Teacher.Evaluated &lt;.001 4.3 (1.2) 5.8 (1.2) 1.2.3 Visualizations of Raw Data For a first look, its useful to plot all the data points on a single scatterplot as displayed in Figure 1.1. Due to ganularity in the rating scale, many points end up being plotted on top of each other (overplotted), so its a good idea to use geom_count() rather than geom_point() so the size of the dot can convey the number of points at that location (Wickham et al. 2018). # Disaggregate: pupil (level 1) only, ignore level 2&#39;s existance # Extraversion treated: continuous measure pop %&gt;% ggplot() + aes(x = extrav, # x-axis variable y = popular) + # y-axis variable geom_count() + # POINTS w/ SIZE = COUNT geom_smooth(method = &quot;lm&quot;) + # linear regression line theme_bw() + # white background labs(x = &quot;Extraversion (10 pt scale)&quot;, # x-axis label y = &quot;Popularity, Sociometric Score&quot;, # y-axis label size = &quot;Count&quot;) + # legend key&#39;s title theme(legend.position = c(0.9, 0.2), # key at legend.background = element_rect(color = &quot;black&quot;)) + # key box scale_x_continuous(breaks = seq(from = 0, to = 10, by = 1)) + # x-ticks scale_y_continuous(breaks = seq(from = 0, to = 10, by = 2)) # y-ticks Figure 1.1: Disaggregate: pupil level only with extraversion treated as an continuous measure. When the degree of overplotting as high as it is in Figure 1.1, it can be useful to represent the data with density contours as seen in Figure 1.2. I’ve chosen to leave the points displayed in this redition, but color them much lighter so that they are present, but do not detract from the pattern of association. # visualize all the data - another way pop %&gt;% ggplot() + aes(x = extrav, # x-axis variable y = popular) + # y-axis variable geom_count(color = &quot;gray&quot;) + # POINTS w/ SIZE = COUNT geom_density2d() + # DENSITY CURVES geom_smooth(method = &quot;lm&quot;, color = &quot;red&quot;) + # linear regression line theme_bw() + # white background labs(x = &quot;Extraversion (10 pt scale)&quot;, # x-axis label y = &quot;Popularity, Sociometric Score&quot;) + # y-axis label guides(size = FALSE) + # don&#39;t include a legend scale_x_continuous(breaks = seq(from = 0, to = 10, by = 1)) + # x-ticks scale_y_continuous(breaks = seq(from = 0, to = 10, by = 2)) # y-ticks Figure 1.2: Disaggregate: pupil level only with extraversion treated as an continuous measure. The argument could be made that the extraversion score should be treated as an ordinal factor instead of as a truely continuous scale since the only valid values are the whole number 1 through 10 and there is no assurance that these category assignments represent a true ratio measurement scale. However, we must keep in mind that this was an observational study, ans as such, the number of pupils assignment each level of extraversion is not equal. # count the number of pupils in assigned each Extraversion value, 1:10 table &lt;- pop %&gt;% group_by(extrav) %&gt;% summarise(count = n_distinct(id), percent = 100 * count / 2000) table %&gt;% stargazer(summary = FALSE, rownames = FALSE, header = FALSE, type = &quot;html&quot;, title = &quot;Distribution of extraversion in pupils&quot;) Distribution of extraversion in pupils extrav count percent 1 3 0.15 2 13 0.65 3 119 5.95 4 423 21.15 5 688 34.4 6 478 23.9 7 194 9.7 8 58 2.9 9 18 0.9 10 6 0.3 Figure 1.3 displays the same data as Figure 1.1, but uses boxplots for the distribution of scores at each level of extraversion. On one extreme, the lowest extraversion score possible was a value of “one”, but only 3 pupils or 0.15% of the 2000 pupils recieved this value. On the other extreme, the middle value of “five” was applied to 688 pupils or a wopping 34.4%. The option varwidth=TRUE in the geom_boxplot() function helps reflect such unbalanced sample sizes by allowing the width of the boxes to be proportional to the square-roots of the number of observations each box represents. # Disaggregate: pupil (level 1) only, ignore level 2&#39;s existance # Extraversion treated: ordinal factor ggplot(pop, # dataset&#39;s name aes(x = factor(extrav), # x-axis values - make factor! y = popular, # y-axis values fill = factor(extrav))) + # makes seperate boxes geom_boxplot(varwidth = TRUE) + # draw boxplots instead of points theme_bw() + # white background guides(fill = FALSE) + # don&#39;t include a legend scale_y_continuous(breaks = seq(from = 0, to = 10, by = 2)) + # y-ticks labs(x = &quot;Extraversion (10 pt scale)&quot;, # x-axis label y = &quot;Popularity, Sociometric Score&quot;) + # y-axis label scale_fill_brewer(palette = &quot;Spectral&quot;, direction = 1) # select color Figure 1.3: Disaggregate: pupil level only with extraversion treated as an ordinal factor. The width of the boxes are proportional to the square-roots of the number of observations each box represents. Up to this point, all investigation of this dataset has been only at the pupil level and any nesting or clustering within classes has been ignored. Plotting is a good was to start to get an idea of the class-to-class variability. # compare the first 9 classrooms becuase all of there are too many at once pop %&gt;% dplyr::filter(class &lt;= 9) %&gt;% # select ONLY NINE classes ggplot(aes(x = extrav, # x-axis values y = popular)) + # y-axis values geom_count() + # POINTS w/ SIZE = COUNT geom_smooth(method = &quot;lm&quot;, color = &quot;red&quot;) + # linear regression line theme_bw() + # white background labs(x = &quot;Extraversion (10 pt scale)&quot;, # x-axis label y = &quot;Popularity, Sociometric Score&quot;, # y-axis label size = &quot;Count&quot;) + # legend key&#39;s title guides(size = FALSE) + # don&#39;t include a legend scale_x_continuous(breaks = seq(from = 0, to = 10, by = 3)) + # x-ticks scale_y_continuous(breaks = seq(from = 0, to = 10, by = 3)) + # y-ticks facet_wrap(~ class, labeller = label_both) + theme(strip.background = element_rect(colour = NA, fill = NA)) Figure 1.4: Illustration of the degree of class level variability in the association between extraversion and popularity. Each panel represents a class and each point a pupil in that class. First nice classes shown. # select specific classes by number for illustration purposes pop %&gt;% dplyr::filter(class %in% c(15, 25, 33, 35, 51, 64, 76, 94, 100)) %&gt;% ggplot(aes(x = extrav, # x-axis values y = popular)) + # y-axis values geom_count() + # POINTS w/ SIZE = COUNT geom_smooth(method = &quot;lm&quot;, color = &quot;red&quot;) + # linear regression line theme_bw() + # white background labs(x = &quot;Extraversion (10 pt scale)&quot;, # x-axis label y = &quot;Popularity, Sociometric Score&quot;, # y-axis label size = &quot;Count&quot;) + # legend key&#39;s title guides(size = FALSE) + # don&#39;t include a legend scale_x_continuous(breaks = seq(from = 0, to = 10, by = 3)) + # x-ticks scale_y_continuous(breaks = seq(from = 0, to = 10, by = 3)) + # y-ticks facet_wrap(~ class) + theme(strip.background = element_blank(), strip.text = element_blank()) Figure 1.5: Illustration of the degree of class level variability in the association between extraversion and popularity. Each panel represents a class and each point a pupil in that class. A set of nine classes was chosen to show a sampling of variability. The facet labels are not shown as the identification number probably would not be advisable for a general publication. # compare all 100 classrooms via linear model for each ggplot(pop, aes(x = extrav, # x-axis values y = popular, # y-axis values group = class)) + # GROUPs for LINES geom_smooth(method = &quot;lm&quot;, # linear regression line color = &quot;gray40&quot;, size = 0.4, se = FALSE) + theme_bw() + # white background labs(x = &quot;Extraversion (10 pt scale)&quot;, # x-axis label y = &quot;Popularity, Sociometric Score&quot;) + # y-axis label scale_x_continuous(breaks = seq(from = 0, to = 10, by = 2)) + # x-ticks scale_y_continuous(breaks = seq(from = 0, to = 10, by = 2)) # y-ticks Figure 1.6: Spaghetti plot of seperate, independent linear models for each of the 100 classes. A helpful resource for choosing colors to use in plots: R color cheatsheet # compare all 100 classrooms via independent linear models pop %&gt;% dplyr::mutate(texp3 = cut(pop$texp, breaks = c(0, 10, 18, 30)) %&gt;% factor(labels = c(&quot;&lt; 10 yrs&quot;, &quot;10 - 18 yrs&quot;, &quot;&gt; 18 yrs&quot;))) %&gt;% ggplot(aes(x = extrav, # x-axis values y = popular, # y-axis values group = class)) + # GROUPs for LINES geom_smooth(aes(color = sex), size = 0.3, method = &quot;lm&quot;, # linear regression line se = FALSE) + theme_bw() + # white background labs(x = &quot;Extraversion (10 pt scale)&quot;, # x-axis label y = &quot;Popularity, Sociometric Score&quot;) + # y-axis label guides(color = FALSE) + # don&#39;t include a legend scale_x_continuous(breaks = seq(from = 0, to = 10, by = 3)) + # x-ticks scale_y_continuous(breaks = seq(from = 0, to = 10, by = 3)) + # y-ticks scale_color_manual(values = c(&quot;dodgerblue&quot;, &quot;maroon1&quot;)) + facet_grid(texp3 ~ sex) Figure 1.7: Spaghetti plot of seperate, independent linear models for each of the 100 classes. Seperate panels are used to untangle the ‘hairball’ in the previous figure. The columns are seperated by the pupils’ gender and the rows by the teacher’s experince in years. R markdown is a user friendly, simplified language that allows for more complex formating utilizing standard \\(\\LaTeX\\) code. A great resource for learning how to many common tasks in \\(\\LaTeX\\) is the Sharewebsite. Specific mathematical equation documentation may be found on the Mathematical Expressions subpage. There are also many websites that offer Point-n-click interfaces to build \\(\\LaTeX\\) equations, including: Host Math, Code Cogs, LaTeX 4 Technics, and Sci-Weavers 1.3 Multilevel Regression Analysis 1.3.1 The Intercept Only Model “The intercept-only model is useful as a null-model that serves as a benchmark with which other models are compared.” Hox, Moerbeek, and Van de Schoot (2017), page 13 Hox, Moerbeek, and Van de Schoot (2017) labeled this as “\\(M_0\\)” in chapter 2: The Set of Level-Specific Model Equations: Level 1 Model Equation (\\(i^{th}\\) pupil in the \\(j^{th}\\) class) \\[ Y_{ij} = B_{0} + e_{ij} \\tag{Hox Eq 2.6} \\] Level 2 Model Equation (\\(j^{th}\\) class) \\[ B_{0} = \\gamma_{00} + u_{0j} \\tag{Hox Eq 2.7} \\] The Single, Multilevel Model Equation: \\[ POP_{ij} = \\gamma_{00} + u_{0j} + e_{ij} \\tag{M0: intercept only} \\] Parameters: Fixed Effects \\[ intercept \\longrightarrow \\gamma_{00} \\] Random Effects \\[ \\begin{align*} class (intercept) \\longrightarrow \\sigma^2_{u_0} &amp; = var[u_{0j}] \\\\ error -or- residual \\longrightarrow \\sigma^2_{e} &amp; = var[e_{ij}] \\\\ \\end{align*} \\] pop_lmer_0 &lt;- lme4::lmer(popular ~ 1 + (1|class), data = pop) summary(pop_lmer_0) Linear mixed model fit by REML [&#39;lmerMod&#39;] Formula: popular ~ 1 + (1 | class) Data: pop REML criterion at convergence: 6330.5 Scaled residuals: Min 1Q Median 3Q Max -3.5655 -0.6975 0.0020 0.6758 3.3175 Random effects: Groups Name Variance Std.Dev. class (Intercept) 0.7021 0.8379 Residual 1.2218 1.1053 Number of obs: 2000, groups: class, 100 Fixed effects: Estimate Std. Error t value (Intercept) 5.07786 0.08739 58.1 The entire population of all students in all classes has a grand-average of 5.0779 and the individual classes have popularity averages that vary around that. 1.3.2 Intraclass Correlation (ICC) Although the Null model above does not explain any variance in the dependent variable (popularity), since there are no independent variables, it does decompose (i.e. divide up) the variance into two pieces. We can compute the amount of total variance in popularity that is attribute to the clustering of students in classes verses the residual variance. \\[ \\rho = \\frac{\\sigma^2_{u0}}{\\sigma^2_{u0}+\\sigma^2_{e}} \\tag{Hox Eq 2.9} \\] Note: the VarCorr() function in the lme4 package returns the standard deviations, not the variances (\\(var = SD^2\\)) for a model fit via the lme4::lmer() function. The summary() function reports both the variances and the stadard deviations. lme4::VarCorr(pop_lmer_0) Groups Name Std.Dev. class (Intercept) 0.83792 Residual 1.10535 \\[ \\sigma^2_{u0} = 0.83792^2 = 0.7021\\\\ \\sigma^2_{e} = 1.10535^2 = 1.2218\\\\ \\] Calculate the ICC by hand: \\[ \\rho = \\frac{\\sigma^2_{u0}} {\\sigma^2_{u0}+\\sigma^2_{e}} = \\frac{0.7021} {0.7021+1.2218} = \\frac{0.7021} {1.9239} = 0.3649358 \\] Calculate the ICC with the icc() fucntion in the sjstats package: sjstats::icc(pop_lmer_0) Linear mixed model Family : gaussian (identity) Formula: popular ~ 1 + (1 | class) ICC (class): 0.3649 Interpretation: 36.5% of the variance of the popularity scores is at the group level, which is very high for social science data. The ICC should be based on a Null (intercept only) model fit via REML (restricted maximum likelihood) estimation. This is the default for the ‘lme4::lmer()’ function. In chapter 2, Hox, Moerbeek, and Van de Schoot (2017) presents the numbers based on fitting the model via ML (maximum likelihood) estimation and thus does not match the presentation above exactly (not just rounding error). This is probably because: (1) estimation methods (REML &amp; ML) are not discussed until chapter 3 and (2) due to the Null model also being used for model fit comparisons in Table 2.1 on the top of page 14. 1.3.3 Adding Predictors to the Model: “M1” (page 17) Hox, Moerbeek, and Van de Schoot (2017) labeled this as “\\(M_1\\)” in chapter 2: The Set of Level-Specific Model Equations: Level 1 Model Equation (\\(i^{th}\\) pupil in the \\(j^{th}\\) class) \\(GEN\\) = pupils’s gender \\(EXT\\) = pupil’s extraversion \\[ POP_{ij} = \\beta_{0j} + \\beta_{1j} GEN_{ij} + \\beta_{2j} EXT_{ij} + e_{ij} \\] Level 2 Model Equation (\\(j^{th}\\) class) \\(YRS\\) = teacher’s experience no cross level interactions \\[ \\begin{align*} \\beta_{0j} &amp; = \\gamma_{00} + \\gamma_{01} YRS{j} + u_{0j} \\\\ \\beta_{1j} &amp; = \\gamma_{10} + u_{1j} \\\\ \\beta_{2j} &amp; = \\gamma_{20} + u_{2j} \\end{align*} \\] The Single, Multilevel Model Equation: \\[ POP_{ij} = \\gamma_{00} + \\gamma_{10} GEN_{ij} + \\gamma_{20} EXT_{ij} + \\gamma_{01} YRS_j + u_{0j} + u_{1j} + u_{2j} + e_{ij} \\tag{M1: with predictors} \\] Parameters: Fixed Effects \\[ \\begin{align*} intercept \\longrightarrow &amp; \\gamma_{00}\\\\ pupil \\; gender \\longrightarrow &amp; \\gamma_{10}\\\\ pupil \\; extravert \\longrightarrow &amp; \\gamma_{20}\\\\ teacher \\; experience \\longrightarrow &amp; \\gamma_{01} \\end{align*} \\] Random Effects ignore covariances for now \\[ \\begin{align*} class (intercept) \\longrightarrow \\sigma^2_{u_0 } &amp; = var[u_{0j}] \\\\ pupil \\; gender \\longrightarrow \\sigma^2_{u_1} &amp; = var[u_{1j}] \\\\ pupil \\; extravert \\longrightarrow \\sigma^2_{u_2} &amp; = var[u_{2j}] \\\\ error -or- residual \\longrightarrow \\sigma^2_{e} &amp; = var[e_{ij}] \\end{align*} \\] pop_lm &lt;- lm(popular ~ 1, data = pop) pop_lmer_0_ml &lt;- lme4::lmer(popular ~ 1 + (1|class), data = pop, REML = FALSE) pop_lmer_1_ml &lt;- lme4::lmer(popular ~ sex + extrav + texp + (sex + extrav|class), data = pop, REML = FALSE) Reproduce Table 2.1 on the top of page 14 (Hox, Moerbeek, and Van de Schoot 2017) texreg::htmlreg(list(pop_lm, pop_lmer_0_ml, pop_lmer_1_ml), custom.model.names = c(&quot;Single-level&quot;, &quot;M0: int only&quot;, &quot;M1: w pred&quot;)) Statistical models Single-level M0: int only M1: w pred (Intercept) 5.08*** 5.08*** 0.75*** (0.03) (0.09) (0.20) sexgirl 1.25*** (0.04) extrav 0.45*** (0.02) texp 0.09*** (0.01) R2 0.00 Adj. R2 0.00 Num. obs. 2000 2000 2000 RMSE 1.38 AIC 6333.47 4834.53 BIC 6350.27 4896.14 Log Likelihood -3163.73 -2406.27 Num. groups: class 100 100 Var: class (Intercept) 0.69 1.30 Var: Residual 1.22 0.55 Var: class sexgirl 0.00 Var: class extrav 0.03 Cov: class (Intercept) sexgirl -0.03 Cov: class (Intercept) extrav -0.18 Cov: class sexgirl extrav 0.00 p &lt; 0.001, p &lt; 0.01, p &lt; 0.05 "],
["references.html", "References", " References "]
]
